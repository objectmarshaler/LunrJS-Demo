{
	"tutorials" : [{
			"id" : "2",
			"category" : "Tokenization",
			"title" : "The Art of Tokenization",
			"body" : "<div class=\"css-entry\"> \n                     \t\t\t\t\t\t\t\t\t\t<div class=\"syn-box\" style=\"float:right;padding-top:5px;padding-left:20px;\">\n\t\t\t\t\t\t \n                            <!-- Google + -->\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t<div id=\"___plusone_0\" style=\"text-indent: 0px; margin: 0px; padding: 0px; background: transparent; border-style: none; float: none; line-height: normal; font-size: 1px; vertical-align: baseline; display: inline-block; width: 106px; height: 24px;\"><iframe frameborder=\"0\" hspace=\"0\" marginheight=\"0\" marginwidth=\"0\" scrolling=\"no\" style=\"position: static; top: 0px; width: 106px; margin: 0px; border-style: none; left: 0px; visibility: visible; height: 24px;\" tabindex=\"0\" vspace=\"0\" width=\"100%\" id=\"I0_1476779658862\" name=\"I0_1476779658862\" src=\"https://apis.google.com/u/0/se/0/_/+1/fastbutton?usegapi=1&amp;origin=https%3A%2F%2Fwww.ibm.com&amp;url=https%3A%2F%2Fwww.ibm.com%2Fdeveloperworks%2Fcommunity%2Fblogs%2Fnlp%2Fentry%2Ftokenization&amp;gsrc=3p&amp;ic=1&amp;jsh=m%3B%2F_%2Fscs%2Fapps-static%2F_%2Fjs%2Fk%3Doz.gapi.en.3OrSP52ONx4.O%2Fm%3D__features__%2Fam%3DAQ%2Frt%3Dj%2Fd%3D1%2Frs%3DAGLTcCMPwdgP_1o4CcK25rd7BTyWk_6CiQ#_methods=onPlusOne%2C_ready%2C_close%2C_open%2C_resizeMe%2C_renderstart%2Concircled%2Cdrefresh%2Cerefresh%2Conload&amp;id=I0_1476779658862&amp;parent=https%3A%2F%2Fwww.ibm.com&amp;pfname=&amp;rpctoken=27467508\" data-gapiattached=\"true\" title=\"+1\"></iframe></div>\n\t\t\t\t\t\t\t<!-- Place this tag after the last +1 button tag. -->\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t<script type=\"text/javascript\">\n\t\t\t\t\t\t\t\tdojo.addOnLoad(function() {setTimeout(\n\t\t\t\t\t\t\t\tfunction() {\n\t\t\t\t\t\t\t\t\tif (window.gplusonescript === undefined) {\n\t\t\t\t\t\t\t\t\t\twindow.gplusonescript = true;\n\t\t\t\t\t\t\t\t\t\tvar po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;\n\t\t\t\t\t\t\t\t\t\tpo.src = 'https://apis.google.com/js/plusone.js';\n\t\t\t\t\t\t\t\t\t\tvar s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t},100)}); \n\t\t\t\t\t\t\t</script>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t<!-- Facebook -->\n\t\t\t\t\t\t\t \t\t\t\t\t\t\t<div style=\"!important; margin-top:1px !important;\">\n\t\t\t\t\t\t\t\t<iframe scrolling=\"no\" frameborder=\"0\" allowtransparency=\"true\" title=\"facebook-syndication\" style=\"border:none; overflow:hidden; width:90px; height:22px;\" src=\"https://www.facebook.com/plugins/like.php?href=https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization&amp;layout=button_count&amp;show_faces=false&amp;width=90&amp;action=like&amp;font=arial&amp;colorscheme=light&amp;height=20\"></iframe>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t<!-- Linked IN-->\n\t\t\t\t\t\t\t \t\t\t\t\t\t\t<script src=\"//platform.linkedin.com/in.js\" type=\"text/javascript\"></script>\n\t\t\t\t\t\t\t<span class=\"IN-widget\" style=\"line-height: 1; vertical-align: baseline; display: inline-block; text-align: center;\"><span style=\"padding: 0px !important; margin: 0px !important; text-indent: 0px !important; display: inline-block !important; vertical-align: baseline !important; font-size: 1px !important;\"><span id=\"li_ui_li_gen_1476779656760_0\"><a id=\"li_ui_li_gen_1476779656760_0-link\" href=\"javascript:void(0);\"><span id=\"li_ui_li_gen_1476779656760_0-logo\">in</span><span id=\"li_ui_li_gen_1476779656760_0-title\"><span id=\"li_ui_li_gen_1476779656760_0-mark\"></span><span id=\"li_ui_li_gen_1476779656760_0-title-text\">Share</span></span></a></span></span><span style=\"padding: 0px !important; margin: 0px !important; text-indent: 0px !important; display: inline-block !important; vertical-align: baseline !important; font-size: 1px !important;\"><span id=\"li_ui_li_gen_1476779656770_1-container\" class=\"IN-right IN-hidden\"><span id=\"li_ui_li_gen_1476779656770_1\" class=\"IN-right\"><span id=\"li_ui_li_gen_1476779656770_1-inner\" class=\"IN-right\"><span id=\"li_ui_li_gen_1476779656770_1-content\" class=\"IN-right\">0</span></span></span></span></span></span><script type=\"IN/Share+init\" data-url=\"https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization\" data-counter=\"right\"></script>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t<br> \n\t\t\t\t\t\t\t<!-- Twitter -->\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"https://twitter.com/share\" class=\"twitter-share-button\" data-url=\"https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization?lang=en\">Tweet</a>\n\t\t\t\t\t\t\t<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=\"//platform.twitter.com/widgets.js\";fjs.parentNode.insertBefore(js,fjs);}}(document,\"script\",\"twitter-wjs\");</script>\t        \t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t</div>\n                                \n                   \n\n            \n\t\t\t\t                                                                                                             \t      \t        \t\t\t                             \n\n\n\n\n<!-- SECTION 1 -->\n<h2>Tokenization</h2>\n<p><i>The process of segmenting running text into words and sentences.</i></p>\n<p>Electronic text is a linear sequence of symbols (characters or words or phrases).  Naturally, before any real text processing is to be done, text needs to be segmented into linguistic units such as words, punctuation, numbers, alpha-numerics, etc.  This process is called tokenization.</p>\n<p>In English, words are often separated from each other by blanks (white space), but not all white space is equal.  Both “Los Angeles” and “rock 'n' roll” are individual thoughts despite the fact that they contain multiple words and spaces.  We may also need to separate single words like “I'm” into separate words “I” and “am”.</p>\n<p>Tokenization is a kind of pre-processing in a sense; an identification of basic units to be processed.  It is conventional to concentrate on pure analysis or generation while taking basic units for granted.  Yet without these basic units clearly segregated it is impossible to carry out any analysis or generation.</p>\n<p>The identification of units that do not need to be further decomposed for subsequent processing is an extremely important one.  Errors made at this stage are very likely to induce more errors at later stages of text processing and are therefore very dangerous.</p>\n\n<!-- SECTION 2 -->\n<br>\n<h2>What counts as a token in NLP?</h2>\n<p>The notion of a token must first be defined before computational processing can proceed.  There is more to the issue than simply identifying strings delimited on both sides by spaces or punctuation.</p>\n<p>Different notions depend on different objectives, and often different language backgrounds.</p>\n<ol>\nA token is \n<li>Linguistically significant</li>\n<li>Methodologically useful</li>\n</ol>\n<p>Webster and Kit suggest that finding significant tokens depends on the ability to recognize patterns displaying significant collocation.  Rather than simply relying on wehther a string is bounded by delimters on either side, segmentation into significant tokens relies on a kind of pattern recognition.</p>\n<p>Consider this hypothetical speech transcription:</p>\n<blockquote><i>\twhere is meadows dr who asked</i></blockquote>\n<p>Collocation patterns could help determine if this is about meadows dr (Drive) or dr (Doctor) who.</p>\n\n<!-- SECTION 3 -->\n<br>\n<h2>Standard (White Space) Tokenization</h2>\n<p>Word tokenization may seem simple in a language that separates words by a special 'space' character.  However, not every language does this (e.g. Chinese, Japanese, Thai), and a closer examination will make it clear that white space alone is not sufficient even for English.  </p>\n\n<!-- SECTION 4 -->\n<br>\n<h2>Addressing Specific Challenges</h2>\n<p>Tokenization is generally considered as easy relative to other tasks in natural language, and one of the more uninteresting tasks (for English and other segmented languages).  However, errors made in this phase will propogate into later phases and cause problems.  To address this problem, a number of advanced methods which deal with specific challenges in tokenization have been developed to complement standard tokenizers.</p>\n<p>Bob Carpenter states that tokenization is particularly vexing in the bio-medical text domain, where there are tons of words (or at least phrasal lexical entries) that contain parentheses, hyphens, and so on, and that this turned out to be a problem for WordNet).</p>\n<p>Another challenge for tokenization is “dirty text”1.  Not all text has been passed through an editing and spell-check process.  Text extracted automatically from PDFs, database fields, or other sources may contain inaccurately compounded tokens, spelling errors and unexpected characters. In some cases, when text is stored in a database in fixed fields, with multiple lines per object, fields sometimes need to be reassembled but the spaces have (inconsistently) been trimmed.</p>\n<p>It is not safe to make the assumption that source text will be perfect.  A tokenizer must often be customized to the data in question.</p>\n\n<!-- SECTION 5 -->\n<br>\n<h2>Low-Level vs High-Level Tokenization</h2>\n<p>Determining if two or more words should stand together to form a single token (like “Rational Software Architect”) would be a high-level tokenization task.  High-level segmentation is much more linguistically motivated than 'low-level' segmentation, and requires (at a minimum) relatively shallow linguistic processing.</p>\n\n<br>\n<h2>Steps in Low Level Tokenization</h2><br>\n<br>\n<h3>Step 1: Segmenting Text into Words</h3>\n\n<p>The first step in the majority of text processing applications is to segment text into words.</p>\n<p>In all modern languages that use a Latin-, Cyrillic-, or Greek-based writing system, such as English and other European languages, word tokens are delimited by a blank space. Thus, for such languages, which are called segmented languages, token boundary identification is a somewhat trivial task since the majority of tokens are bound by explicit separators like spaces and punctuation. A simple program which replaces white spaces with word boundaries and cuts off leading and trailing quotation marks, parentheses and punctuation already produces a reasonable performance.</p>\n<p>The majority of existing tokenizers signal token boundaries by white spaces. Thus, if such a tokenizer finds two tokens directly adjacent to each other, as, for instance, when a word is followed by a comma, it inserts a white space between them.</p>\n<p>The example given in a following section will show how a standard white space tokenizer fares in a more complex example</p>\n\n<br>\n<h3>Step 2:  Handling Abbreviations</h3>\n<p>In English and other Indo-European languages although a period is directly attached to the previous word, it is usually a separate token which signals the end of the sentence. However, when a period follows an abbreviation it is an integral part of this abbreviation and should be tokenized together with it.</p>\n<blockquote><i>the dr. lives in a blue box.</i></blockquote>\n<p>Without addressing the challenge posed by abbreviation, this line would be delimited into</p>\n<blockquote><i>\nthe dr.<br>\nlives in a blue box.\n</i></blockquote>\n<p>Unfortunately, universally accepted standards for many abbreviations and acronyms do not exist. </p>\n\n<p>The most widely adopted approach to the recognition of abbreviations is to maintain a list of known abbreviations. Thus during tokenization a word with a trailing period can be looked up in such a list and, if it is found there, it is tokenized as a single token, otherwise the period is tokenized as a separate token. Naturally, the accuracy of this approach depends on how well the list of abbreviations is tailored to the text under processing. There will almost certainly be abbreviations in the text which are not included in the list. Also, abbreviations in the list can coincide with common words and trigger erroneous tokenization. For instance, `in' can be an abbreviation for `inches; `no' can be an abbreviation for `number, `bus' can be an abbreviation for `business; `sun' can be an abbreviation for `Sunday; etc.</p>\n<p>The following lists are by no means comprehensive:</p>\n<ol>Common Acronyms with Punctuation\n<li>I.O.U.</li>\n<li>M.D.</li>\n<li>N.B.</li>\n<li>P.O.</li>\n<li>U.K.</li>\n<li>U.S.</li>\n<li>U.S.A.</li>\n<li>P.S.</li>\n</ol>\n<br>\n<ol>Common Words containing Periods\n<li>.c</li>\n<li>mr.</li>\n<li>mrs.</li>\n<li>.com</li>\n<li>dr.</li>\n<li>.sh</li>\n<li>.java</li>\n<li>st.</li>\n</ol>\n<br><br>\n<h3>Step 3: Handling Hyphenated Words</h3>\n<p>Segmentation of hyphenated words answers a question `One word or two?'</p>\n<p>Hyphenated segments present a case of ambiguity for a tokenizer-sometimes a hyphen is part of a token, i.e. self-assessment, F-15, forty-two and sometimes it is not e.g. Los Angeles-based.  </p>\n<p>Segmentation of hyphenated words is task dependent. For instance, part-of-speech taggers (Chapter ii) usually treat hyphenated words as a single syntactic unit and therefore prefer them to be tokenized as single tokens. On the other hand named entity recognition (NER) systems (Chapter 30) attempt to split a named entity from the rest of a hyphenated fragment; e.g. in parsing the fragment `Moscow-based' such a system needs `Moscow' to be tokenized separately from `based' to be able to tag it as a location.</p>\n<ol>Types of Hyphens:\n<li>End-of-Line Hyphen</li>\n<li>True Hyphen\n    </li><ol><li>Lexical Hyphen</li><li>Sententially Determined Hyphenation</li></ol></ol><ol>\n</ol>\n<br><br>\n\n<h2>End-of-Line Hyphen</h2>\n<p>End-of-line hyphens are used for splitting whole words into parts to perform justification of text during typesetting. Therefore they should be removed during tokenization because they are not part of the word but rather layouting instructions.</p>\n\n<br>\n<h2>True Hyphen</h2>\n<p>True hyphens, on the other hand, are integral parts of complex tokens, e.g.forty-seven, and should therefore not be removed. Sometimes it is difficult to distinguish a true hyphen from an end-of-line hyphen when a hyphen occurs at the end of a line.</p>\n\n<br>\n<h2>Lexical Hyphen</h2>\n<p>Hyphenated compound words which have made their way into standard language vocabularly.  For instance, certain prefixes (and less commonly suffixes) are often written hyphenated, e.g. co-, pre-, meta-, multi-, etc.</p>\n\n<br>\n<h2>Sententially Determined Hyphenation</h2>\n<p>Here hyphenated forms are created dynamically as a mechanism to prevent incorrect parsing of the phrase in which the words appear. There are several types of hyphenation in this class. One is created when a noun is modified by an `ed'-verb to dynamically create an adjective, e.g. case-based, computer-linked, hand-delivered. Another case involves an entire expression when it is used as a modifier in a noun group, as in a three-to-five-year direct marketing plan. In treating these cases a lexical look-up strategy is not much help and normally such expressions are treated as a single token unless there is a need to recognize specific tokens, such as dates, measures, names, in which case they are handled by specialized subgrammars</p>\n<p>This hypothetical sentence poes many challenges:</p>\n<br>\n<blockquote><i>\nthe New York-based co-operative was fine-\ntuning forty-two K-9-like models.\n</i></blockquote>\n\n<table border=\"1\" width=\"100%\">\n<tbody>\n\t<tr>\n\t\t<td width=\"50%\">Token</td>\n\t\t<td width=\"50%\">Type</td>\n        </tr>\n</tbody>\n\t<tbody><tr>\n\t\t<td width=\"10%\">New York-based</td>\n\t\t<td width=\"18%\"><b>Sentential</b></td>\n        </tr>\n\t<tr>\n\t\t<td width=\"10%\">co-operative</td>\n\t\t<td width=\"18%\"><b>Lexical</b></td>\n        </tr>\n\t<tr>\n\t\t<td width=\"10%\">fine-tuning</td>\n\t\t<td width=\"18%\"><b>End-of-Line</b>, but could also be considered a <b>Lexical</b> hyphen based on the author's stylistic preferences.</td>\n        </tr>\n\t<tr>\n\t\t<td width=\"10%\">Forty-two</td>\n\t\t<td width=\"18%\"><b>Lexical</b></td>\n        </tr>\n\t<tr>\n\t\t<td width=\"10%\">K-9-like</td>\n\t\t<td width=\"18%\"><b>Lexical</b> and <b>Sentential</b></td>\n        </tr>\n</tbody></table>\n<br><br><br>\n<h3>Step 3: Numerical and special expressions</h3>\n\n<ol>Examples:\n<li>Email addresses</li>\n<li>URLs</li>\n<li>Complex enumeration of items</li>\n<li>Telephone Numbers</li>\n<li>Dates</li>\n<li>Time</li>\n<li>Measures</li>\n<li>Vehicle Licence Numbers</li>\n<li>Paper and book citations</li>\n<li>etc</li>\n</ol>\n<p>These can produce a lot of confusion to a tokenizer because they usually involve rather complex alpha numerical and punctuation syntax.  </p>\n\n\n<p>Take phone numbers for example - </p>\n<ol>A variety of formats exist:\n<li>123-456-7890</li>\n<li>(123)-456-7890</li>\n<li>123.456.7890</li>\n<li>(123) 456-7890</li>\n<li>etc</li>\n</ol>\n\n<p>A pre-processor should be designed to recognize phone numbers and perform normalization.  All phone numbers would then be in a single format, making the job of a tokenizer easier.</p>\n\n<ol>Date/Time Formats:<br>\n<li>8th-Feb</li>\n<li>8-Feb-2013</li>\n<li>02/08/13</li>\n<li>February 8th, 2013</li>\n<li>Feb 8th</li>\n<li>etc</li>\n</ol>\n\n<p>A pre-processor could recognize all these distinct variations and normalize into a single expression.</p>\n\n<!-- section 1 -->\n<h2>Tokenization Example</h2>\n<p></p><blockquote><i>\"I said, 'what're you?  Crazy?'\" said Sandowsky.  \"I can't afford to do that.\"</i>\n\n<table border=\"1\" width=\"100%\">\n<tbody>\n\t<tr>\n\t\t<td width=\"10%\">&nbsp;</td>\n\t\t<td width=\"18%\">Naïve  Whitespace Parser</td>\n\t\t<td width=\"18%\">Apache Open NLP 1.5.2 (using en-token.bin)</td>\n\t\t<td width=\"18%\">Stanford 2.0.3</td>\n\t\t<td width=\"18%\">Custom</td>\n\t\t<td width=\"18%\">Hypothetical Tokenizer (Ideal Tokenization)</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"1\" width=\"28\">\n\t\t\t<p align=\"center\"><i>1</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">“</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">“</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">“</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">“</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"2\" width=\"28\">\n\t\t\t<p align=\"center\"><i>2</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">“i</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">i</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">i</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">i</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">i</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"3\" width=\"28\">\n\t\t\t<p align=\"center\"><i>3</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">said,</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">said</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">said</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">said</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">said</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"4\" width=\"28\">\n\t\t\t<p align=\"center\"><i>4</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">,</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">,</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">,</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">,</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"5\" width=\"28\">\n\t\t\t<p align=\"center\"><i>5</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'what're</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'what</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">`</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"6\" width=\"28\">\n\t\t\t<p align=\"center\"><i>6</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">what</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">what're</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">what</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"7\" width=\"28\">\n\t\t\t<p align=\"center\"><i>7</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'re</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'re</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">are</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"8\" width=\"28\">\n\t\t\t<p align=\"center\"><i>8</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">you?</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">you</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">you</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">you</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">you</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"9\" width=\"28\">\n\t\t\t<p align=\"center\"><i>9</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">?</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">?</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">?</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">?</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"10\" width=\"28\">\n\t\t\t<p align=\"center\"><i>10</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">crazy?'”</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">crazy</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">crazy</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">crazy</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">crazy</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"11\" width=\"28\">\n\t\t\t<p align=\"center\"><i>11</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">?</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">?</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">?</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">?</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"12\" width=\"28\">\n\t\t\t<p align=\"center\"><i>12</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"13\" width=\"28\">\n\t\t\t<p align=\"center\"><i>13</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">said</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">said</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">said</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">said</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">said</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"14\" width=\"28\">\n\t\t\t<p align=\"center\"><i>14</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">sandowsky.</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">sandowsky</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">sandowsky</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">sandowsky</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">sandowsky</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"15\" width=\"28\">\n\t\t\t<p align=\"center\"><i>15</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">.</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">.</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">.</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">.</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"16\" width=\"28\">\n\t\t\t<p align=\"center\"><i>16</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">“</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"17\" width=\"28\">\n\t\t\t<p align=\"center\"><i>17</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'i</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">i</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">i</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">i</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">i</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"18\" width=\"28\">\n\t\t\t<p align=\"center\"><i>18</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">can't</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">ca</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">ca</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">can't</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">can</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"19\" width=\"28\">\n\t\t\t<p align=\"center\"><i>19</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">n't</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">n't</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">not</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"20\" width=\"28\">\n\t\t\t<p align=\"center\"><i>20</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">afford</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">afford</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">afford</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">afford</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">afford</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"21\" width=\"28\">\n\t\t\t<p align=\"center\"><i>21</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">to</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">to</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">to</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">to</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">to</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"22\" width=\"28\">\n\t\t\t<p align=\"center\"><i>22</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">do</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">do</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">do</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">do</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">do</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"23\" width=\"28\">\n\t\t\t<p align=\"center\"><i>23</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">that.'</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">that</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\" style=\"margin-bottom: 0in\">that</p>\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">that</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">that</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"24\" width=\"28\">\n\t\t\t<p align=\"center\"><i>24</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">.</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">.</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">.</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">.</p>\n\t\t</td>\n\t</tr>\n\t<tr valign=\"top\">\n\t\t<td sdnum=\"1033;\" sdval=\"25\" width=\"28\">\n\t\t\t<p align=\"center\"><i>25</i></p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\"><br>\n\t\t\t</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t\t<td width=\"114\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t\t<td width=\"113\">\n\t\t\t<p align=\"center\">'</p>\n\t\t</td>\n\t</tr>\n</tbody>\n</table>\n\n</blockquote>\n<p>The naïve white space parser is shown to perform poorly here.</p>\n<p>The Stanford tokenizer does somewhat better than the OpenNLP tokenizer, which is to be expected.  The custom parser (included in the appendix) in the 4th column, does a nearly perfect job, though without the enclitic expansion shown in the first hypothetical pass.</p>\n<p>The more accurate (and complex) segmentation process in the fourth and fifth columns require a morphological parsing process.</p>\n<p>We can address some of these issues in the first three examples by treating punctuation, in addition to white space, as a word boundary.  But punctuation often occurs internally, in examples like u.s.a., Ph.D., AT&amp;T, ma'am, cap'n, 01/02/06 and stanford.edu.  Similarity, assuming we want 7.1 or 82.4 as a word, we can't segment on every period, since that would segment these into \"7\" and \"1\" and \"82\" and \"4\".  Should \"data-base\" be considered two separate tokens or a single token?  The number \"$2,023.74\" should be considered a single token, but in this case, the comma and period do not represent delimiters, where in other cases they might.  And should the \"$\" sign be considered part of that token, or a separate token in its own right?</p>\n<p>The java<wbr>.uti<wbr>l.Si<wbr>mple<wbr>Toke<wbr>nize<wbr>r class in Java is an example of a white space tokenizer, where you can define the set of characters that mark the boundaries of tokens.  Another Java class, java<wbr>.tex<wbr>t.Br<wbr>eakI<wbr>tera<wbr>tor, can identify word or sentence boundaries, but still does not handle ambiguities.</p>\n\n<div>&nbsp;</div><h2>Named Entity Extraction</h2>\n\n<p>It's almost impossible to separate tokenization from named entity extraction.  It really isn't possible to come up with a generic set of rules that will handle all ambiguous cases within English; the easiest approach is usually just to have multi-word expression dictionaries.</p>\n<p>\n\t</p><blockquote>\n\t\t<i>\n\t\t\tInstall Rational Software Architect on AIX 5.3\n\t\t</i>\n\n\t\t<table _moz_resizing=\"true\" border=\"1\" width=\"100%\">\n\t\t\t<tbody>\n\t\t\t\t<tr>\n\t\t\t\t\t<td width=\"10%\">&nbsp;</td>\n\t\t\t\t\t<td width=\"45%\">Naïve  Whitespace Parser</td>\n\t\t\t\t\t<td width=\"45%\">Hypothetical Tokenizer (Ideal Tokenization)</td>\n\t\t\t\t</tr>\n\t\t\t</tbody>\n\t\t\t<tbody><tr valign=\"top\">\n\t\t\t\t<td sdnum=\"1033;\" sdval=\"1\">\n\t\t\t\t\t<p align=\"center\"><i>1</i></p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">install</p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">install</p>\n\t\t\t\t</td>\n\t\t\t</tr>\n\t\t\t<tr valign=\"top\">\n\t\t\t\t<td sdnum=\"1033;\" sdval=\"2\">\n\t\t\t\t\t<p align=\"center\"><i>2</i></p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">rational</p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">rational\n\t\t\t\t\tsoftware architect for websphere</p>\n\t\t\t\t</td>\n\t\t\t</tr>\n\t\t\t<tr valign=\"top\">\n\t\t\t\t<td sdnum=\"1033;\" sdval=\"3\">\n\t\t\t\t\t<p align=\"center\"><i>3</i></p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">software</p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\"><br>\n\t\t\t\t\t</p>\n\t\t\t\t</td>\n\t\t\t</tr>\n\t\t\t<tr valign=\"top\">\n\t\t\t\t<td sdnum=\"1033;\" sdval=\"4\">\n\t\t\t\t\t<p align=\"center\"><i>4</i></p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">architect</p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\"><br>\n\t\t\t\t\t</p>\n\t\t\t\t</td>\n\t\t\t</tr>\n\t\t\t<tr valign=\"top\">\n\t\t\t\t<td sdnum=\"1033;\" sdval=\"5\">\n\t\t\t\t\t<p align=\"center\"><i>5</i></p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">for</p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\"><br>\n\t\t\t\t\t</p>\n\t\t\t\t</td>\n\t\t\t</tr>\n\t\t\t<tr valign=\"top\">\n\t\t\t\t<td sdnum=\"1033;\" sdval=\"6\">\n\t\t\t\t\t<p align=\"center\"><i>6</i></p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">websphere</p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\"><br>\n\t\t\t\t\t</p>\n\t\t\t\t</td>\n\t\t\t</tr>\n\t\t\t<tr valign=\"top\">\n\t\t\t\t<td sdnum=\"1033;\" sdval=\"7\">\n\t\t\t\t\t<p align=\"center\"><i>7</i></p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">on</p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">on</p>\n\t\t\t\t</td>\n\t\t\t</tr>\n\t\t\t<tr valign=\"top\">\n\t\t\t\t<td sdnum=\"1033;\" sdval=\"8\">\n\t\t\t\t\t<p align=\"center\"><i>8</i></p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">aix</p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\">aix\n\t\t\t\t\t5.3</p>\n\t\t\t\t</td>\n\t\t\t</tr>\n\t\t\t<tr valign=\"top\">\n\t\t\t\t<td sdnum=\"1033;\" sdval=\"9\">\n\t\t\t\t\t<p align=\"center\"><i>9</i></p>\n\t\t\t\t</td>\n\t\t\t\t<td sdnum=\"1033;\" sdval=\"5.3\">\n\t\t\t\t\t<p align=\"center\">5.3</p>\n\t\t\t\t</td>\n\t\t\t\t<td>\n\t\t\t\t\t<p align=\"center\"><br>\n\t\t\t\t\t</p>\n\t\t\t\t</td>\n\t\t\t</tr>\n\t\t</tbody></table>\n\t</blockquote>\n<p>\n</p><p>Dictionaries will have to exist that express to the tokenization process that \"Rational Software Architect for WebSphere\" is a single token (a product), and \"AIX 5.3\" is likewise a single product.</p>\n<p>The impact that tokenization has upon the rest of the process can not be understated.  A typical next step, following tokenization, is to send the segmented text to a deep parser.  In the first column, the rational product would end up being deep parsed into a structure like this:</p>\n<p>OpenNLP 1.5.2 (en-<wbr>pars<wbr>er-c<wbr>hunk<wbr>ing.<wbr>bin)<wbr>:</p>\n<div>&nbsp;&nbsp;&nbsp; &lt;node prob=\"0.99\" span=\"<span style=\"background-color: rgb(255, 255, 0);\">Rational Software Architect for WebSphere</span>\" type=\"<b>NP</b>\"&gt;<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;node prob=\"1.0\" span=\"<span style=\"background-color: rgb(255, 255, 0);\">Rational Software Architect</span>\" type=\"<b>NP</b>\"&gt;<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;node prob=\"0.86\" span=\"<span style=\"background-color: rgb(255, 255, 0);\">Rational</span>\" type=\"<b>NNP</b>\"/&gt;<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;node prob=\"0.94\" span=\"<span style=\"background-color: rgb(255, 255, 0);\">Software</span>\" type=\"<b>NNP</b>\"/&gt;<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;node prob=\"0.93\" span=\"<span style=\"background-color: rgb(255, 255, 0);\">Architect</span>\" type=\"<b>NNP</b>\"/&gt;<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;/node&gt;<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;node prob=\"0.99\" span=\"<span style=\"background-color: rgb(255, 255, 0);\">for WebSphere</span>\" type=\"<b>PP</b>\"&gt;<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;node prob=\"0.93\" span=\"<span style=\"background-color: rgb(255, 255, 0);\">for</span>\" type=\"<b>IN</b>\"/&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;node prob=\"1.0\" span=\"<span style=\"background-color: rgb(255, 255, 0);\">WebSphere</span>\" type=\"<b>NP</b>\"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;node prob=\"0.24\" span=\"<span style=\"background-color: rgb(255, 255, 0);\">WebSphere</span>\" type=\"<b>NNP</b>\"/&gt;<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;/node&gt;<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;/node&gt;<br>&nbsp;&nbsp;&nbsp; &lt;/node&gt;<br></div><div>&nbsp;</div>\n\n<p>(Output from Stanford 2.0.3 is identical)</p>\n<p>Note the formation of a prepositional phrase (PP) around \"for WebSphere\" and the noun phrase trigram \"Rational Software Architect\".  If the sentence was semantically segmented with the aid of a multi-word dictionary, the output from the deep parser would have looked like this:\n</p><div>&nbsp;&nbsp;&nbsp; &lt;node span=\"<span style=\"background-color: rgb(255, 255, 0);\">Rational Software Architect for WebSphere</span>\" type=\"<b>NP</b>\"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;node span=\"<span style=\"background-color: rgb(255, 255, 0);\">Rational Software Architect for WebSphere</span>\" type=\"<b>NNP</b>\"/&gt;<br>&nbsp;&nbsp;&nbsp; &lt;/node&gt;<br></div>\n\n<p>There is a single noun phrase containing one noun (NNP = singular noun1).</p>\n<div>&nbsp;</div><h2>\n\tEnglish Enclitics\n</h2>\n<p>A clitic is a unit whose status lies between that of an affix and a word.  The phonological behavior of a clitic is like affixes; they tend to be short and unaccented.  Their syntactic behavior is more like words, often acting as pronouns, articles, conjunctions, or verbs.  Clitics preceding a word are called proclitics, and those following are enclictics.</p>\n<p>English enclitics include:</p>\n<p>The abbreviated forms of <i>be</i>:</p>\n<ol>\n\t\t<li>\n\t\t\t’m in I’m\n\t\t</li>\n\t\t<li>\n\t\t\t’re in you’re\n\t\t</li>\n\t\t<li>\n\t\t\t’s in she’s\n\t\t</li>\n\t</ol>\n<p>The abbreviated forms of <i>auxiliary verbs</i>:</p>\n<ol>\n\t\t<li>\n\t\t\t’ll in they’ll\n\t\t</li>\n\t\t<li>\n\t\t\t’ve in they’ve\n\t\t</li>\n\t\t<li>\n\t\t\t’d in you’d\n\t\t</li>\n\t</ol>\n<p>Note that clitics in English are ambiguous.  The word \"she's\" can mean \"she has\" or \"she is\".</p>\n<p>A tokenizer can also be used to expand clitic contractions that are marked by apostrophes, for example:</p>\n<blockquote>\n\t\twhat're =&gt; what are <br>\n\t\twe're =&gt; we are\n</blockquote>\n<p>This requires ambiguity resolution, since apostrophes are also used as genitive markers as in \"the book's over in the containers' above\" or as quotative markers.  While these contractions tend to be clictics, not all clictics are marked this way with contractions.  In general, then, segmenting and expanding clitics and be done as part of a morphological parsing process.</p>\n<p>Enclitic Analysis (New York Times):</p>\n\n<blockquote>\n\t\t<table border=\"1\" width=\"100%\">\n\t\t\t<tbody>\n\t\t\t\t<tr>\n\t\t\t\t\t<td width=\"16%\">Clitic</td>\n\t\t\t\t\t<td width=\"16%\">Example</td>\n\t\t\t\t\t<td width=\"16%\">Full Form</td>\n\t\t\t\t\t<td width=\"16%\">Total Frequency</td>\n\t\t\t\t\t<td width=\"16%\">Totals</td>\n\t\t\t\t\t<td width=\"16%\">% Occurence</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>'s</td>\n\t\t\t\t\t<td>He's</td>\n\t\t\t\t\t<td>He has</td>\n\t\t\t\t\t<td>15,909,933</td>\n\t\t\t\t\t<td>17,054,319</td>\n\t\t\t\t\t<td>93.29%</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>'re</td>\n\t\t\t\t\t<td>You're</td>\n\t\t\t\t\t<td>You are</td>\n\t\t\t\t\t<td>381,176</td>\n\t\t\t\t\t<td>17,054,319</td>\n\t\t\t\t\t<td>2.24%</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>'m</td>\n\t\t\t\t\t<td>I'm</td>\n\t\t\t\t\t<td>I am</td>\n\t\t\t\t\t<td>257,465</td>\n\t\t\t\t\t<td>17,054,319</td>\n\t\t\t\t\t<td>1.51%</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>'ve</td>\n\t\t\t\t\t<td>They've</td>\n\t\t\t\t\t<td>They have</td>\n\t\t\t\t\t<td>242,249</td>\n\t\t\t\t\t<td>17,054,319</td>\n\t\t\t\t\t<td>1.42%</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>'ll</td>\n\t\t\t\t\t<td>We'll</td>\n\t\t\t\t\t<td>We will</td>\n\t\t\t\t\t<td>142,452</td>\n\t\t\t\t\t<td>17,054,319</td>\n\t\t\t\t\t<td>0.84%</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>'d</td>\n\t\t\t\t\t<td>She'd</td>\n\t\t\t\t\t<td>She would, She had</td>\n\t\t\t\t\t<td>121,044</td>\n\t\t\t\t\t<td>17,054,319</td>\n\t\t\t\t\t<td>0.71%</td>\n\t\t\t\t</tr>\n\t\t\t</tbody>\n\t\t</table>\n\t</blockquote>\n\n<div>&nbsp;</div><div>&nbsp;&nbsp; <br></div><h2>References:</h2>\n\t<ol>\n\t\t<li>\n\t\t\tJurafsky, Dan. Speech and Language Processing, 2nd Edition. NJ: Pearson, 2009. Book.\n\t\t</li>\n\t\t<li>\n\t\t\tJackson, Peter.  Natural Language Processing for Online Applications.  PHL: John Benjamins Publishing Company, 2007.  Book.\n\t\t</li>\t\t\n                <li>\n\t\t\tMitkov, Ruslan. The Oxford Handbook of Computational Linguistics.  Oxford University Press, 2009. Book.\n\t\t</li>\n                <li>\n\t\t\tWebster, Jonathan., Kit, Chunyu. 1992.  Tokenization as the initial phase in NLP.  City Polytechnic of Hong Kong.\n\t\t</li>\n                <li>\n\t\t\t<a href=\"http://lingpipe-blog.com/2008/06/26/the-curse-of-intelligent-tokenization\" target=\"_blank\">The Curse of \"Intelligent\" Tokenization</a>. LingPipe Blog. 26 June 2008.\t\n                </li>\n\t</ol>\n\n<div>&nbsp; </div><div>&nbsp;</div><h2>Appendix A - Anlaysis of clitic usage from the NYT Corpus</h2>\n<br>&nbsp;<br>\n<ol>\n\t<li>\n\t\t<a href=\"https://www.ibm.com/developerworks/mydeveloperworks/blogs/nlp/resource/0240/CliticAnalysis-All.zip \" target=\"_blank\">Clitic Analysis - All.csv</a><br><i>\n\t\tContains all clitics and term frequencies, sorted by alpha.\n\t</i><br>&nbsp;</li>\n\t<li>\n\t\t<a href=\"https://www.ibm.com/developerworks/mydeveloperworks/blogs/nlp/resource/0240/CliticAnalysis-Min5Freq.zip \" target=\"_blank\">Clitic Analysis - Min 5 Freq.csv</a><br><i>\n\t\tContains all clitics and term frequencies (threshold &gt;=5), sorted by alpha.\n\t</i><br>&nbsp;</li>\n\t<li>\n\t\t<a href=\"https://www.ibm.com/developerworks/mydeveloperworks/blogs/nlp/resource/0240/CliticAnalysis-Totals.zip \" target=\"_blank\">Clitic Analysis.xls</a><br><i>\n\t\tAnalysis of \"Clitic Analysis - Min 5 Freq.csv\" formatted in an Excel Spreadsheet.\n\t</i><br>&nbsp;</li>\n\t<li>\n\t\t<a href=\"https://www.ibm.com/developerworks/mydeveloperworks/blogs/nlp/resource/0240/CliticAnalysis.zip \" target=\"_blank\">Clitic Analysis - Totals.xls</a><br><i>\n\t\tSummarized counts of clitics (table shown in this article)\n\t</i></li>\n</ol>\n<br> <br>\n<div>  </div><div> </div><h2>Appendix B - Source Code</h2>\n<br> <br>\n<ol>\n\t<li><a href=\"https://www.ibm.com/developerworks/mydeveloperworks/blogs/nlp/resource/0240/StanfordTokenizer.zip\" target=\"_blank\">Stanford Tokenizer<br></a>\n\t</li><li><a href=\"https://www.ibm.com/developerworks/mydeveloperworks/blogs/nlp/resource/0240/OpenNLPTokenizer.zip\" target=\"_blank\">OpenNLP Tokenizer<br></a>\n\t</li><li><a href=\"https://www.ibm.com/developerworks/mydeveloperworks/blogs/nlp/resource/0240/CustomTokenizer.zip \" target=\"_blank\">Custom Tokenizer</a>\n</li></ol>\n           \n                                \t              \t\t            \t\t\t<br><br>\n\t\t\t   <span class=\"min-tags\" role=\"list\">\n\t\t\t\tTags:&nbsp;\n\t\t\t       \t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=semantics&amp;lang=en\" title=\"semantics\">semantics</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=opennlp&amp;lang=en\" title=\"opennlp\">opennlp</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=lexer&amp;lang=en\" title=\"lexer\">lexer</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=tokenization&amp;lang=en\" title=\"tokenization\">tokenization</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=natural_language_processing&amp;lang=en\" title=\"natural_language_processing\">natural_language_processi...</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=parsing&amp;lang=en\" title=\"parsing\">parsing</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=parse&amp;lang=en\" title=\"parse\">parse</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=syntax&amp;lang=en\" title=\"syntax\">syntax</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=apache&amp;lang=en\" title=\"apache\">apache</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=tokens&amp;lang=en\" title=\"tokens\">tokens</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=open_nlp&amp;lang=en\" title=\"open_nlp\">open_nlp</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=rdf&amp;lang=en\" title=\"rdf\">rdf</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=segementation&amp;lang=en\" title=\"segementation\">segementation</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=parser&amp;lang=en\" title=\"parser\">parser</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=stanford&amp;lang=en\" title=\"stanford\">stanford</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=watson&amp;lang=en\" title=\"watson\">watson</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=nlp&amp;lang=en\" title=\"nlp\">nlp</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t        <span role=\"listitem\">\n\t\t\t\t\t<a href=\"https://www.ibm.com/developerworks/community/blogs/nlp?tags=lexical_analysis&amp;lang=en\" title=\"lexical_analysis\">lexical_analysis</a>\n\t\t\t\t</span>\n\t\t\t\t\t\t\t  </span>\n\t\t\t                     <div style=\"clear:both\"></div>\n\n                    \n                                                                  \n                                                   \n           <div style=\"clear:both;\"></div>\n           \n\t        </div>"
		}, {
			"id" : "3",
			"category" : "Tokenization",
			"title" : "Tokenization (lexical analysis) - WIKI",
			"body" : "<div id=\"mw-content-text\" lang=\"en\" dir=\"ltr\" class=\"mw-content-ltr\"><table class=\"metadata plainlinks ambox ambox-move\" role=\"presentation\">\n<tbody><tr>\n<td class=\"mbox-image\">\n<div style=\"width:52px\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Merge-arrow.svg/50px-Merge-arrow.svg.png\" width=\"50\" height=\"20\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Merge-arrow.svg/75px-Merge-arrow.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Merge-arrow.svg/100px-Merge-arrow.svg.png 2x\" data-file-width=\"50\" data-file-height=\"20\"></div>\n</td>\n<td class=\"mbox-text\"><span class=\"mbox-text-span\">It has been suggested that this article be <a href=\"/wiki/Wikipedia:Merging\" title=\"Wikipedia:Merging\">merged</a> into <i><a href=\"/wiki/Lexical_analysis#Tokenization\" title=\"Lexical analysis\">Lexical analysis#Tokenization</a></i>. (<a href=\"/wiki/Talk:Lexical_analysis\" title=\"Talk:Lexical analysis\">Discuss</a>) <small><i>Proposed since August 2014.</i></small></span></td>\n</tr>\n</tbody></table>\n<table class=\"metadata plainlinks ambox ambox-move\" role=\"presentation\">\n<tbody><tr>\n<td class=\"mbox-image\">\n<div style=\"width:52px\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Merge-arrow.svg/50px-Merge-arrow.svg.png\" width=\"50\" height=\"20\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Merge-arrow.svg/75px-Merge-arrow.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Merge-arrow.svg/100px-Merge-arrow.svg.png 2x\" data-file-width=\"50\" data-file-height=\"20\"></div>\n</td>\n<td class=\"mbox-text\"><span class=\"mbox-text-span\">It has been suggested that this article be <a href=\"/wiki/Wikipedia:Merging\" title=\"Wikipedia:Merging\">merged</a> into <i><a href=\"/wiki/Text_segmentation#Word_segmentation\" title=\"Text segmentation\">Text segmentation#Word segmentation</a></i>. (<a href=\"/wiki/Talk:Text_segmentation\" title=\"Talk:Text segmentation\">Discuss</a>) <small><i>Proposed since October 2014.</i></small></span></td>\n</tr>\n</tbody></table>\n<table class=\"metadata plainlinks ambox ambox-content ambox-Refimprove\" role=\"presentation\">\n<tbody><tr>\n<td class=\"mbox-image\">\n<div style=\"width:52px\"><a href=\"/wiki/File:Question_book-new.svg\" class=\"image\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png\" width=\"50\" height=\"39\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/75px-Question_book-new.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png 2x\" data-file-width=\"512\" data-file-height=\"399\"></a></div>\n</td>\n<td class=\"mbox-text\"><span class=\"mbox-text-span\">This article <b>needs additional citations for <a href=\"/wiki/Wikipedia:Verifiability\" title=\"Wikipedia:Verifiability\">verification</a></b>. <span class=\"hide-when-compact\">Please help <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Tokenization_(lexical_analysis)&amp;action=edit\">improve this article</a> by <a href=\"/wiki/Help:Introduction_to_referencing_with_Wiki_Markup/1\" title=\"Help:Introduction to referencing with Wiki Markup/1\">adding citations to reliable sources</a>. Unsourced material may be challenged and removed.</span> <small><i>(August 2010)</i></small> <small class=\"hide-when-compact\"><i>(<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></span></td>\n</tr>\n</tbody></table>\n<p>In <a href=\"/wiki/Lexical_analysis\" title=\"Lexical analysis\">lexical analysis</a>, <b>tokenization</b> is the process of breaking a stream of text up into words, phrases, symbols, or other meaningful elements called tokens. The list of tokens becomes input for further processing such as <a href=\"/wiki/Parsing\" title=\"Parsing\">parsing</a> or <a href=\"/wiki/Text_mining\" title=\"Text mining\">text mining</a>. Tokenization is useful both in linguistics (where it is a form of <a href=\"/wiki/Text_segmentation\" title=\"Text segmentation\">text segmentation</a>), and in computer science, where it forms part of <a href=\"/wiki/Lexical_analysis\" title=\"Lexical analysis\">lexical analysis</a>.</p>\n<p></p>\n<div id=\"toc\" class=\"toc\">\n<div id=\"toctitle\">\n<h2>Contents</h2>\n<span class=\"toctoggle\">&nbsp;[<a role=\"button\" tabindex=\"0\" id=\"togglelink\">hide</a>]&nbsp;</span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Methods_and_obstacles\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Methods and obstacles</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Software\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Software</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#See_also\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-4\"><a href=\"#References\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">References</span></a></li>\n</ul>\n</div>\n<p></p>\n<h2><span class=\"mw-headline\" id=\"Methods_and_obstacles\">Methods and obstacles</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Tokenization_(lexical_analysis)&amp;action=edit&amp;section=1\" title=\"Edit section: Methods and obstacles\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Typically, tokenization occurs at the word level. However, it is sometimes difficult to define what is meant by a \"word\". Often a tokenizer relies on simple heuristics, for example:</p>\n<ul>\n<li>Punctuation and whitespace may or may not be included in the resulting list of tokens.</li>\n<li>All contiguous strings of alphabetic characters are part of one token; likewise with numbers</li>\n<li>Tokens are separated by <a href=\"/wiki/Whitespace_character\" title=\"Whitespace character\">whitespace</a> characters, such as a space or line break, or by punctuation characters.</li>\n</ul>\n<p>In languages that use inter-word spaces (such as most that use the Latin alphabet, and most programming languages), this approach is fairly straightforward. However, even here there are many edge cases such as <a href=\"/wiki/Poetic_contraction\" title=\"Poetic contraction\">contractions</a>, <a href=\"/wiki/Hyphen\" title=\"Hyphen\">hyphenated words</a>, <a href=\"/wiki/Emoticons\" class=\"mw-redirect\" title=\"Emoticons\">emoticons</a>, and larger constructs such as <a href=\"/wiki/URI\" class=\"mw-redirect\" title=\"URI\">URIs</a> (which for some purposes may count as single tokens). A classic example is \"New York-based\", which a naive tokenizer may break at the space even though the better break is (arguably) at the hyphen.</p>\n<p>Tokenization is particularly difficult for languages written in <a href=\"/wiki/Scriptio_continua\" title=\"Scriptio continua\">scriptio continua</a> which exhibit no word boundaries such as <a href=\"/wiki/Ancient_Greek\" title=\"Ancient Greek\">Ancient Greek</a>, <a href=\"/wiki/Chinese_language\" title=\"Chinese language\">Chinese</a>,<sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\">[1]</a></sup> or <a href=\"/wiki/Thai_language\" title=\"Thai language\">Thai</a>. <a href=\"/wiki/Agglutinative_language\" title=\"Agglutinative language\">Agglutinative language</a>, such as Korean, also make tokenization tasks complicated.</p>\n<p>Some ways to address the more difficult problems include developing more complex heuristics, querying a table of common special-cases, or fitting the tokens to a <a href=\"/wiki/Language_model\" title=\"Language model\">language model</a> that identifies collocations in a later processing step.</p>\n<h2><span class=\"mw-headline\" id=\"Software\">Software</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Tokenization_(lexical_analysis)&amp;action=edit&amp;section=2\" title=\"Edit section: Software\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://opennlp.apache.org/index.html\">Apache OpenNLP</a> includes rule based and statistical tokenizers which support many languages</li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"http://tokenizer.tool.uniwits.com\">U-Tokenizer</a> is an API over HTTP that can cut Mandarin and Japanese sentences at word boundary. English is supported as well.</li>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"https://dev.havenondemand.com/apis/tokenizetext#overview\">HPE Haven OnDemand Text Tokenization API</a> (Commercial product, with freemium access) uses Advanced Probabilistic Concept Modelling to determine the weight that the term holds in the specified text indexes</li>\n</ul>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Tokenization_(lexical_analysis)&amp;action=edit&amp;section=3\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul>\n<li><a href=\"/wiki/Tokenization_(data_security)\" title=\"Tokenization (data security)\">Tokenization (data security)</a></li>\n</ul>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Tokenization_(lexical_analysis)&amp;action=edit&amp;section=4\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\"><span class=\"cite-accessibility-label\">Jump up </span>^</a></b></span> <span class=\"reference-text\">Huang, C., Simon, P., Hsieh, S., &amp; Prevot, L. (2007) <a rel=\"nofollow\" class=\"external text\" href=\"http://www.aclweb.org/anthology/P/P07/P07-2018.pdf\">Rethinking Chinese Word Segmentation: Tokenization, Character Classification, or Word break Identification</a></span></li>\n</ol>\n</div>\n<ul>\n<li><a rel=\"nofollow\" class=\"external text\" href=\"https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization?lang=en\">\"The Art of Tokenization\"</a>, <i><a href=\"/wiki/DeveloperWorks\" class=\"mw-redirect\" title=\"DeveloperWorks\">developerWorks</a></i>, Jan 23, 2013.</li>\n</ul>\n<p><br></p>\n<table class=\"metadata plainlinks stub\" role=\"presentation\" style=\"background:transparent\">\n<tbody><tr>\n<td><a href=\"/wiki/File:Emoji_u1f4bb.svg\" class=\"image\"><img alt=\"Stub icon\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Emoji_u1f4bb.svg/30px-Emoji_u1f4bb.svg.png\" width=\"30\" height=\"30\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Emoji_u1f4bb.svg/45px-Emoji_u1f4bb.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Emoji_u1f4bb.svg/60px-Emoji_u1f4bb.svg.png 2x\" data-file-width=\"128\" data-file-height=\"128\"></a></td>\n<td><i>This computing article is a <a href=\"/wiki/Wikipedia:Stub\" title=\"Wikipedia:Stub\">stub</a>. You can help Wikipedia by <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Tokenization_(lexical_analysis)&amp;action=edit\">expanding it</a>.</i>\n<div class=\"plainlinks hlist navbar mini\" style=\"position: absolute; right: 15px; display: none;\">\n<ul>\n<li class=\"nv-view\"><a href=\"/wiki/Template:Compu-stub\" title=\"Template:Compu-stub\"><abbr title=\"View this template\">v</abbr></a></li>\n<li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Compu-stub\" title=\"Template talk:Compu-stub\"><abbr title=\"Discuss this template\">t</abbr></a></li>\n<li class=\"nv-edit\"><a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Template:Compu-stub&amp;action=edit\"><abbr title=\"Edit this template\">e</abbr></a></li>\n</ul>\n</div>\n</td>\n</tr>\n</tbody></table>\n\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:24517557-0!*!0!!en!4!* and timestamp 20160930093814 and revision id 739364718\n -->\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.log.warn(\"Gadget \\\"teahouse\\\" styles loaded twice. Migrate to type=general. See \\u003Chttps://phabricator.wikimedia.org/T42284\\u003E.\");mw.log.warn(\"Gadget \\\"ReferenceTooltips\\\" styles loaded twice. Migrate to type=general. See \\u003Chttps://phabricator.wikimedia.org/T42284\\u003E.\");mw.log.warn(\"Gadget \\\"featured-articles-links\\\" styles loaded twice. Migrate to type=general. See \\u003Chttps://phabricator.wikimedia.org/T42284\\u003E.\");});</script><noscript>&lt;img src=\"//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" alt=\"\" title=\"\" width=\"1\" height=\"1\" style=\"border: none; position: absolute;\" /&gt;</noscript></div>"
		},
		{
			"id" : "4",
			"category" : "Stop Words",
			"title" : "List of English Stop Words",
			"body" : "<article id=\"post-183\" class=\"post-183 post type-post status-publish format-standard has-post-thumbnail hentry category-search-techniques tag-featured tag-filter tag-noise-words tag-pictures tag-stop-words\">\n<div class=\"post-image\">\n<div class=\"post-heading\">\n<h3><a href=\"http://xpo6.com/list-of-english-stop-words/\">List of English Stop Words</a></h3>\n</div>\n<img width=\"837\" height=\"499\" src=\"http://i0.wp.com/xpo6.com/wp-content/uploads/2009/04/stop-words.png?fit=837%2C499\" class=\"img-responsive wp-post-image\" alt=\"Stop Words\" srcset=\"http://i0.wp.com/xpo6.com/wp-content/uploads/2009/04/stop-words.png?w=837 837w, http://i0.wp.com/xpo6.com/wp-content/uploads/2009/04/stop-words.png?resize=300%2C179 300w\" sizes=\"(max-width: 837px) 100vw, 837px\"> </div>\n<p><strong>Stop Words</strong> are words which do not contain important significance to be used in Search Queries. Usually these words are filtered out from search queries because they return vast amount of unnecessary information. A better definition is provided below:</p>\n<p>“Words that do not appear in the index in a particular database because they are either insignificant (i.e., articles, prepositions) or so common that the results would be higher than the system can handle (as in the case of IUCAT where terms such as United States or Department are stop words in keyword searching.) Stop words vary from system to system. Also, some systems will merely ignore stop words where use of stop words in other systems will result in retrieving zero hits. ”</p>\n<p><em>http://www.iusb.edu/~libg/instruction/helpguide/handouts/2005Boolean.shtml</em></p>\n<p>Since I needed to use them in a project (<a title=\"Alexander von Humboldt \" href=\"http://www.avhumboldt.net\" target=\"_blank\">Humboldt Diglital Library and Network</a>), I am posting here a list of English stop words, and below a PHP array containing these words</p>\n<p>Here is a list of english stop words:<br>\n<code><br>\na<br>\nabout<br>\nabove<br>\nacross<br>\nafter<br>\nafterwards<br>\nagain<br>\nagainst<br>\nall<br>\nalmost<br>\nalone<br>\nalong<br>\nalready<br>\nalso<br>\nalthough<br>\nalways<br>\nam<br>\namong<br>\namongst<br>\namoungst<br>\namount<br>\nan<br>\nand<br>\nanother<br>\nany<br>\nanyhow<br>\nanyone<br>\nanything<br>\nanyway<br>\nanywhere<br>\nare<br>\naround<br>\nas<br>\nat<br>\nback<br>\nbe<br>\nbecame<br>\nbecause<br>\nbecome<br>\nbecomes<br>\nbecoming<br>\nbeen<br>\nbefore<br>\nbeforehand<br>\nbehind<br>\nbeing<br>\nbelow<br>\nbeside<br>\nbesides<br>\nbetween<br>\nbeyond<br>\nbill<br>\nboth<br>\nbottom<br>\nbut<br>\nby<br>\ncall<br>\ncan<br>\ncannot<br>\ncant<br>\nco<br>\ncomputer<br>\ncon<br>\ncould<br>\ncouldnt<br>\ncry<br>\nde<br>\ndescribe<br>\ndetail<br>\ndo<br>\ndone<br>\ndown<br>\ndue<br>\nduring<br>\neach<br>\neg<br>\neight<br>\neither<br>\neleven<br>\nelse<br>\nelsewhere<br>\nempty<br>\nenough<br>\netc<br>\neven<br>\never<br>\nevery<br>\neveryone<br>\neverything<br>\neverywhere<br>\nexcept<br>\nfew<br>\nfifteen<br>\nfify<br>\nfill<br>\nfind<br>\nfire<br>\nfirst<br>\nfive<br>\nfor<br>\nformer<br>\nformerly<br>\nforty<br>\nfound<br>\nfour<br>\nfrom<br>\nfront<br>\nfull<br>\nfurther<br>\nget<br>\ngive<br>\ngo<br>\nhad<br>\nhas<br>\nhasnt<br>\nhave<br>\nhe<br>\nhence<br>\nher<br>\nhere<br>\nhereafter<br>\nhereby<br>\nherein<br>\nhereupon<br>\nhers<br>\nherse\"<br>\nhim<br>\nhimse\"<br>\nhis<br>\nhow<br>\nhowever<br>\nhundred<br>\ni<br>\nie<br>\nif<br>\nin<br>\ninc<br>\nindeed<br>\ninterest<br>\ninto<br>\nis<br>\nit<br>\nits<br>\nitse\"<br>\nkeep<br>\nlast<br>\nlatter<br>\nlatterly<br>\nleast<br>\nless<br>\nltd<br>\nmade<br>\nmany<br>\nmay<br>\nme<br>\nmeanwhile<br>\nmight<br>\nmill<br>\nmine<br>\nmore<br>\nmoreover<br>\nmost<br>\nmostly<br>\nmove<br>\nmuch<br>\nmust<br>\nmy<br>\nmyse\"<br>\nname<br>\nnamely<br>\nneither<br>\nnever<br>\nnevertheless<br>\nnext<br>\nnine<br>\nno<br>\nnobody<br>\nnone<br>\nnoone<br>\nnor<br>\nnot<br>\nnothing<br>\nnow<br>\nnowhere<br>\nof<br>\noff<br>\noften<br>\non<br>\nonce<br>\none<br>\nonly<br>\nonto<br>\nor<br>\nother<br>\nothers<br>\notherwise<br>\nour<br>\nours<br>\nourselves<br>\nout<br>\nover<br>\nown<br>\npart<br>\nper<br>\nperhaps<br>\nplease<br>\nput<br>\nrather<br>\nre<br>\nsame<br>\nsee<br>\nseem<br>\nseemed<br>\nseeming<br>\nseems<br>\nserious<br>\nseveral<br>\nshe<br>\nshould<br>\nshow<br>\nside<br>\nsince<br>\nsincere<br>\nsix<br>\nsixty<br>\nso<br>\nsome<br>\nsomehow<br>\nsomeone<br>\nsomething<br>\nsometime<br>\nsometimes<br>\nsomewhere<br>\nstill<br>\nsuch<br>\nsystem<br>\ntake<br>\nten<br>\nthan<br>\nthat<br>\nthe<br>\ntheir<br>\nthem<br>\nthemselves<br>\nthen<br>\nthence<br>\nthere<br>\nthereafter<br>\nthereby<br>\ntherefore<br>\ntherein<br>\nthereupon<br>\nthese<br>\nthey<br>\nthick<br>\nthin<br>\nthird<br>\nthis<br>\nthose<br>\nthough<br>\nthree<br>\nthrough<br>\nthroughout<br>\nthru<br>\nthus<br>\nto<br>\ntogether<br>\ntoo<br>\ntop<br>\ntoward<br>\ntowards<br>\ntwelve<br>\ntwenty<br>\ntwo<br>\nun<br>\nunder<br>\nuntil<br>\nup<br>\nupon<br>\nus<br>\nvery<br>\nvia<br>\nwas<br>\nwe<br>\nwell<br>\nwere<br>\nwhat<br>\nwhatever<br>\nwhen<br>\nwhence<br>\nwhenever<br>\nwhere<br>\nwhereafter<br>\nwhereas<br>\nwhereby<br>\nwherein<br>\nwhereupon<br>\nwherever<br>\nwhether<br>\nwhich<br>\nwhile<br>\nwhither<br>\nwho<br>\nwhoever<br>\nwhole<br>\nwhom<br>\nwhose<br>\nwhy<br>\nwill<br>\nwith<br>\nwithin<br>\nwithout<br>\nwould<br>\nyet<br>\nyou<br>\nyour<br>\nyours<br>\nyourself<br>\nyourselves</code><br>\nAnd here is a php array with stop words:<br>\n<code>$stopwords = array(\"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \"amoungst\", \"amount\",&nbsp; \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \"anywhere\", \"are\", \"around\", \"as\",&nbsp; \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thickv\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\");</code></p>\n<h4>Updated October 3d, 2009.</h4>\n<p>This is the stop words list used by MySQL FullText feature</p>\n<blockquote><p>a’s, able, about, above, according, accordingly, across, actually, after, afterwards, again, against, ain’t, all, allow, allows, almost, alone, along, already, also, although, always, am, among, amongst, an, and, another, any, anybody, anyhow, anyone, anything, anyway, anyways, anywhere, apart, appear, appreciate, appropriate, are, aren’t, around, as, aside, ask, asking, associated, at, available, away, awfully, be, became, because, become, becomes, becoming, been, before, beforehand, behind, being, believe, below, beside, besides, best, better, between, beyond, both, brief, but, by, c’mon, c’s, came, can, can’t, cannot, cant, cause, causes, certain, certainly, changes, clearly, co, com, come, comes, concerning, consequently, consider, considering, contain, containing, contains, corresponding, could, couldn’t, course, currently, definitely, described, despite, did, didn’t, different, do, does, doesn’t, doing, don’t, done, down, downwards, during, each, edu, eg, eight, either, else, elsewhere, enough, entirely, especially, et, etc, even, ever, every, everybody, everyone, everything, everywhere, ex, exactly, example, except, far, few, fifth, first, five, followed, following, follows, for, former, formerly, forth, four, from, further, furthermore, get, gets, getting, given, gives, go, goes, going, gone, got, gotten, greetings, had, hadn’t, happens, hardly, has, hasn’t, have, haven’t, having, he, he’s, hello, help, hence, her, here, here’s, hereafter, hereby, herein, hereupon, hers, herself, hi, him, himself, his, hither, hopefully, how, howbeit, however, i’d, i’ll, i’m, i’ve, ie, if, ignored, immediate, in, inasmuch, inc, indeed, indicate, indicated, indicates, inner, insofar, instead, into, inward, is, isn’t, it, it’d, it’ll, it’s, its, itself, just, keep, keeps, kept, know, knows, known, last, lately, later, latter, latterly, least, less, lest, let, let’s, like, liked, likely, little, look, looking, looks, ltd, mainly, many, may, maybe, me, mean, meanwhile, merely, might, more, moreover, most, mostly, much, must, my, myself, name, namely, nd, near, nearly, necessary, need, needs, neither, never, nevertheless, new, next, nine, no, nobody, non, none, noone, nor, normally, not, nothing, novel, now, nowhere, obviously, of, off, often, oh, ok, okay, old, on, once, one, ones, only, onto, or, other, others, otherwise, ought, our, ours, ourselves, out, outside, over, overall, own, particular, particularly, per, perhaps, placed, please, plus, possible, presumably, probably, provides, que, quite, qv, rather, rd, re, really, reasonably, regarding, regardless, regards, relatively, respectively, right, said, same, saw, say, saying, says, second, secondly, see, seeing, seem, seemed, seeming, seems, seen, self, selves, sensible, sent, serious, seriously, seven, several, shall, she, should, shouldn’t, since, six, so, some, somebody, somehow, someone, something, sometime, sometimes, somewhat, somewhere, soon, sorry, specified, specify, specifying, still, sub, such, sup, sure, t’s, take, taken, tell, tends, th, than, thank, thanks, thanx, that, that’s, thats, the, their, theirs, them, themselves, then, thence, there, there’s, thereafter, thereby, therefore, therein, theres, thereupon, these, they, they’d, they’ll, they’re, they’ve, think, third, this, thorough, thoroughly, those, though, three, through, throughout, thru, thus, to, together, too, took, toward, towards, tried, tries, truly, try, trying, twice, two, un, under, unfortunately, unless, unlikely, until, unto, up, upon, us, use, used, useful, uses, using, usually, value, various, very, via, viz, vs, want, wants, was, wasn’t, way, we, we’d, we’ll, we’re, we’ve, welcome, well, went, were, weren’t, what, what’s, whatever, when, whence, whenever, where, where’s, whereafter, whereas, whereby, wherein, whereupon, wherever, whether, which, while, whither, who, who’s, whoever, whole, whom, whose, why, will, willing, wish, with, within, without, won’t, wonder, would, would, wouldn’t, yes, yet, you, you’d, you’ll, you’re, you’ve, your, yours, yourself, yourselves, zero</p></blockquote>\n<h2>CSV Format</h2>\n<blockquote><p>a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your</p></blockquote>\n<p>I have also created another article where you can <a title=\"Download Stop Word List\" href=\"http://xpo6.com/download-stop-word-list/\">download stop words</a> in csv, txt or as a php file</p>\n<div class=\"sharedaddy sd-sharing-enabled\"><div class=\"robots-nocontent sd-block sd-social sd-social-icon-text sd-sharing\"><h3 class=\"sd-title\">Share this:</h3><div class=\"sd-content\"><ul><li class=\"share-twitter\"><a rel=\"nofollow\" data-shared=\"sharing-twitter-183\" class=\"share-twitter sd-button share-icon\" href=\"http://xpo6.com/list-of-english-stop-words/?share=twitter&amp;nb=1\" target=\"_blank\" title=\"Click to share on Twitter\"><span>Twitter</span></a></li><li class=\"share-google-plus-1\"><a rel=\"nofollow\" data-shared=\"sharing-google-183\" class=\"share-google-plus-1 sd-button share-icon\" href=\"http://xpo6.com/list-of-english-stop-words/?share=google-plus-1&amp;nb=1\" target=\"_blank\" title=\"Click to share on Google+\"><span>Google</span></a></li><li class=\"share-end\"></li></ul></div></div></div><div class=\"sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-loaded\" id=\"like-post-wrapper-83247450-183-5805dd289466b\" data-src=\"//widgets.wp.com/likes/#blog_id=83247450&amp;post_id=183&amp;origin=xpo6.com&amp;obj_id=83247450-183-5805dd289466b\" data-name=\"like-post-frame-83247450-183-5805dd289466b\"><h3 class=\"sd-title\">Like this:</h3><div class=\"likes-widget-placeholder post-likes-widget-placeholder\" style=\"height: 55px; display: none;\"><span class=\"button\"><span>Like</span></span> <span class=\"loading\">Loading...</span></div><iframe class=\"post-likes-widget jetpack-likes-widget\" name=\"like-post-frame-83247450-183-5805dd289466b\" height=\"55px\" width=\"100%\" frameborder=\"0\" src=\"//widgets.wp.com/likes/#blog_id=83247450&amp;post_id=183&amp;origin=xpo6.com&amp;obj_id=83247450-183-5805dd289466b\"></iframe><span class=\"sd-text-color\"></span><a class=\"sd-link-color\"></a></div>\n<div id=\"jp-relatedposts\" class=\"jp-relatedposts\">\n<h3 class=\"jp-relatedposts-headline\"><em>Related</em></h3>\n</div>\n</article>"
		},
		{
			"id" : "5",
			"category" : "Stemming",
			"title" : "The Porter stemming algorithm",
			"body" : "<table width=\"75%\" align=\"CENTER\" cols=\"1\">\n\n\n<tbody><tr><td>\n<br>&nbsp;<h2>Links to resources</h2>\n\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td><a href=\"../..\"> Snowball main page</a>\n</td></tr><tr><td><a href=\"stem_ISO_8859_1.sbl\">    The stemmer in Snowball</a>\n</td></tr><tr><td><a href=\"stem.c\">      The ANSI C stemmer</a>\n</td></tr><tr><td><a href=\"stem.h\">      — and its header</a>\n</td></tr><tr><td><a href=\"voc.txt\">     Sample English vocabulary</a>\n</td></tr><tr><td><a href=\"output.txt\">  Its stemmed equivalent</a>\n</td></tr><tr><td><a href=\"diffs.txt\">   Vocabulary + stemmed equivalent</a>\n</td></tr><tr><td><a href=\"tarball.tgz\"> Tar-gzipped file of all of the above</a>\n<br><br>\n</td></tr><tr><td><a href=\"http://www.tartarus.org/~martin/PorterStemmer/index.html\">\nThe ‘official’ home page of the Porter stemming algorithm</a>\n</td></tr></tbody></table></dd></dl>\n\n<br><br>\n\n<b>Here is a case study on how to code up a stemming algorithm in Snowball. First,\nthe definition of the Porter stemmer, as it appeared in <b><i>Program</i></b>, Vol 14 no. 3 pp\n130-137, July 1980.</b>\n\n<br><br>\n\n</td></tr><tr><td bgcolor=\"silver\">\n\n<br>&nbsp;<h2>THE ALGORITHM</h2>\n\nA <i>consonant</i> in a word is a letter other than A, E, I, O or U, and other\nthan Y preceded by a consonant. (The fact that the term ‘consonant’ is\ndefined to some extent in terms of itself does not make it ambiguous.) So in\nTOY the consonants are T and Y, and in SYZYGY they are S, Z and G. If a\nletter is not a consonant it is a <i>vowel</i>.\n<br><br>\nA consonant will be denoted by c, a vowel by v. A list ccc... of length\ngreater than 0 will be denoted by C, and a list vvv... of length greater\nthan 0 will be denoted by V. Any word, or part of a word, therefore has one\nof the four forms:\n<dl>\n    <dt>CVCV ... C\n    </dt><dt>CVCV ... V\n    </dt><dt>VCVC ... C\n    </dt><dt>VCVC ... V\n</dt></dl>\nThese may all be represented by the single form\n<dl><dd>\n    [C]VCVC ... [V]\n</dd></dl>\nwhere the square brackets denote arbitrary presence of their contents.\nUsing (VC)<sup>m</sup> to denote VC repeated m times, this may again be written as\n<dl><dd>\n    [C](VC)<sup>m</sup>[V].\n</dd></dl>\nm will be called the <i>measure</i> of any word or word part when represented in\nthis form. The case m = 0 covers the null word. Here are some examples:\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>   m=0 </td><td></td><td>   TR, &nbsp;   EE, &nbsp;   TREE, &nbsp;   Y, &nbsp;   BY.\n</td></tr><tr><td>   m=1 </td><td></td><td>   TROUBLE, &nbsp;   OATS, &nbsp;   TREES, &nbsp;   IVY.\n</td></tr><tr><td>   m=2 </td><td></td><td>   TROUBLES, &nbsp;   PRIVATE, &nbsp;   OATEN, &nbsp;   ORRERY.\n</td></tr></tbody></table></dd></dl>\nThe <i>rules</i> for removing a suffix will be given in the form\n<dl><dd>\n    (condition) S1 <tt>-&gt;</tt> S2\n</dd></dl>\nThis means that if a word ends with the suffix S1, and the stem before S1\nsatisfies the given condition, S1 is replaced by S2. The condition is\nusually given in terms of m, e.g.\n<dl><dd>\n    (m &gt; 1) EMENT <tt>-&gt;</tt>\n</dd></dl>\nHere S1 is ‘EMENT’ and S2 is null. This would map REPLACEMENT to REPLAC,\nsince REPLAC is a word part for which m = 2.\n<br><br>\nThe ‘condition’ part may also contain the following:\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>*S  </td><td></td><td>-</td><td></td><td> the stem ends with S (and similarly for the other letters).\n\n</td></tr><tr><td>*v* </td><td></td><td>-</td><td></td><td> the stem contains a vowel.\n\n</td></tr><tr><td>*d  </td><td></td><td>-</td><td></td><td> the stem ends with a double consonant (e.g. -TT, -SS).\n\n</td></tr><tr><td>*o  </td><td></td><td>-</td><td></td><td> the stem ends cvc, where the second c is not W, X or Y (e.g.\n       -WIL, -HOP).\n</td></tr></tbody></table></dd></dl>\nAnd the condition part may also contain expressions with <i>and</i>, <i>or</i> and\n<i>not</i>, so that\n<dl><dd>\n    (m&gt;1 and (*S or *T))\n</dd></dl>\ntests for a stem with m&gt;1 ending in S or T, while\n<dl><dd>\n    (*d and not (*L or *S or *Z))\n</dd></dl>\ntests for a stem ending with a double consonant other than L, S or Z.\nElaborate conditions like this are required only rarely.\n<br><br>\nIn a set of rules written beneath each other, only one is obeyed, and this\nwill be the one with the longest matching S1 for the given word. For\nexample, with\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>    SSES </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> SS\n</td></tr><tr><td>    IES  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> I\n</td></tr><tr><td>    SS   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> SS\n</td></tr><tr><td>    S    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>\n</td></tr></tbody></table></dd></dl>\n(here the conditions are all null) CARESSES maps to CARESS since SSES is\nthe longest match for S1. Equally CARESS maps to CARESS (S1=‘SS’) and CARES\nto CARE (S1=‘S’).\n<br><br>\nIn the rules below, examples of their application, successful or otherwise,\nare given on the right in lower case. The algorithm now follows:\n<br><br>\nStep 1a\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td> SSES </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> SS </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  caresses  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  caress\n</td></tr><tr><td> IES  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> I  </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  ponies    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  poni\n</td></tr><tr><td>      </td><td></td><td>     </td><td></td><td>    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  ties      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  ti\n</td></tr><tr><td> SS   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> SS </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  caress    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  caress\n</td></tr><tr><td> S    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  cats      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  cat\n</td></tr></tbody></table></dd></dl>\nStep 1b\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td> (m&gt;0) EED </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> EE </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> feed      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  feed\n</td></tr><tr><td>           </td><td></td><td>     </td><td></td><td>    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> agreed    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  agree\n</td></tr><tr><td> (*v*) ED  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> plastered </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  plaster\n</td></tr><tr><td>           </td><td></td><td>     </td><td></td><td>    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> bled      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  bled\n</td></tr><tr><td> (*v*) ING </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> motoring  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  motor\n</td></tr><tr><td>           </td><td></td><td>     </td><td></td><td>    </td><td></td><td>        </td><td></td><td> sing      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  sing\n</td></tr></tbody></table></dd></dl>\nIf the second or third of the rules in Step 1b is successful, the following\nis done:\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td> AT </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> ATE           </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> conflat(ed)  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  conflate\n</td></tr><tr><td> BL </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> BLE           </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> troubl(ed)   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  trouble\n</td></tr><tr><td> IZ </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> IZE           </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> siz(ed)      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  size\n</td></tr><tr><td> (*d and not (*L or *S or *Z))\n      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> single letter </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> hopp(ing)    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  hop\n</td></tr><tr><td>    </td><td></td><td>     </td><td></td><td>               </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> tann(ed)     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  tan\n</td></tr><tr><td>    </td><td></td><td>     </td><td></td><td>               </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> fall(ing)    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  fall\n</td></tr><tr><td>    </td><td></td><td>     </td><td></td><td>               </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> hiss(ing)    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  hiss\n</td></tr><tr><td>    </td><td></td><td>     </td><td></td><td>               </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> fizz(ed)     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  fizz\n</td></tr><tr><td> (m=1 and *o)\n      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> E             </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> fail(ing)    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  fail\n</td></tr><tr><td>    </td><td></td><td>     </td><td></td><td>               </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> fil(ing)     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  file\n</td></tr></tbody></table></dd></dl>\nThe rule to map to a single letter causes the removal of one of the double\nletter pair. The -E is put back on -AT, -BL and -IZ, so that the suffixes\n-ATE, -BLE and -IZE can be recognised later. This E may be removed in step\n4.\n<br><br>\nStep 1c\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>    (*v*) Y </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> I     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> happy        </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  happi\n</td></tr><tr><td>            </td><td></td><td>     </td><td></td><td>       </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> sky          </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  sky\n</td></tr></tbody></table></dd></dl>\nStep 1 deals with plurals and past participles. The subsequent steps are\nmuch more straightforward.\n<br><br>\nStep 2\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>    (m&gt;0) ATIONAL </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  ATE    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> relational     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  relate\n</td></tr><tr><td>    (m&gt;0) TIONAL  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  TION   </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> conditional    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  condition\n</td></tr><tr><td>                  </td><td></td><td>     </td><td></td><td>         </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> rational       </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  rational\n</td></tr><tr><td>    (m&gt;0) ENCI    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  ENCE   </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> valenci        </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  valence\n</td></tr><tr><td>    (m&gt;0) ANCI    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  ANCE   </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> hesitanci      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  hesitance\n</td></tr><tr><td>    (m&gt;0) IZER    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  IZE    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> digitizer      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  digitize\n</td></tr><tr><td>    (m&gt;0) ABLI    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  ABLE   </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> conformabli    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  conformable\n</td></tr><tr><td>    (m&gt;0) ALLI    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  AL     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> radicalli      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  radical\n</td></tr><tr><td>    (m&gt;0) ENTLI   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  ENT    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> differentli    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  different\n</td></tr><tr><td>    (m&gt;0) ELI     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  E      </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> vileli         </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  vile\n</td></tr><tr><td>    (m&gt;0) OUSLI   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  OUS    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> analogousli    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  analogous\n</td></tr><tr><td>    (m&gt;0) IZATION </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  IZE    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> vietnamization </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  vietnamize\n</td></tr><tr><td>    (m&gt;0) ATION   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  ATE    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> predication    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  predicate\n</td></tr><tr><td>    (m&gt;0) ATOR    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  ATE    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> operator       </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  operate\n</td></tr><tr><td>    (m&gt;0) ALISM   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  AL     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> feudalism      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  feudal\n</td></tr><tr><td>    (m&gt;0) IVENESS </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  IVE    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> decisiveness   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  decisive\n</td></tr><tr><td>    (m&gt;0) FULNESS </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  FUL    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> hopefulness    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  hopeful\n</td></tr><tr><td>    (m&gt;0) OUSNESS </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  OUS    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> callousness    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  callous\n</td></tr><tr><td>    (m&gt;0) ALITI   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  AL     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> formaliti      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  formal\n</td></tr><tr><td>    (m&gt;0) IVITI   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  IVE    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> sensitiviti    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  sensitive\n</td></tr><tr><td>    (m&gt;0) BILITI  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  BLE    </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> sensibiliti    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  sensible\n</td></tr></tbody></table></dd></dl>\nThe test for the string S1 can be made fast by doing a program switch on\nthe penultimate letter of the word being tested. This gives a fairly even\nbreakdown of the possible values of the string S1. It will be seen in fact\nthat the S1-strings in step 2 are presented here in the alphabetical order\nof their penultimate letter. Similar techniques may be applied in the other\nsteps.\n<br><br>\nStep 3\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>    (m&gt;0) ICATE </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  IC </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  triplicate     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  triplic\n</td></tr><tr><td>    (m&gt;0) ATIVE </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  formative      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  form\n</td></tr><tr><td>    (m&gt;0) ALIZE </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  AL </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  formalize      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  formal\n</td></tr><tr><td>    (m&gt;0) ICITI </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  IC </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  electriciti    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  electric\n</td></tr><tr><td>    (m&gt;0) ICAL  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  IC </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  electrical     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  electric\n</td></tr><tr><td>    (m&gt;0) FUL   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  hopeful        </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  hope\n</td></tr><tr><td>    (m&gt;0) NESS  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  goodness       </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  good\n</td></tr></tbody></table></dd></dl>\nStep 4\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>    (m&gt;1) AL    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  revival        </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  reviv\n</td></tr><tr><td>    (m&gt;1) ANCE  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  allowance      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  allow\n</td></tr><tr><td>    (m&gt;1) ENCE  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  inference      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  infer\n</td></tr><tr><td>    (m&gt;1) ER    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  airliner       </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  airlin\n</td></tr><tr><td>    (m&gt;1) IC    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  gyroscopic     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  gyroscop\n</td></tr><tr><td>    (m&gt;1) ABLE  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  adjustable     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  adjust\n</td></tr><tr><td>    (m&gt;1) IBLE  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  defensible     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  defens\n</td></tr><tr><td>    (m&gt;1) ANT   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  irritant       </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  irrit\n</td></tr><tr><td>    (m&gt;1) EMENT </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  replacement    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  replac\n</td></tr><tr><td>    (m&gt;1) MENT  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  adjustment     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  adjust\n</td></tr><tr><td>    (m&gt;1) ENT   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  dependent      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  depend\n</td></tr><tr><td>    (m&gt;1 and (*S or *T)) ION\n                  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  adoption       </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  adopt\n</td></tr><tr><td>    (m&gt;1) OU    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  homologou      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  homolog\n</td></tr><tr><td>    (m&gt;1) ISM   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  communism      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  commun\n</td></tr><tr><td>    (m&gt;1) ATE   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  activate       </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  activ\n</td></tr><tr><td>    (m&gt;1) ITI   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  angulariti     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  angular\n</td></tr><tr><td>    (m&gt;1) OUS   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  homologous     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  homolog\n</td></tr><tr><td>    (m&gt;1) IVE   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  effective      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  effect\n</td></tr><tr><td>    (m&gt;1) IZE   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>  bowdlerize     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  bowdler\n</td></tr></tbody></table></dd></dl>\nThe suffixes are now removed. All that remains is a little tidying up.\n<br><br>\nStep 5a\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>    (m&gt;1) E     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>       probate   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  probat\n</td></tr><tr><td>                </td><td></td><td>     </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>       rate      </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  rate\n</td></tr><tr><td>    (m=1 and not *o) E\n                  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>     </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td>       cease     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  ceas\n</td></tr></tbody></table></dd></dl>\nStep 5b\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>    (m &gt; 1 and *d and *L)\n                  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td> single letter </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> controll </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  control\n</td></tr><tr><td>                </td><td></td><td>     </td><td></td><td>               </td><td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td></td><td> roll     </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  roll\n</td></tr></tbody></table></dd></dl>\n</td></tr>\n\n<tr><td>\n<br><br>\n<b>Now, turning it into Snowball.</b>\n<br><br>\n\nThe Porter stemmer makes a use of a measure, <i>m</i>, of the length of a word or\nword part. If <i>C</i> is a sequence of one or more consonants, and <i>V</i> a sequence\nof one or more vowels, any word part has the form\n<dl><dd>\n    [<i>C</i>](<i>VC</i>)<sup><i>m</i></sup>[<i>V</i>],\n</dd></dl>\nwhich is to be read as an optional <i>C</i>, followed by <i>m</i> repetitions of <i>VC</i>,\nfollowed by an optional <i>V</i>. This defines <i>m</i>. So for <i>crepuscular</i> the\nmeasure would be 4.\n<br><pre>    c r e p u s c u l a r\n       |   |     |   |   |\n    [C] V C  V C  V C V C\n         1    2    3   4\n</pre>\nMost of the rules for suffix removal involve leaving behind a stem whose\nmeasure exceeds some value, for example,\n<dl><dd>\n    (<i>m</i> &gt; 0) <b><i>eed</i></b> <tt>-&gt;</tt> <b><i>ee</i></b>\n</dd></dl>\nmeans ‘replace <b><i>eed</i></b> with <b><i>ee</i></b> if the stem before <b><i>eed</i></b> has measure\n<i>m</i> &gt; 0’. Implementations of the Porter stemmer usually have a routine that\ncomputes <i>m</i> each time there is a possible candidate for removal.\n<br><br>\nIn fact the only tests on <i>m</i> in the Porter stemmer are <i>m</i> &gt; 0, <i>m</i> &gt; 1, and,\nat two interesting points, <i>m</i> = 1. This suggests that there are two\ncritical positions in a word: the point at which, going from left to\nright, <i>m</i> &gt; 0 becomes true, and then the point at which <i>m</i> &gt; 1 becomes true.\nIt turns out that <i>m</i> &gt; 0 becomes true at the point after the first consonant\nfollowing a vowel, and <i>m</i> &gt; 1 becomes true at the point after the first\nconsonant following a vowel following a consonant following a vowel.\nCalling these positions <i>p</i>1 and <i>p</i>2, we can determine them quite simply in\nSnowball:\n<br><pre>    define v 'aeiouy'\n\n    ....\n\n    do(\n        gopast v  gopast non-v  setmark p1\n        gopast v  gopast non-v  setmark p2\n    )\n</pre>\nThe region to the right of <i>p</i>1 will be denoted by <i>R</i>1, the region to the\nright of <i>p</i>2 by <i>R</i>2:\n<br><pre>    c r e p u s c u l a r\n           |   |\n           p1  p2\n           &lt;---  R1  ---&gt;\n               &lt;-- R2 --&gt;\n</pre>\nWe can test for being in these regions with calls to &nbsp;<tt>R1</tt>&nbsp; and &nbsp;<tt>R2</tt>, defined by,\n<br><pre>    define R1 as $p1 &lt;= cursor\n    define R2 as $p2 &lt;= cursor\n</pre>\nand using these tests instead of computing <i>m</i> is acceptable, so long as the\nstemming process never alters the <i>p</i>1 and <i>p</i>2 positions, which is indeed true\nin the Porter stemmer.\n<br><br>\nA particularly interesting feature of the stemmers presented here is the\ncommon use they make of the positions <i>p</i>1 and <i>p</i>2. The details of marking\n<i>p</i>1\nand <i>p</i>2 vary between the languages because the definitions of vowel and\nconsonant vary. For example, French <b><i>i</i></b> preceded and followed by vowel\nshould be treated as a consonant (<i>inqu<b><i>i</i></b>étude</i>); Portuguese (ã and <b><i>õ</i></b>\nshould be treated as a vowel-consonant pair (<i>São João</i>). A third\nimportant position is <i>pV</i>, which tries to mark the position of the shortest\nacceptable verb stem. Its definition varies somewhat between languages.\nThe Porter stemmer does not use a <i>pV</i> explicitly, but the idea appears when\nthe verb endings <b><i>ing</i></b> and <b><i>ed</i></b> are removed only when preceded by a vowel.\nIn English therefore <i>pV</i> would be defined as the position after the first\nvowel.\n<br><br>\nThe Porter stemmer is divided into five steps, step 1 is divided further\ninto steps 1<i>a</i>, 1<i>b</i> and 1<i>c</i>, and step 5 into steps 5<i>a</i> and 5<i>b</i>. Step 1 removes\nthe <i>i</i>-suffixes, and steps 2 to 4 the <i>d</i>-suffixes <a href=\"../../texts/glossary.html\">(*)</a>. Composite <i>d</i>-suffixes are\nreduced to single <i>d</i>-suffixes one at a time. So for example if a word ends\n<b><i>icational</i></b>, step 2 reduces it to <b><i>icate</i></b> and step 3 to <b><i>ic</i></b>. Three steps are\nsufficient for this process in English. Step 5 does some tidying up.\n<br><br>\nOne can see how easily the stemming rules translate into Snowball by\ncomparing the definition of Step 1<i>a</i> from the 1980 paper,\n<br><pre>    Step 1a:\n        SSES -&gt; SS                         caresses  -&gt;  caress\n        IES  -&gt; I                          ponies    -&gt;  poni\n                                           ties      -&gt;  ti\n        SS   -&gt; SS                         caress    -&gt;  caress\n        S    -&gt;                            cats      -&gt;  cat\n</pre>\nwith its Snowball equivalent,\n<br><pre>    define Step_1a as (\n        [substring] among (\n            'sses' (&lt;-'ss')\n            'ies'  (&lt;-'i')\n            'ss'   ()\n            's'    (delete)\n        )\n    )\n</pre>\nThe word to be stemmed is being scanned right to left from the end. The\nlongest of &nbsp;<tt>'sses'</tt>, &nbsp;<tt>'ies'</tt>, &nbsp;<tt>'ss'</tt>&nbsp; or &nbsp;<tt>'s'</tt>&nbsp; is searched for and defined as the\nslice. (If none are found, Step_1a signals <b><i>f</i></b>.) If &nbsp;<tt>'sses'</tt>&nbsp; is found, it is\nreplaced by &nbsp;<tt>'ss'</tt>, and so on. Of course, replacing &nbsp;<tt>'ss'</tt>&nbsp; by &nbsp;<tt>'ss'</tt>&nbsp; is a dummy\naction, so we can write\n<br><pre>            'ss'   ()\n</pre>\ninstead of\n<br><pre>            'ss'   (&lt;-'ss')\n</pre>\nRemember that &nbsp;<tt>delete</tt>&nbsp; just means &nbsp;<tt>&lt;- ''</tt>.\n<br><br>\nThe really tricky part of the whole algorithm is step 1<i>b</i>,\nwhich may be worth looking at in detail. Here it is, without the\nexample words on the far right,\n<br><pre>    Step 1b:\n        (m &gt; 0) EED -&gt; EE\n        (*v*)   ED  -&gt;\n        (*v*)   ING -&gt;\n\n    If the second or third of the rules in Step 1b is successful, the\n    following is done:\n\n        AT -&gt; ATE\n        BL -&gt; BLE\n        IZ -&gt; IZE\n        (*d and not (*L or *S or *Z)) -&gt; single letter\n        (m = 1 and *o) -&gt; E\n</pre>\nThe first part of the rule means that <b><i>eed</i></b> maps to <b><i>ee</i></b> if <b><i>eed</i></b> is in <i>R</i>1\n(which is equivalent to <i>m</i> &gt; 0), or <b><i>ed</i></b> and <b><i>ing</i></b> are removed if they are\npreceded by a vowel. In Snowball this is simply,\n<br><pre>    define Step_1b as (\n        [substring] among (\n            'eed'  (R1 &lt;-'ee')\n            'ed'\n            'ing'  (test gopast v  delete)\n        )\n    )\n</pre>\nBut this must be modified by the second part of the rule. <i>*d</i> indicates a\ntest for double letter consonant — <b><i>bb</i></b>, <b><i>dd</i></b> etc. <i>*L</i>, <i>*S</i>, <i>*Z</i> are tests\nfor <b><i>l</i></b>, <b><i>s</i></b>, <b><i>z</i></b>. <i>*o</i> is a short vowel test — it is matched by\nconsonant-vowel-consonant, where the consonant on the right is not <i>w</i>, <i>x</i>\nor <i>y</i>. If the short vowel test is satisfied, <i>m</i> = 1 is equivalent to the\ncursor being at <i>p</i>1. So the second part of the rule means, map <b><i>at</i></b>, <b><i>bl</i></b>, <b><i>iz</i></b>\nto <b><i>ate</i></b>, <b><i>ble</i></b>, <b><i>ize</i></b>; map certain double letters to single letters; and\nadd <b><i>e</i></b> after a short vowel in words of one syllable.\n<br><br>\nWe first need two extra groupings,\n<br><pre>    define v        'aeiouy'\n    define v_WXY    v + 'wxY'   // v with 'w', 'x' and 'y'-consonant\n    define v_LSZ    v + 'lsz'   // v with 'l', 's', 'z'\n</pre>\nand a test for a short vowel,\n<br><pre>    define shortv as ( non-v_WXY v non-v )\n</pre>\n(The &nbsp;<tt>v_WXY</tt>&nbsp; test comes first because we are scanning backwards, from right to\nleft.)\n<br><br>\nThe double to single letter map can be done as follows: first define the\nslice as the next &nbsp;<tt>non-v_LSZ</tt>&nbsp; and copy it to a string, &nbsp;<tt>ch</tt>, as a single\ncharacter,\n<br><pre>    strings ( ch )\n\n    ....\n\n    [non-v_LSZ] -&gt;ch\n</pre>\nA further test, &nbsp;<tt>ch</tt>, tests that the next letter of the string is the same\nas the one in &nbsp;<tt>ch</tt>, and if this gives signal <b><i>t</i></b>, &nbsp;<tt>delete</tt>&nbsp; deletes the slice,\n<br><pre>    [non-v_LSZ] -&gt;ch  ch  delete\n</pre>\n<tt>Step_1b</tt>&nbsp; can then be written like this,\n<br><pre>    define Step_1b as (\n        [substring] among (\n            'eed'  (R1 &lt;-'ee')\n            'ed'\n            'ing' (\n                test gopast v  delete\n                (test among('at' 'bl' 'iz')  &lt;+ 'e')\n                or\n                ([non-v_LSZ]-&gt;ch  ch  delete)\n                or\n                (atmark p1  test shortv  &lt;+ 'e')\n            )\n        )\n    )\n</pre>\nBut we can improve the appearance, and speed, of this by turning the\nsecond part of the rule into another &nbsp;<tt>among</tt>&nbsp; command, noting that the only\nletters that need undoubling are <b><i>b</i></b>, <b><i>d</i></b>, <b><i>f</i></b>, <b><i>g</i></b>, <b><i>m</i></b>, <b><i>n</i></b>, <b><i>p</i></b>, <b><i>r</i></b>\nand <b><i>t</i></b>,\n<br><pre>    define Step_1b as (\n        [substring] among (\n            'eed'  (R1 &lt;-'ee')\n            'ed'\n            'ing' (\n                test gopast v  delete\n                test substring among(\n                    'at' 'bl' 'iz'\n                         (&lt;+ 'e')\n                    'bb' 'dd' 'ff' 'gg' 'mm' 'nn' 'pp' 'rr' 'tt'\n                    // ignoring double c, h, j, k, q, v, w, and x\n                         ([next]  delete)\n                    ''   (atmark p1  test shortv  &lt;+ 'e')\n                )\n            )\n        )\n    )\n</pre>\nNote the null string in the second &nbsp;<tt>among</tt>, which acts as a default case.\n<br><br>\nThe Porter stemmer in Snowball is given below. This is an exact\nimplementation of the algorithm described in the 1980 paper, unlike the\nother implementations distributed by the author, which have, and have\nalways had, three small points of difference (clearly indicated) from the\noriginal algorithm. Since all other implementations of the algorithm seen\nby the author are in some degree inexact, this may well be the first ever\ncorrect implementation.\n<br><br>\n\n</td></tr>\n\n<tr><td bgcolor=\"lightblue\">\n<br>&nbsp;<h2>The full algorithm in Snowball</h2>\n\n<br><pre><dl><dd>\nintegers ( p1 p2 )\nbooleans ( Y_found )\n\nroutines (\n   shortv\n   R1 R2\n   Step_1a Step_1b Step_1c Step_2 Step_3 Step_4 Step_5a Step_5b\n)\n\nexternals ( stem )\n\ngroupings ( v v_WXY )\n\ndefine v        'aeiouy'\ndefine v_WXY    v + 'wxY'\n\nbackwardmode (\n\n    define shortv as ( non-v_WXY v non-v )\n\n    define R1 as $p1 &lt;= cursor\n    define R2 as $p2 &lt;= cursor\n\n    define Step_1a as (\n        [substring] among (\n            'sses' (&lt;-'ss')\n            'ies'  (&lt;-'i')\n            'ss'   ()\n            's'    (delete)\n        )\n    )\n\n    define Step_1b as (\n        [substring] among (\n            'eed'  (R1 &lt;-'ee')\n            'ed'\n            'ing' (\n                test gopast v  delete\n                test substring among(\n                    'at' 'bl' 'iz'\n                         (&lt;+ 'e')\n                    'bb' 'dd' 'ff' 'gg' 'mm' 'nn' 'pp' 'rr' 'tt'\n                    // ignoring double c, h, j, k, q, v, w, and x\n                         ([next]  delete)\n                    ''   (atmark p1  test shortv  &lt;+ 'e')\n                )\n            )\n        )\n    )\n\n    define Step_1c as (\n        ['y' or 'Y']\n        gopast v\n        &lt;-'i'\n    )\n\n    define Step_2 as (\n        [substring] R1 among (\n            'tional'  (&lt;-'tion')\n            'enci'    (&lt;-'ence')\n            'anci'    (&lt;-'ance')\n            'abli'    (&lt;-'able')\n            'entli'   (&lt;-'ent')\n            'eli'     (&lt;-'e')\n            'izer' 'ization'\n                      (&lt;-'ize')\n            'ational' 'ation' 'ator'\n                      (&lt;-'ate')\n            'alli'    (&lt;-'al')\n            'alism' 'aliti'\n                      (&lt;-'al')\n            'fulness' (&lt;-'ful')\n            'ousli' 'ousness'\n                      (&lt;-'ous')\n            'iveness' 'iviti'\n                      (&lt;-'ive')\n            'biliti'  (&lt;-'ble')\n        )\n    )\n\n    define Step_3 as (\n        [substring] R1 among (\n            'alize'   (&lt;-'al')\n            'icate' 'iciti' 'ical'\n                      (&lt;-'ic')\n            'ative' 'ful' 'ness'\n                      (delete)\n        )\n    )\n\n    define Step_4 as (\n        [substring] R2 among (\n            'al' 'ance' 'ence' 'er' 'ic' 'able' 'ible' 'ant' 'ement'\n            'ment' 'ent' 'ou' 'ism' 'ate' 'iti' 'ous' 'ive' 'ize'\n                      (delete)\n            'ion'     ('s' or 't' delete)\n        )\n    )\n\n    define Step_5a as (\n        ['e']\n        R2 or (R1 not shortv)\n        delete\n    )\n\n    define Step_5b as (\n        ['l']\n        R2 'l'\n        delete\n    )\n)\n\ndefine stem as (\n\n    unset Y_found\n    do ( ['y'] &lt;-'Y' set Y_found)\n    do repeat(goto (v ['y']) &lt;-'Y' set Y_found)\n\n    $p1 = limit\n    $p2 = limit\n    do(\n        gopast v  gopast non-v  setmark p1\n        gopast v  gopast non-v  setmark p2\n    )\n\n    backwards (\n        do Step_1a\n        do Step_1b\n        do Step_1c\n        do Step_2\n        do Step_3\n        do Step_4\n        do Step_5a\n        do Step_5b\n    )\n\n    do(Y_found  repeat(goto (['Y']) &lt;-'y'))\n\n)\n</dd></dl>\n</pre>\n</td></tr>\n\n</tbody></table>"
		}, {
			"id" : "6",
			"category" : "stemming",
			"title" : "French stemming algorithm",
			"body" : "<table width=\"75%\" align=\"CENTER\" cols=\"1\">\n\n\n<tbody><tr><td>\n<br>&nbsp;<h2>Links to resources</h2>\n\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td><a href=\"../..\"> Snowball main page</a>\n</td></tr><tr><td><a href=\"stem_ISO_8859_1.sbl\">    The stemmer in Snowball</a>\n</td></tr><tr><td><a href=\"stem.c\">      The ANSI C stemmer</a>\n</td></tr><tr><td><a href=\"stem.h\">      — and its header</a>\n</td></tr><tr><td><a href=\"voc.txt\">     Sample French vocabulary</a>\n</td></tr><tr><td><a href=\"output.txt\">  Its stemmed equivalent</a>\n</td></tr><tr><td><a href=\"diffs.txt\">   Vocabulary + stemmed equivalent in two columns</a>\n</td></tr><tr><td><a href=\"tarball.tgz\"> Tar-gzipped file of all of the above</a>\n<br><br>\n</td></tr><tr><td><a href=\"stop.txt\">    French stop word list</a>\n</td></tr></tbody></table></dd></dl>\n\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td><a href=\"stem_MS_DOS_Latin_I.sbl\">    The stemmer in Snowball — MS DOS Latin I encodings</a>\n</td></tr></tbody></table></dd></dl>\n\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td><a href=\"../../texts/romance.html\">\n                  Romance language stemmers</a>\n</td></tr></tbody></table></dd></dl>\n\n</td></tr>\n\n<tr><td bgcolor=\"lightpink\">\n\n<br><br>\n\nHere is a sample of French vocabulary, with the stemmed forms that will\nbe generated with this algorithm.\n\n<br><br>\n\n\n\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>  <b>word</b> </td>\n <td></td><td> </td>\n <td></td><td> <b>stem</b> </td>\n <td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>\n <td></td><td> <b>word</b> </td>\n <td></td><td> </td>\n <td></td><td> <b>stem</b> </td>\n</tr>\n\n<tr><td>\ncontinu<br>\ncontinua<br>\ncontinuait<br>\ncontinuant<br>\ncontinuation<br>\ncontinue<br>\ncontinué<br>\ncontinuel<br>\ncontinuelle<br>\ncontinuellement<br>\ncontinuelles<br>\ncontinuels<br>\ncontinuer<br>\ncontinuera<br>\ncontinuerait<br>\ncontinueront<br>\ncontinuez<br>\ncontinuité<br>\ncontinuons<br>\ncontorsions<br>\ncontour<br>\ncontournait<br>\ncontournant<br>\ncontourne<br>\ncontours<br>\ncontractait<br>\ncontracté<br>\ncontractée<br>\ncontracter<br>\ncontractés<br>\ncontractions<br>\ncontradictoirement<br>\ncontradictoires<br>\ncontraindre<br>\ncontraint<br>\ncontrainte<br>\ncontraintes<br>\ncontraire<br>\ncontraires<br>\ncontraria<br>\n</td>\n<td></td><td> &nbsp;<tt><b> =&gt; </b></tt>&nbsp; </td>\n<td></td><td>\ncontinu<br>\ncontinu<br>\ncontinu<br>\ncontinu<br>\ncontinu<br>\ncontinu<br>\ncontinu<br>\ncontinuel<br>\ncontinuel<br>\ncontinuel<br>\ncontinuel<br>\ncontinuel<br>\ncontinu<br>\ncontinu<br>\ncontinu<br>\ncontinu<br>\ncontinu<br>\ncontinu<br>\ncontinuon<br>\ncontors<br>\ncontour<br>\ncontourn<br>\ncontourn<br>\ncontourn<br>\ncontour<br>\ncontract<br>\ncontract<br>\ncontract<br>\ncontract<br>\ncontract<br>\ncontract<br>\ncontradictoir<br>\ncontradictoir<br>\ncontraindr<br>\ncontraint<br>\ncontraint<br>\ncontraint<br>\ncontrair<br>\ncontrair<br>\ncontrari<br>\n</td>\n<td></td><td> </td>\n<td></td><td>\nmain<br>\nmains<br>\nmaintenaient<br>\nmaintenait<br>\nmaintenant<br>\nmaintenir<br>\nmaintenue<br>\nmaintien<br>\nmaintint<br>\nmaire<br>\nmaires<br>\nmairie<br>\nmais<br>\nmaïs<br>\nmaison<br>\nmaisons<br>\nmaistre<br>\nmaitre<br>\nmaître<br>\nmaîtres<br>\nmaîtresse<br>\nmaîtresses<br>\nmajesté<br>\nmajestueuse<br>\nmajestueusement<br>\nmajestueux<br>\nmajeur<br>\nmajeure<br>\nmajor<br>\nmajordome<br>\nmajordomes<br>\nmajorité<br>\nmajorités<br>\nmal<br>\nmalacca<br>\nmalade<br>\nmalades<br>\nmaladie<br>\nmaladies<br>\nmaladive<br>\n</td>\n<td></td><td> &nbsp;<tt><b> =&gt; </b></tt>&nbsp; </td>\n<td></td><td>\nmain<br>\nmain<br>\nmainten<br>\nmainten<br>\nmainten<br>\nmainten<br>\nmaintenu<br>\nmaintien<br>\nmaintint<br>\nmair<br>\nmair<br>\nmair<br>\nmais<br>\nmaï<br>\nmaison<br>\nmaison<br>\nmaistr<br>\nmaitr<br>\nmaîtr<br>\nmaîtr<br>\nmaîtress<br>\nmaîtress<br>\nmajest<br>\nmajestu<br>\nmajestu<br>\nmajestu<br>\nmajeur<br>\nmajeur<br>\nmajor<br>\nmajordom<br>\nmajordom<br>\nmajor<br>\nmajor<br>\nmal<br>\nmalacc<br>\nmalad<br>\nmalad<br>\nmalad<br>\nmalad<br>\nmalad<br>\n</td>\n</tr>\n</tbody></table></dd></dl>\n\n\n</td></tr>\n\n<tr><td>\n\n<br><br>\n<br>&nbsp;<h2>The stemming algorithm</h2>\n\nLetters in French include the following accented forms,\n<dl><dd>\n    <b><i>â  &nbsp;  à  &nbsp;  ç  &nbsp;  ë  &nbsp;  é  &nbsp;  ê  &nbsp;  è  &nbsp;  ï  &nbsp;  î  &nbsp;  ô  &nbsp;  û  &nbsp;  ù</i></b>\n</dd></dl>\nThe following letters are vowels:\n<dl><dd>\n    <b><i>a  &nbsp;  e  &nbsp;  i  &nbsp;  o  &nbsp;  u  &nbsp;  y  &nbsp;  â  &nbsp;  à  &nbsp;  ë  &nbsp;  é  &nbsp;  ê  &nbsp;  è  &nbsp;  ï  &nbsp;  î  &nbsp;  ô  &nbsp;  û  &nbsp;  ù</i></b>\n</dd></dl>\nAssume the word is in lower case. Then put into upper case <b><i>u</i></b> or <b><i>i</i></b> preceded\nand followed by a vowel, and <b><i>y</i></b> preceded or followed by a vowel. <b><i>u</i></b> after <b><i>q</i></b> is\nalso put into upper case. For example,\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>    jouer   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  joUer\n</td></tr><tr><td>    ennuie  </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  ennuIe\n</td></tr><tr><td>    yeux    </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  Yeux\n</td></tr><tr><td>    quand   </td><td></td><td> <tt>-&gt;</tt> </td><td></td><td>  qUand\n</td></tr></tbody></table></dd></dl>\n(The upper case forms are not then classed as vowels — see <a href=\"../../texts/vowelmarking.html\"> note</a> on vowel\nmarking.)\n<br><br>\nIf the word begins with two vowels, <i>RV</i> is the region after the third\nletter, otherwise the region after the first vowel not at the beginning of\nthe word, or the end of the word if these positions cannot be found. (Exceptionally,\n<b><i>par</i></b>, <b><i>col</i></b> or <b><i>tap</i></b>, at the begining of a word is also taken to define\n<i>RV</i> as the region to their right.)\n<br><br>\nFor example,\n<br><pre>    a i m e r     a d o r e r     v o l e r    t a p i s\n         |...|         |.....|       |.....|        |...|\n</pre>\n<i>R</i>1 is the region after the first non-vowel following a vowel, or the end of\nthe word if there is no such non-vowel.\n\n<i>R</i>2 is the region after the first non-vowel following a vowel in <i>R</i>1, or the\nend of the word if there is no such non-vowel.\n(See <a href=\"../../texts/r1r2.html\"> note</a> on <i>R</i>1 and <i>R</i>2.)\n<br><br>\nFor example:\n<br><pre>    f a m e u s e m e n t\n         |......R1.......|\n               |...R2....|\n</pre>\nNote that <i>R</i>1 can contain <i>RV</i> (<i>adorer</i>), and <i>RV</i> can contain <i>R</i>1 (<i>voler</i>).\n<br><br>\nBelow, ‘delete if in <i>R</i>2’ means that a found suffix should be removed if it\nlies entirely in <i>R</i>2, but not if it overlaps <i>R</i>2 and the rest of the word.\n‘delete if in <i>R</i>1 and preceded by <i>X</i>’ means that <i>X</i> itself does not have to\ncome in <i>R</i>1, while ‘delete if preceded by <i>X</i> in <i>R</i>1’ means that <i>X</i>, like the\nsuffix, must be entirely in <i>R</i>1.\n<br><br>\nStart with step 1\n<br><br>\nStep 1: Standard suffix removal\n<dl><dd>\n    Search for the longest among the following suffixes, and perform the\n    action indicated.\n<br><br>\n<dl>\n    <dt><b><i>ance  &nbsp;  iqUe  &nbsp;  isme  &nbsp;  able  &nbsp;  iste  &nbsp;  eux  &nbsp;  ances  &nbsp;  iqUes  &nbsp;  ismes  &nbsp;  ables  &nbsp;  istes</i></b>\n        </dt><dd>delete if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>atrice  &nbsp;  ateur  &nbsp;  ation  &nbsp;  atrices  &nbsp;  ateurs  &nbsp;  ations</i></b>\n        </dt><dd>delete if in <i>R</i>2\n        </dd><dd>if preceded by <b><i>ic</i></b>, delete if in <i>R</i>2, else replace by <b><i>iqU</i></b>\n<br><br>\n    </dd><dt><b><i>logie  &nbsp;  logies</i></b>\n        </dt><dd>replace with <b><i>log</i></b> if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>usion  &nbsp;  ution  &nbsp;  usions  &nbsp;  utions</i></b>\n        </dt><dd>replace with <b><i>u</i></b> if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>ence  &nbsp;  ences</i></b>\n        </dt><dd>replace with <b><i>ent</i></b> if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>ement  &nbsp;  ements</i></b>\n        </dt><dd>delete if in <i>RV</i>\n        </dd><dd>if preceded by <b><i>iv</i></b>, delete if in <i>R</i>2 (and if further preceded by <b><i>at</i></b>,\n        delete if in <i>R</i>2), otherwise,\n        </dd><dd>if preceded by <b><i>eus</i></b>, delete if in <i>R</i>2, else replace by <b><i>eux</i></b>\n          if in <i>R</i>1, otherwise,\n        </dd><dd>if preceded by <b><i>abl</i></b> or <b><i>iqU</i></b>, delete if in <i>R</i>2, otherwise,\n        </dd><dd>if preceded by <b><i>ièr</i></b> or <b><i>Ièr</i></b>, replace by <b><i>i</i></b> if in <i>RV</i>\n<br><br>\n    </dd><dt><b><i>ité  &nbsp;  ités</i></b>\n        </dt><dd>delete if in <i>R</i>2\n        </dd><dd>if preceded by <b><i>abil</i></b>, delete if in <i>R</i>2, else replace by <b><i>abl</i></b>,\n        otherwise,\n        </dd><dd>if preceded by <b><i>ic</i></b>, delete if in <i>R</i>2, else replace by <b><i>iqU</i></b>, otherwise,\n        </dd><dd>if preceded by <b><i>iv</i></b>, delete if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>if  &nbsp;  ive  &nbsp;  ifs  &nbsp;  ives</i></b>\n        </dt><dd>delete if in <i>R</i>2\n        </dd><dd>if preceded by <b><i>at</i></b>, delete if in <i>R</i>2 (and if further preceded by <b><i>ic</i></b>,\n        delete if in <i>R</i>2, else replace by <b><i>iqU</i></b>)\n<br><br>\n    </dd><dt><b><i>eaux</i></b>\n        </dt><dd>replace with <b><i>eau</i></b>\n<br><br>\n    </dd><dt><b><i>aux</i></b>\n        </dt><dd>replace with <b><i>al</i></b> if in <i>R</i>1\n<br><br>\n    </dd><dt><b><i>euse  &nbsp;  euses</i></b>\n        </dt><dd>delete if in <i>R</i>2, else replace by <b><i>eux</i></b> if in <i>R</i>1\n<br><br>\n    </dd><dt><b><i>issement  &nbsp;  issements</i></b>\n        </dt><dd>delete if in <i>R</i>1 and preceded by a non-vowel\n<br><br>\n    </dd><dt><b><i>amment</i></b>\n        </dt><dd>replace with <b><i>ant</i></b> if in <i>RV</i>\n<br><br>\n    </dd><dt><b><i>emment</i></b>\n        </dt><dd>replace with <b><i>ent</i></b> if in <i>RV</i>\n<br><br>\n    </dd><dt><b><i>ment  &nbsp;  ments</i></b>\n        </dt><dd>delete if preceded by a vowel in <i>RV</i>\n</dd></dl>\n</dd></dl>\n\nIn steps 2<i>a</i> and 2<i>b</i> all tests are confined to the <i>RV</i> region.\n<br><br>\nDo step 2<i>a</i> if either no ending was removed by step 1, or if one of endings\n<b><i>amment</i></b>, <b><i>emment</i></b>, <b><i>ment</i></b>, <b><i>ments</i></b> was found.\n<br><br>\nStep 2<i>a</i>: Verb suffixes beginning <b><i>i</i></b>\n<dl><dd>\n    Search for the longest among the following suffixes and if found,\n    delete if preceded by a non-vowel.\n<br><br>\n<dl><dd>\n        <b><i>îmes  &nbsp;  ît  &nbsp;  îtes  &nbsp;  i  &nbsp;  ie  &nbsp;  ies  &nbsp;  ir  &nbsp;  ira  &nbsp;  irai  &nbsp;  iraIent  &nbsp;  irais  &nbsp;  irait  &nbsp;  iras\n         &nbsp;  irent  &nbsp;  irez  &nbsp;  iriez  &nbsp;  irions  &nbsp;  irons  &nbsp;  iront  &nbsp;  is  &nbsp;  issaIent  &nbsp;  issais  &nbsp;  issait\n         &nbsp;  issant  &nbsp;  issante  &nbsp;  issantes  &nbsp;  issants  &nbsp;  isse  &nbsp;  issent  &nbsp;  isses  &nbsp;  issez  &nbsp;  issiez\n         &nbsp;  issions  &nbsp;  issons  &nbsp;  it</i></b>\n</dd></dl>\n<br>\n    (Note that the non-vowel itself must also be in <i>RV</i>.)\n</dd></dl>\nDo step 2<i>b</i> if step 2<i>a</i> was done, but failed to remove a suffix.\n<br><br>\nStep 2<i>b</i>: Other verb suffixes\n<dl><dd>\n    Search for the longest among the following suffixes, and perform the\n    action indicated.\n<br><br>\n<dl>\n    <dt><b><i>ions</i></b>\n        </dt><dd>delete if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>é  &nbsp;  ée  &nbsp;  ées  &nbsp;  és  &nbsp;  èrent  &nbsp;  er  &nbsp;  era  &nbsp;  erai  &nbsp;  eraIent  &nbsp;  erais  &nbsp;  erait  &nbsp;  eras  &nbsp;  erez\n     &nbsp;  eriez  &nbsp;  erions  &nbsp;  erons  &nbsp;  eront  &nbsp;  ez  &nbsp;  iez</i></b>\n        </dt><dd>delete\n<br><br>\n    </dd><dt><b><i>âmes  &nbsp;  ât  &nbsp;  âtes  &nbsp;  a  &nbsp;  ai  &nbsp;  aIent  &nbsp;  ais  &nbsp;  ait  &nbsp;  ant  &nbsp;  ante  &nbsp;  antes  &nbsp;  ants  &nbsp;  as  &nbsp;  asse\n     &nbsp;  assent  &nbsp;  asses  &nbsp;  assiez  &nbsp;  assions</i></b>\n        </dt><dd>delete\n        </dd><dd>if preceded by <b><i>e</i></b>, delete\n</dd></dl>\n<br>\n    (Note that the <b><i>e</i></b> that may be deleted in this last step must also be in\n    <i>RV</i>.)\n</dd></dl>\nIf the last step to be obeyed — either step 1, 2<i>a</i> or 2<i>b</i> — altered the word,\ndo step 3\n<br><br>\nStep 3\n<dl><dd>\n    Replace final <b><i>Y</i></b> with <b><i>i</i></b> or final <b><i>ç</i></b> with <b><i>c</i></b>\n</dd></dl>\nAlternatively, if the last step to be obeyed did not alter the word, do\nstep 4\n<br><br>\nStep 4: Residual suffix\n<dl><dd>\n    If the word ends <b><i>s</i></b>, not preceded by <b><i>a</i></b>, <b><i>i</i></b>, <b><i>o</i></b>, <b><i>u</i></b>, <b><i>è</i></b> or <b><i>s</i></b>, delete it.\n<br><br>\n    In the rest of step 4, all tests are confined to the <i>RV</i> region.\n<br><br>\n    Search for the longest among the following suffixes, and perform the\n    action indicated.\n<br><br>\n<dl>\n    <dt><b><i>ion</i></b>\n        </dt><dd>delete if in <i>R</i>2 and preceded by <b><i>s</i></b> or <b><i>t</i></b>\n<br><br>\n    </dd><dt><b><i>ier  &nbsp;  ière  &nbsp;  Ier  &nbsp;  Ière</i></b>\n        </dt><dd>replace with <b><i>i</i></b>\n<br><br>\n    </dd><dt><b><i>e</i></b>\n        </dt><dd>delete\n<br><br>\n    </dd><dt><b><i>ë</i></b>\n        </dt><dd>if preceded by <b><i>gu</i></b>, delete\n</dd></dl>\n<br>\n    (So note that <b><i>ion</i></b> is removed only when it is in <i>R</i>2 — as well as being\n    in <i>RV</i> — and preceded by <b><i>s</i></b> or <b><i>t</i></b> which must be in <i>RV</i>.)\n</dd></dl>\nAlways do steps 5 and 6.\n<br><br>\nStep 5: Undouble\n<dl><dd>\n    If the word ends <b><i>enn</i></b>, <b><i>onn</i></b>, <b><i>ett</i></b>, <b><i>ell</i></b> or <b><i>eill</i></b>, delete the last letter\n</dd></dl>\nStep 6: Un-accent\n<dl><dd>\n    If the words ends <b><i>é</i></b> or <b><i>è</i></b> followed by at least one non-vowel, remove\n    the accent from the <b><i>e</i></b>.\n</dd></dl>\nAnd finally:\n<dl><dd>\n    Turn any remaining <b><i>I</i></b>, <b><i>U</i></b> and <b><i>Y</i></b> letters in the word back into lower case.\n</dd></dl>\n\n\n</td></tr>\n\n<tr><td bgcolor=\"lightblue\">\n\n<br>&nbsp;<h2>The same algorithm in Snowball</h2>\n\n<br><pre><dl><dd>\nroutines (\n           prelude postlude mark_regions\n           RV R1 R2\n           standard_suffix\n           i_verb_suffix\n           verb_suffix\n           residual_suffix\n           un_double\n           un_accent\n)\n\nexternals ( stem )\n\nintegers ( pV p1 p2 )\n\ngroupings ( v keep_with_s )\n\nstringescapes {}\n\n/* special characters (in ISO Latin I) */\n\nstringdef a^   hex 'E2'  // a-circumflex\nstringdef a`   hex 'E0'  // a-grave\nstringdef c,   hex 'E7'  // c-cedilla\n\nstringdef e\"   hex 'EB'  // e-diaeresis (rare)\nstringdef e'   hex 'E9'  // e-acute\nstringdef e^   hex 'EA'  // e-circumflex\nstringdef e`   hex 'E8'  // e-grave\nstringdef i\"   hex 'EF'  // i-diaeresis\nstringdef i^   hex 'EE'  // i-circumflex\nstringdef o^   hex 'F4'  // o-circumflex\nstringdef u^   hex 'FB'  // u-circumflex\nstringdef u`   hex 'F9'  // u-grave\n\ndefine v 'aeiouy{a^}{a`}{e\"}{e'}{e^}{e`}{i\"}{i^}{o^}{u^}{u`}'\n\ndefine prelude as repeat goto (\n\n    (  v [ ('u' ] v &lt;- 'U') or\n           ('i' ] v &lt;- 'I') or\n           ('y' ] &lt;- 'Y')\n    )\n    or\n    (  ['y'] v &lt;- 'Y' )\n    or\n    (  'q' ['u'] &lt;- 'U' )\n)\n\ndefine mark_regions as (\n\n    $pV = limit\n    $p1 = limit\n    $p2 = limit  // defaults\n\n    do (\n        ( v v next )\n        or\n        among ( // this exception list begun Nov 2006\n            'par'  // paris, parie, pari\n            'col'  // colis\n            'tap'  // tapis\n            // extensions possible here\n        )\n        or\n        ( next gopast v )\n        setmark pV\n    )\n    do (\n        gopast v gopast non-v setmark p1\n        gopast v gopast non-v setmark p2\n    )\n)\n\ndefine postlude as repeat (\n\n    [substring] among(\n        'I' (&lt;- 'i')\n        'U' (&lt;- 'u')\n        'Y' (&lt;- 'y')\n        ''  (next)\n    )\n)\n\nbackwardmode (\n\n    define RV as $pV &lt;= cursor\n    define R1 as $p1 &lt;= cursor\n    define R2 as $p2 &lt;= cursor\n\n    define standard_suffix as (\n        [substring] among(\n\n            'ance' 'iqUe' 'isme' 'able' 'iste' 'eux'\n            'ances' 'iqUes' 'ismes' 'ables' 'istes'\n               ( R2 delete )\n            'atrice' 'ateur' 'ation'\n            'atrices' 'ateurs' 'ations'\n               ( R2 delete\n                 try ( ['ic'] (R2 delete) or &lt;-'iqU' )\n               )\n            'logie'\n            'logies'\n               ( R2 &lt;- 'log' )\n            'usion' 'ution'\n            'usions' 'utions'\n               ( R2 &lt;- 'u' )\n            'ence'\n            'ences'\n               ( R2 &lt;- 'ent' )\n            'ement'\n            'ements'\n            (\n                RV delete\n                try (\n                    [substring] among(\n                        'iv'   (R2 delete ['at'] R2 delete)\n                        'eus'  ((R2 delete) or (R1&lt;-'eux'))\n                        'abl' 'iqU'\n                               (R2 delete)\n                        'i{e`}r' 'I{e`}r'      //)\n                               (RV &lt;-'i')      //)--new 2 Sept 02\n                    )\n                )\n            )\n            'it{e'}'\n            'it{e'}s'\n            (\n                R2 delete\n                try (\n                    [substring] among(\n                        'abil' ((R2 delete) or &lt;-'abl')\n                        'ic'   ((R2 delete) or &lt;-'iqU')\n                        'iv'   (R2 delete)\n                    )\n                )\n            )\n            'if' 'ive'\n            'ifs' 'ives'\n            (\n                R2 delete\n                try ( ['at'] R2 delete ['ic'] (R2 delete) or &lt;-'iqU' )\n            )\n            'eaux' (&lt;- 'eau')\n            'aux'  (R1 &lt;- 'al')\n            'euse'\n            'euses'((R2 delete) or (R1&lt;-'eux'))\n\n            'issement'\n            'issements'(R1 non-v delete) // verbal\n\n            // fail(...) below forces entry to verb_suffix. -ment typically\n            // follows the p.p., e.g 'confus{e'}ment'.\n\n            'amment'   (RV fail(&lt;- 'ant'))\n            'emment'   (RV fail(&lt;- 'ent'))\n            'ment'\n            'ments'    (test(v RV) fail(delete))\n                       // v is e,i,u,{e'},I or U\n        )\n    )\n\n    define i_verb_suffix as setlimit tomark pV for (\n        [substring] among (\n            '{i^}mes' '{i^}t' '{i^}tes' 'i' 'ie' 'ies' 'ir' 'ira' 'irai'\n            'iraIent' 'irais' 'irait' 'iras' 'irent' 'irez' 'iriez'\n            'irions' 'irons' 'iront' 'is' 'issaIent' 'issais' 'issait'\n            'issant' 'issante' 'issantes' 'issants' 'isse' 'issent' 'isses'\n            'issez' 'issiez' 'issions' 'issons' 'it'\n                (non-v delete)\n        )\n    )\n\n    define verb_suffix as setlimit tomark pV for (\n        [substring] among (\n            'ions'\n                (R2 delete)\n\n            '{e'}' '{e'}e' '{e'}es' '{e'}s' '{e`}rent' 'er' 'era' 'erai'\n            'eraIent' 'erais' 'erait' 'eras' 'erez' 'eriez' 'erions'\n            'erons' 'eront' 'ez' 'iez'\n\n            // 'ons' //-best omitted\n\n                (delete)\n\n            '{a^}mes' '{a^}t' '{a^}tes' 'a' 'ai' 'aIent' 'ais' 'ait' 'ant'\n            'ante' 'antes' 'ants' 'as' 'asse' 'assent' 'asses' 'assiez'\n            'assions'\n                (delete\n                 try(['e'] delete)\n                )\n        )\n    )\n\n    define keep_with_s 'aiou{e`}s'\n\n    define residual_suffix as (\n        try(['s'] test non-keep_with_s delete)\n        setlimit tomark pV for (\n            [substring] among(\n                'ion'           (R2 's' or 't' delete)\n                'ier' 'i{e`}re'\n                'Ier' 'I{e`}re' (&lt;-'i')\n                'e'             (delete)\n                '{e\"}'          ('gu' delete)\n            )\n        )\n    )\n\n    define un_double as (\n        test among('enn' 'onn' 'ett' 'ell' 'eill') [next] delete\n    )\n\n    define un_accent as (\n        atleast 1 non-v\n        [ '{e'}' or '{e`}' ] &lt;-'e'\n    )\n)\n\ndefine stem as (\n\n    do prelude\n    do mark_regions\n    backwards (\n\n        do (\n            (\n                 ( standard_suffix or\n                   i_verb_suffix or\n                   verb_suffix\n                 )\n                 and\n                 try( [ ('Y'   ] &lt;- 'i' ) or\n                        ('{c,}'] &lt;- 'c' )\n                 )\n            ) or\n            residual_suffix\n        )\n\n        // try(['ent'] RV delete) // is best omitted\n\n        do un_double\n        do un_accent\n    )\n    do postlude\n)\n\n</dd></dl>\n</pre>\n</td></tr></tbody></table>"
		}, {
			"id" : "7",
			"category" : "stemming",
			"title" : "Spanish stemming algorithm",
			"body" : "<table width=\"75%\" align=\"CENTER\" cols=\"1\">\n\n\n<tbody><tr><td>\n<br>&nbsp;<h2>Links to resources</h2>\n\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td><a href=\"../..\"> Snowball main page</a>\n</td></tr><tr><td><a href=\"stem_ISO_8859_1.sbl\">    The stemmer in Snowball</a>\n</td></tr><tr><td><a href=\"stem.c\">      The ANSI C stemmer</a>\n</td></tr><tr><td><a href=\"stem.h\">      — and its header</a>\n</td></tr><tr><td><a href=\"voc.txt\">     Sample Spanish vocabulary</a>\n</td></tr><tr><td><a href=\"output.txt\">  Its stemmed equivalent</a>\n</td></tr><tr><td><a href=\"diffs.txt\">   Vocabulary + stemmed equivalent in two columns</a>\n</td></tr><tr><td><a href=\"tarball.tgz\"> Tar-gzipped file of all of the above</a>\n<br><br>\n</td></tr><tr><td><a href=\"stop.txt\">    Spanish stop word list</a>\n</td></tr></tbody></table></dd></dl>\n\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td><a href=\"stem_MS_DOS_Latin_I.sbl\">    The stemmer in Snowball — MS DOS Latin I encodings</a>\n</td></tr></tbody></table></dd></dl>\n\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td><a href=\"../../texts/romance.html\">\n                  Romance language stemmers</a>\n</td></tr></tbody></table></dd></dl>\n\n</td></tr>\n\n<tr><td bgcolor=\"lightpink\">\n\n<br><br>\n\nHere is a sample of Spanish vocabulary, with the stemmed forms that will\nbe generated with this algorithm.\n\n<br><br>\n\n\n\n<dl><dd><table cellpadding=\"0\">\n<tbody><tr><td>  <b>word</b> </td>\n <td></td><td> </td>\n <td></td><td> <b>stem</b> </td>\n <td></td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>\n <td></td><td> <b>word</b> </td>\n <td></td><td> </td>\n <td></td><td> <b>stem</b> </td>\n</tr>\n\n<tr><td>\nche<br>\ncheca<br>\nchecar<br>\ncheco<br>\nchecoslovaquia<br>\nchedraoui<br>\nchefs<br>\ncheliabinsk<br>\nchelo<br>\nchemical<br>\nchemicalweek<br>\nchemise<br>\nchepo<br>\ncheque<br>\nchequeo<br>\ncheques<br>\ncheraw<br>\nchesca<br>\nchester<br>\nchetumal<br>\nchetumaleños<br>\nchevrolet<br>\ncheyene<br>\ncheyenne<br>\nchi<br>\nchía<br>\nchiapaneca<br>\nchiapas<br>\nchiba<br>\nchic<br>\nchica<br>\nchicago<br>\nchicana<br>\nchicano<br>\nchicas<br>\nchicharrones<br>\nchichen<br>\nchichimecas<br>\nchicles<br>\nchico<br>\n</td>\n<td></td><td> &nbsp;<tt><b> =&gt; </b></tt>&nbsp; </td>\n<td></td><td>\nche<br>\nchec<br>\nchec<br>\nchec<br>\nchecoslovaqui<br>\nchedraoui<br>\nchefs<br>\ncheliabinsk<br>\nchel<br>\nchemical<br>\nchemicalweek<br>\nchemis<br>\nchep<br>\nchequ<br>\ncheque<br>\nchequ<br>\ncheraw<br>\nchesc<br>\nchest<br>\nchetumal<br>\nchetumaleñ<br>\nchevrolet<br>\ncheyen<br>\ncheyenn<br>\nchi<br>\nchi<br>\nchiapanec<br>\nchiap<br>\nchib<br>\nchic<br>\nchic<br>\nchicag<br>\nchican<br>\nchican<br>\nchic<br>\nchicharron<br>\nchich<br>\nchichimec<br>\nchicl<br>\nchic<br>\n</td>\n<td></td><td> </td>\n<td></td><td>\ntorá<br>\ntórax<br>\ntorcer<br>\ntoreado<br>\ntoreados<br>\ntoreándolo<br>\ntorear<br>\ntoreara<br>\ntorearlo<br>\ntoreó<br>\ntorero<br>\ntoreros<br>\ntorio<br>\ntormenta<br>\ntormentas<br>\ntornado<br>\ntornados<br>\ntornar<br>\ntornen<br>\ntorneo<br>\ntorneos<br>\ntornillo<br>\ntornillos<br>\ntorniquete<br>\ntorno<br>\ntoro<br>\ntoronto<br>\ntoros<br>\ntorpedearon<br>\ntorpeza<br>\ntorrado<br>\ntorralba<br>\ntorre<br>\ntorrencial<br>\ntorrenciales<br>\ntorrente<br>\ntorreon<br>\ntorreón<br>\ntorres<br>\ntorrescano<br>\n</td>\n<td></td><td> &nbsp;<tt><b> =&gt; </b></tt>&nbsp; </td>\n<td></td><td>\ntor<br>\ntorax<br>\ntorc<br>\ntor<br>\ntor<br>\ntor<br>\ntor<br>\ntor<br>\ntor<br>\ntore<br>\ntorer<br>\ntorer<br>\ntori<br>\ntorment<br>\ntorment<br>\ntorn<br>\ntorn<br>\ntorn<br>\ntorn<br>\ntorne<br>\ntorne<br>\ntornill<br>\ntornill<br>\ntorniquet<br>\ntorn<br>\ntor<br>\ntoront<br>\ntor<br>\ntorped<br>\ntorpez<br>\ntorr<br>\ntorralb<br>\ntorr<br>\ntorrencial<br>\ntorrencial<br>\ntorrent<br>\ntorreon<br>\ntorreon<br>\ntorr<br>\ntorrescan<br>\n</td>\n</tr>\n</tbody></table></dd></dl>\n\n\n</td></tr>\n\n<tr><td>\n\n<br><br>\n<br>&nbsp;<h2>The stemming algorithm</h2>\n\nLetters in Spanish include the following accented forms,\n<dl><dd>\n    <b><i>á  &nbsp;  é  &nbsp;  í  &nbsp;  ó  &nbsp;  ú  &nbsp;  ü  &nbsp;  ñ</i></b>\n</dd></dl>\nThe following letters are vowels:\n<dl><dd>\n    <b><i>a  &nbsp;  e  &nbsp;  i  &nbsp;  o  &nbsp;  u  &nbsp;  á  &nbsp;  é  &nbsp;  í  &nbsp;  ó  &nbsp;  ú  &nbsp;  ü</i></b>\n</dd></dl>\n<i>R</i>2 is defined in the usual way —\nsee the <a href=\"../../texts/r1r2.html\"> note</a> on <i>R</i>1 and <i>R</i>2.\n<br><br>\n<i>RV</i> is defined as follows (and this is not the same as the\n <a href=\"../french/stemmer.html\">French stemmer</a>\ndefinition):\n<br><br>\nIf the second letter is a consonant, <i>RV</i> is the region after the next\nfollowing vowel, or if the first two letters are vowels, <i>RV</i> is the region\nafter the next consonant, and otherwise (consonant-vowel case) <i>RV</i> is the\nregion after the third letter. But <i>RV</i> is the end of the word if these\npositions cannot be found.\n<br><br>\nFor example,\n<br><pre>    m a c h o     o l i v a     t r a b a j o     á u r e o\n         |...|         |...|         |.......|         |...|\n</pre>\nAlways do steps 0 and 1.\n<br><br>\nStep 0: Attached pronoun\n<dl><dd>\n    Search for the longest among the following suffixes\n<br><br><dl><dd>\n        <b><i>me  &nbsp;  se  &nbsp;  sela  &nbsp;  selo  &nbsp;  selas  &nbsp;  selos  &nbsp;  la  &nbsp;  le  &nbsp;  lo  &nbsp;  las  &nbsp;  les  &nbsp;  los  &nbsp;  nos</i></b>\n</dd></dl><br>\n    and delete it, if comes after one of\n<br><br><dl><dd>\n        (<i>a</i>) <b><i>iéndo  &nbsp;  ándo  &nbsp;  ár  &nbsp;  ér  &nbsp;  ír</i></b><br>\n        (<i>b</i>) <b><i>ando  &nbsp;  iendo  &nbsp;  ar  &nbsp;  er  &nbsp;  ir</i></b><br>\n        (<i>c</i>) <b><i>yendo</i></b> following <b><i>u</i></b>\n</dd></dl><br>\n    in <i>RV</i>. In the case of (<i>c</i>), <b><i>yendo</i></b> must lie in <i>RV</i>, but the preceding\n    <b><i>u</i></b> can be outside it.\n<br><br>\n    In the case of (<i>a</i>), deletion is followed by removing the acute accent\n    (for example, <i>haciéndola</i> <tt>-&gt;</tt> <i>haciendo</i>).\n</dd></dl>\nStep 1: Standard suffix removal\n<dl><dd>\n    Search for the longest among the following suffixes, and perform the\n    action indicated.\n<br><br>\n<dl>\n    <dt><b><i>anza  &nbsp;  anzas  &nbsp;  ico  &nbsp;  ica  &nbsp;  icos  &nbsp;  icas  &nbsp;  ismo  &nbsp;  ismos  &nbsp;  able  &nbsp;  ables  &nbsp;  ible  &nbsp;  ibles  &nbsp;  ista\n     &nbsp;  istas  &nbsp;  oso  &nbsp;  osa  &nbsp;  osos  &nbsp;  osas  &nbsp;  amiento  &nbsp;  amientos  &nbsp;  imiento  &nbsp;\n    imientos</i></b>\n        </dt><dd>delete if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>adora  &nbsp;  ador  &nbsp;  ación  &nbsp;  adoras  &nbsp;  adores  &nbsp;  aciones  &nbsp;  ante  &nbsp;  antes  &nbsp;  ancia  &nbsp;  ancias</i></b>\n        </dt><dd>delete if in <i>R</i>2\n        </dd><dd>if preceded by <b><i>ic</i></b>, delete if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>logía  &nbsp;  logías</i></b>\n        </dt><dd>replace with <b><i>log</i></b> if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>ución  &nbsp;  uciones</i></b>\n        </dt><dd>replace with <b><i>u</i></b> if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>encia  &nbsp;  encias</i></b>\n        </dt><dd>replace with <b><i>ente</i></b> if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>amente</i></b>\n        </dt><dd>delete if in <i>R</i>1\n        </dd><dd>if preceded by <b><i>iv</i></b>, delete if in <i>R</i>2 (and if further preceded by <b><i>at</i></b>,\n        delete if in <i>R</i>2), otherwise,\n        </dd><dd>if preceded by <b><i>os</i></b>, <b><i>ic</i></b> or <b><i>ad</i></b>, delete if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>mente</i></b>\n        </dt><dd>delete if in <i>R</i>2\n        </dd><dd>if preceded by <b><i>ante</i></b>, <b><i>able</i></b> or <b><i>ible</i></b>, delete if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>idad  &nbsp;  idades</i></b>\n        </dt><dd>delete if in <i>R</i>2\n        </dd><dd>if preceded by <b><i>abil</i></b>, <b><i>ic</i></b> or <b><i>iv</i></b>, delete if in <i>R</i>2\n<br><br>\n    </dd><dt><b><i>iva  &nbsp;  ivo  &nbsp;  ivas  &nbsp;  ivos</i></b>\n        </dt><dd>delete if in <i>R</i>2\n        </dd><dd>if preceded by <b><i>at</i></b>, delete if in <i>R</i>2\n</dd></dl>\n</dd></dl>\nDo step 2<i>a</i> if no ending was removed by step 1.\n<br><br>\nStep 2<i>a</i>: Verb suffixes beginning <b><i>y</i></b>\n<dl><dd>\n    Search for the longest among the following suffixes in <i>RV</i>, and if found,\n    delete if preceded by <b><i>u</i></b>.\n<br><br><dl><dd>\n        <b><i>ya  &nbsp;  ye  &nbsp;  yan  &nbsp;  yen  &nbsp;  yeron  &nbsp;  yendo  &nbsp;  yo  &nbsp;  yó  &nbsp;  yas  &nbsp;  yes  &nbsp;  yais  &nbsp;\n        yamos</i></b>\n</dd></dl><br>\n    (Note that the preceding u need not be in <i>RV</i>.)\n</dd></dl>\nDo Step 2<i>b</i> if step 2<i>a</i> was done, but failed to remove a suffix.\n<br><br>\nStep 2<i>b</i>: Other verb suffixes\n<dl><dd>\n    Search for the longest among the following suffixes in <i>RV</i>, and perform the\n    action indicated.\n<br><br>\n<dl>\n    <dt><b><i>en  &nbsp;  es  &nbsp;  éis  &nbsp;  emos</i></b>\n        </dt><dd>delete, and if preceded by <b><i>gu</i></b> delete the <b><i>u</i></b> (the <b><i>gu</i></b> need not be in\n        <i>RV</i>)\n<br><br>\n    </dd><dt><b><i>arían  &nbsp;  arías  &nbsp;  arán  &nbsp;  arás  &nbsp;  aríais  &nbsp;  aría  &nbsp;  aréis  &nbsp;  aríamos  &nbsp;  aremos\n     &nbsp;  ará  &nbsp;  aré\n     &nbsp;  erían  &nbsp;  erías  &nbsp;  erán  &nbsp;  erás  &nbsp;  eríais  &nbsp;  ería  &nbsp;  eréis  &nbsp;  eríamos  &nbsp;  eremos\n     &nbsp;  erá  &nbsp;  eré\n     &nbsp;  irían  &nbsp;  irías  &nbsp;  irán  &nbsp;  irás  &nbsp;  iríais  &nbsp;  iría  &nbsp;  iréis  &nbsp;  iríamos  &nbsp;  iremos\n     &nbsp;  irá  &nbsp;  iré\n     &nbsp;  aba  &nbsp;  ada  &nbsp;  ida  &nbsp;  ía  &nbsp;  ara  &nbsp;  iera  &nbsp;  ad  &nbsp;  ed  &nbsp;  id  &nbsp;  ase  &nbsp;  iese  &nbsp;  aste  &nbsp;  iste  &nbsp;  an  &nbsp;  aban  &nbsp;  ían\n     &nbsp;  aran  &nbsp;  ieran  &nbsp;  asen  &nbsp;  iesen  &nbsp;  aron  &nbsp;  ieron  &nbsp;  ado  &nbsp;  ido  &nbsp;  ando  &nbsp;  iendo  &nbsp;  ió  &nbsp;  ar  &nbsp;  er  &nbsp;  ir  &nbsp;  as\n     &nbsp;  abas  &nbsp;  adas  &nbsp;  idas  &nbsp;  ías  &nbsp;  aras  &nbsp;  ieras  &nbsp;  ases  &nbsp;  ieses  &nbsp;  ís  &nbsp;  áis  &nbsp;  abais  &nbsp;  íais\n     &nbsp;  arais  &nbsp;  ierais  &nbsp;    &nbsp;  aseis  &nbsp;  ieseis  &nbsp;  asteis  &nbsp;  isteis  &nbsp;  ados  &nbsp;  idos  &nbsp;  amos  &nbsp;  ábamos\n     &nbsp;  íamos  &nbsp;  imos  &nbsp;  áramos  &nbsp;  iéramos  &nbsp;  iésemos  &nbsp;  ásemos</i></b>\n        </dt><dd>delete\n</dd></dl>\n</dd></dl>\nAlways do step 3.\n<br><br>\nStep 3: residual suffix\n<dl><dd>\n    Search for the longest among the following suffixes in <i>RV</i>, and perform the\n    action indicated.\n<br><br>\n<dl>\n    <dt><b><i>os  &nbsp;  a  &nbsp;  o  &nbsp;  á  &nbsp;  í  &nbsp;  ó</i></b>\n        </dt><dd>delete if in <i>RV</i>\n<br><br>\n    </dd><dt><b><i>e  &nbsp;  é</i></b>\n        </dt><dd>delete if in <i>RV</i>, and if preceded by <b><i>gu</i></b> with the <b><i>u</i></b> in <i>RV</i> delete the <b><i>u</i></b>\n</dd></dl>\n</dd></dl>\nAnd finally:\n<dl><dd>\n    Remove acute accents\n</dd></dl>\n\n</td></tr>\n\n<tr><td bgcolor=\"lightblue\">\n\n<br>&nbsp;<h2>The same algorithm in Snowball</h2>\n\n<br><pre><dl><dd>\nroutines (\n           postlude mark_regions\n           RV R1 R2\n           attached_pronoun\n           standard_suffix\n           y_verb_suffix\n           verb_suffix\n           residual_suffix\n)\n\nexternals ( stem )\n\nintegers ( pV p1 p2 )\n\ngroupings ( v )\n\nstringescapes {}\n\n/* special characters (in ISO Latin I) */\n\nstringdef a'   hex 'E1'  // a-acute\nstringdef e'   hex 'E9'  // e-acute\nstringdef i'   hex 'ED'  // i-acute\nstringdef o'   hex 'F3'  // o-acute\nstringdef u'   hex 'FA'  // u-acute\nstringdef u\"   hex 'FC'  // u-diaeresis\nstringdef n~   hex 'F1'  // n-tilde\n\ndefine v 'aeiou{a'}{e'}{i'}{o'}{u'}{u\"}'\n\ndefine mark_regions as (\n\n    $pV = limit\n    $p1 = limit\n    $p2 = limit  // defaults\n\n    do (\n        ( v (non-v gopast v) or (v gopast non-v) )\n        or\n        ( non-v (non-v gopast v) or (v next) )\n        setmark pV\n    )\n    do (\n        gopast v gopast non-v setmark p1\n        gopast v gopast non-v setmark p2\n    )\n)\n\ndefine postlude as repeat (\n    [substring] among(\n        '{a'}' (&lt;- 'a')\n        '{e'}' (&lt;- 'e')\n        '{i'}' (&lt;- 'i')\n        '{o'}' (&lt;- 'o')\n        '{u'}' (&lt;- 'u')\n        // and possibly {u\"}-&gt;u here, or in prelude\n        ''     (next)\n    ) //or next\n)\n\nbackwardmode (\n\n    define RV as $pV &lt;= cursor\n    define R1 as $p1 &lt;= cursor\n    define R2 as $p2 &lt;= cursor\n\n    define attached_pronoun as (\n        [substring] among(\n            'me' 'se'  'sela' 'selo' 'selas' 'selos' 'la' 'le' 'lo'\n            'las' 'les' 'los' 'nos'\n        )\n        substring RV among(\n            'i{e'}ndo' (] &lt;- 'iendo')\n            '{a'}ndo'  (] &lt;- 'ando')\n            '{a'}r'    (] &lt;- 'ar')\n            '{e'}r'    (] &lt;- 'er')\n            '{i'}r'    (] &lt;- 'ir')\n            'ando'\n            'iendo'\n            'ar' 'er' 'ir'\n                       (delete)\n            'yendo'    ('u' delete)\n        )\n    )\n\n    define standard_suffix as (\n        [substring] among(\n\n            'anza' 'anzas'\n            'ico' 'ica' 'icos' 'icas'\n            'ismo' 'ismos'\n            'able' 'ables'\n            'ible' 'ibles'\n            'ista' 'istas'\n            'oso' 'osa' 'osos' 'osas'\n            'amiento' 'amientos'\n            'imiento' 'imientos'\n            (\n                R2 delete\n            )\n            'adora' 'ador' 'aci{o'}n'\n            'adoras' 'adores' 'aciones'\n            'ante' 'antes' 'ancia' 'ancias'// Note 1\n            (\n                R2 delete\n                try ( ['ic'] R2 delete )\n            )\n            'log{i'}a'\n            'log{i'}as'\n            (\n                R2 &lt;- 'log'\n            )\n            'uci{o'}n' 'uciones'\n            (\n                R2 &lt;- 'u'\n            )\n            'encia' 'encias'\n            (\n                R2 &lt;- 'ente'\n            )\n            'amente'\n            (\n                R1 delete\n                try (\n                    [substring] R2 delete among(\n                        'iv' (['at'] R2 delete)\n                        'os'\n                        'ic'\n                        'ad'\n                    )\n                )\n            )\n            'mente'\n            (\n                R2 delete\n                try (\n                    [substring] among(\n                        'ante' // Note 1\n                        'able'\n                        'ible' (R2 delete)\n                    )\n                )\n            )\n            'idad'\n            'idades'\n            (\n                R2 delete\n                try (\n                    [substring] among(\n                        'abil'\n                        'ic'\n                        'iv'   (R2 delete)\n                    )\n                )\n            )\n            'iva' 'ivo'\n            'ivas' 'ivos'\n            (\n                R2 delete\n                try (\n                    ['at'] R2 delete // but not a further   ['ic'] R2 delete\n                )\n            )\n        )\n    )\n\n    define y_verb_suffix as (\n        setlimit tomark pV for ([substring]) among(\n            'ya' 'ye' 'yan' 'yen' 'yeron' 'yendo' 'yo' 'y{o'}'\n            'yas' 'yes' 'yais' 'yamos'\n                ('u' delete)\n        )\n    )\n\n    define verb_suffix as (\n        setlimit tomark pV for ([substring]) among(\n\n            'en' 'es' '{e'}is' 'emos'\n                (try ('u' test 'g') ] delete)\n\n            'ar{i'}an' 'ar{i'}as' 'ar{a'}n' 'ar{a'}s' 'ar{i'}ais'\n            'ar{i'}a' 'ar{e'}is' 'ar{i'}amos' 'aremos' 'ar{a'}'\n            'ar{e'}'\n            'er{i'}an' 'er{i'}as' 'er{a'}n' 'er{a'}s' 'er{i'}ais'\n            'er{i'}a' 'er{e'}is' 'er{i'}amos' 'eremos' 'er{a'}'\n            'er{e'}'\n            'ir{i'}an' 'ir{i'}as' 'ir{a'}n' 'ir{a'}s' 'ir{i'}ais'\n            'ir{i'}a' 'ir{e'}is' 'ir{i'}amos' 'iremos' 'ir{a'}'\n            'ir{e'}'\n\n            'aba' 'ada' 'ida' '{i'}a' 'ara' 'iera' 'ad' 'ed'\n            'id' 'ase' 'iese' 'aste' 'iste' 'an' 'aban' '{i'}an'\n            'aran' 'ieran' 'asen' 'iesen' 'aron' 'ieron' 'ado'\n            'ido' 'ando' 'iendo' 'i{o'}' 'ar' 'er' 'ir' 'as'\n            'abas' 'adas' 'idas' '{i'}as' 'aras' 'ieras' 'ases'\n            'ieses' '{i'}s' '{a'}is' 'abais' '{i'}ais' 'arais'\n            'ierais'  'aseis' 'ieseis' 'asteis' 'isteis' 'ados'\n            'idos' 'amos' '{a'}bamos' '{i'}amos' 'imos'\n            '{a'}ramos' 'i{e'}ramos' 'i{e'}semos' '{a'}semos'\n                (delete)\n        )\n    )\n\n    define residual_suffix as (\n        [substring] among(\n            'os'\n            'a' 'o' '{a'}' '{i'}' '{o'}'\n                ( RV delete )\n            'e' '{e'}'\n                ( RV delete try( ['u'] test 'g' RV delete ) )\n        )\n    )\n)\n\ndefine stem as (\n    do mark_regions\n    backwards (\n        do attached_pronoun\n        do ( standard_suffix or\n             y_verb_suffix or\n             verb_suffix\n           )\n        do residual_suffix\n    )\n    do postlude\n)\n\n/*\n    Note 1: additions of 15 Jun 2005\n*/\n</dd></dl>\n</pre>\n</td></tr></tbody></table>"
		}, {
			"id" : "8",
			"category" : "lunr",
			"title" : "lunr.js 0.7.0",
			"body" : "<div class=\"main\">\n      <header>\n        <div class=\"search\">\n          <input type=\"search\" id=\"search-input\" placeholder=\"Search\">\n          <div id=\"search-results\"></div>\n        </div>\n        <h1>lunr.js <span class=\"version\">0.7.0</span></h1>\n      </header>\n\n      \n        <article id=\"lunr\">\n          <header>\n            <h2>lunr</h2>\n          </header>\n\n          <section>\n            <p>Convenience function for instantiating a new lunr index and configuring it with the default pipeline functions and the passed config function.</p>\n\n<p>When using this convenience function a new index will be created with the following functions already in the pipeline:</p>\n\n<p>lunr.StopWordFilter - filters out any stop words before they enter the index</p>\n\n<p>lunr.stemmer - stems the tokens before entering the index.</p>\n\n<p>Example:</p>\n\n<pre><code><span class=\"keyword\">var</span> idx = lunr(<span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">this</span>.field(<span class=\"string\">'title'</span>, <span class=\"number\">10</span>)\n  <span class=\"keyword\">this</span>.field(<span class=\"string\">'tags'</span>, <span class=\"number\">100</span>)\n  <span class=\"keyword\">this</span>.field(<span class=\"string\">'body'</span>)\n\n  <span class=\"keyword\">this</span>.ref(<span class=\"string\">'cid'</span>)\n\n  <span class=\"keyword\">this</span>.pipeline.add(<span class=\"keyword\">function</span> () {\n    <span class=\"comment\">// some custom pipeline function</span>\n  })\n\n})\n</code></pre>\n          </section>\n\n          \n        </article>\n      \n        <article id=\"EventEmitter\">\n          <header>\n            <h2>EventEmitter</h2>\n          </header>\n\n          <section>\n            <p>lunr.EventEmitter is an event emitter for lunr. It manages adding and removing event handlers and triggering events and their handlers.</p>\n          </section>\n\n          \n            <section class=\"method\" id=\"addListener\">\n              <header>\n                <h3>addListener</h3>\n                <h4>lunr.EventEmitter.prototype.addListener()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">addListener</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>[eventName] - The name(s) of events to bind this function to.</li>\n                  \n                    <li>fn - The function to call when an event is fired.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Binds a handler function to a specific event(s).</p>\n\n<p>Can bind a single function to many different events in one call.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">EventEmitter</span>.prototype.addListener = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">var</span> args = <span class=\"class\">Array</span>.prototype.slice.call(arguments),\n      fn = args.pop(),\n      names = args\n\n  <span class=\"keyword\">if</span> (<span class=\"keyword\">typeof</span> fn !== <span class=\"string\">\"function\"</span>) <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"class\">TypeError</span> (<span class=\"string\">\"last argument must be a function\"</span>)\n\n  names.forEach(<span class=\"keyword\">function</span> (name) {\n    <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.hasHandler(name)) <span class=\"keyword\">this</span>.events[name] = []\n    <span class=\"keyword\">this</span>.events[name].push(fn)\n  }, <span class=\"keyword\">this</span>)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"removeListener\">\n              <header>\n                <h3>removeListener</h3>\n                <h4>lunr.EventEmitter.prototype.removeListener()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">removeListener</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>eventName - The name of the event to remove this function from.</li>\n                  \n                    <li>fn - The function to remove from an event.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Removes a handler function from a specific event.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">EventEmitter</span>.prototype.removeListener = <span class=\"keyword\">function</span> (name, fn) {\n  <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.hasHandler(name)) <span class=\"keyword\">return</span>\n\n  <span class=\"keyword\">var</span> fnIndex = <span class=\"keyword\">this</span>.events[name].indexOf(fn)\n  <span class=\"keyword\">this</span>.events[name].splice(fnIndex, <span class=\"number\">1</span>)\n\n  <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.events[name].length) <span class=\"keyword\">delete</span> <span class=\"keyword\">this</span>.events[name]\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"emit\">\n              <header>\n                <h3>emit</h3>\n                <h4>lunr.EventEmitter.prototype.emit()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">emit</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>eventName - The name of the event to emit.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Calls all functions bound to the given event.</p>\n\n<p>Additional data can be passed to the event handler as arguments to <code>emit</code> after the event name.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">EventEmitter</span>.prototype.emit = <span class=\"keyword\">function</span> (name) {\n  <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.hasHandler(name)) <span class=\"keyword\">return</span>\n\n  <span class=\"keyword\">var</span> args = <span class=\"class\">Array</span>.prototype.slice.call(arguments, <span class=\"number\">1</span>)\n\n  <span class=\"keyword\">this</span>.events[name].forEach(<span class=\"keyword\">function</span> (fn) {\n    fn.apply(<span class=\"special\">undefined</span>, args)\n  })\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"hasHandler\">\n              <header>\n                <h3>hasHandler</h3>\n                <h4>lunr.EventEmitter.prototype.hasHandler()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">hasHandler</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>eventName - The name of the event to check.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Checks whether a handler has ever been stored against an event.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">EventEmitter</span>.prototype.hasHandler = <span class=\"keyword\">function</span> (name) {\n  <span class=\"keyword\">return</span> name <span class=\"keyword\">in</span> <span class=\"keyword\">this</span>.events\n}</code></pre>\n              </section>\n              \n            </section>\n          \n        </article>\n      \n        <article id=\"tokenizer\">\n          <header>\n            <h2>tokenizer</h2>\n          </header>\n\n          <section>\n            <p>A function for splitting a string into tokens ready to be inserted into the search index. Uses <code>lunr.tokenizer.seperator</code> to split strings, change the value of this property to change how strings are split into tokens.</p>\n          </section>\n\n          \n            <section class=\"method\" id=\"load\">\n              <header>\n                <h3>load</h3>\n                <h4>lunr.tokenizer.load()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">load</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>label - The label of the serialised tokenizer.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Loads a previously serialised tokenizer.</p>\n\n<p>A tokenizer function to be loaded must already be registered with lunr.tokenizer. If the serialised tokenizer has not been registered then an error will be thrown.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.tokenizer.load = <span class=\"keyword\">function</span> (label) {\n  <span class=\"keyword\">var</span> fn = <span class=\"keyword\">this</span>.registeredFunctions[label]\n\n  <span class=\"keyword\">if</span> (!fn) {\n    <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"class\">Error</span>(<span class=\"string\">'Cannot load un-registered function: '</span> + label)\n  }\n\n  <span class=\"keyword\">return</span> fn\n}\n\nlunr.tokenizer.label = <span class=\"string\">'default'</span>\n\nlunr.tokenizer.registeredFunctions = {\n  <span class=\"string\">'default'</span>: lunr.tokenizer\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"registerFunction\">\n              <header>\n                <h3>registerFunction</h3>\n                <h4>lunr.tokenizer.registerFunction()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">registerFunction</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>fn - The function to register.</li>\n                  \n                    <li>label - The label to register this function with</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Register a tokenizer function.</p>\n\n<p>Functions that are used as tokenizers should be registered if they are to be used with a serialised index.</p>\n\n<p>Registering a function does not add it to an index, functions must still be associated with a specific index for them to be used when indexing and searching documents.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.tokenizer.registerFunction = <span class=\"keyword\">function</span> (fn, label) {\n  <span class=\"keyword\">if</span> (label <span class=\"keyword\">in</span> <span class=\"keyword\">this</span>.registeredFunctions) {\n    lunr.utils.warn(<span class=\"string\">'Overwriting existing tokenizer: '</span> + label)\n  }\n\n  fn.label = label\n  <span class=\"keyword\">this</span>.registeredFunctions[label] = fn\n}</code></pre>\n              </section>\n              \n            </section>\n          \n        </article>\n      \n        <article id=\"Pipeline\">\n          <header>\n            <h2>Pipeline</h2>\n          </header>\n\n          <section>\n            <p>lunr.Pipelines maintain an ordered list of functions to be applied to all tokens in documents entering the search index and queries being ran against the index.</p>\n\n<p>An instance of lunr.Index created with the lunr shortcut will contain a pipeline with a stop word filter and an English language stemmer. Extra functions can be added before or after either of these functions or these default functions can be removed.</p>\n\n<p>When run the pipeline will call each function in turn, passing a token, the index of that token in the original list of all tokens and finally a list of all the original tokens.</p>\n\n<p>The output of functions in the pipeline will be passed to the next function in the pipeline. To exclude a token from entering the index the function should return undefined, the rest of the pipeline will not be called with this token.</p>\n\n<p>For serialisation of pipelines to work, all functions used in an instance of a pipeline should be registered with lunr.Pipeline. Registered functions can then be loaded. If trying to load a serialised pipeline that uses functions that are not registered an error will be thrown.</p>\n\n<p>If not planning on serialising the pipeline then registering pipeline functions is not necessary.</p>\n          </section>\n\n          \n            <section class=\"method\" id=\"registerFunction\">\n              <header>\n                <h3>registerFunction</h3>\n                <h4>lunr.Pipeline.registerFunction()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">registerFunction</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>fn - The function to check for.</li>\n                  \n                    <li>label - The label to register this function with</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Register a function with the pipeline.</p>\n\n<p>Functions that are used in the pipeline should be registered if the pipeline needs to be serialised, or a serialised pipeline needs to be loaded.</p>\n\n<p>Registering a function does not add it to a pipeline, functions must still be added to instances of the pipeline for them to be used when running a pipeline.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Pipeline</span>.registerFunction = <span class=\"keyword\">function</span> (fn, label) {\n  <span class=\"keyword\">if</span> (label <span class=\"keyword\">in</span> <span class=\"keyword\">this</span>.registeredFunctions) {\n    lunr.utils.warn(<span class=\"string\">'Overwriting existing registered function: '</span> + label)\n  }\n\n  fn.label = label\n  lunr.<span class=\"class\">Pipeline</span>.registeredFunctions[fn.label] = fn\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"warnIfFunctionNotRegistered\">\n              <header>\n                <h3>warnIfFunctionNotRegistered</h3>\n                <h4>lunr.Pipeline.warnIfFunctionNotRegistered()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">warnIfFunctionNotRegistered</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>fn - The function to check for.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Warns if the function is not registered as a Pipeline function.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Pipeline</span>.warnIfFunctionNotRegistered = <span class=\"keyword\">function</span> (fn) {\n  <span class=\"keyword\">var</span> isRegistered = fn.label &amp;&amp; (fn.label <span class=\"keyword\">in</span> <span class=\"keyword\">this</span>.registeredFunctions)\n\n  <span class=\"keyword\">if</span> (!isRegistered) {\n    lunr.utils.warn(<span class=\"string\">'Function is not registered with pipeline. This may cause problems when serialising the index.\\n'</span>, fn)\n  }\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"load\">\n              <header>\n                <h3>load</h3>\n                <h4>lunr.Pipeline.load()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">load</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>serialised - The serialised pipeline to load.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Loads a previously serialised pipeline.</p>\n\n<p>All functions to be loaded must already be registered with lunr.Pipeline. If any function from the serialised data has not been registered then an error will be thrown.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Pipeline</span>.load = <span class=\"keyword\">function</span> (serialised) {\n  <span class=\"keyword\">var</span> pipeline = <span class=\"keyword\">new</span> lunr.<span class=\"class\">Pipeline</span>\n\n  serialised.forEach(<span class=\"keyword\">function</span> (fnName) {\n    <span class=\"keyword\">var</span> fn = lunr.<span class=\"class\">Pipeline</span>.registeredFunctions[fnName]\n\n    <span class=\"keyword\">if</span> (fn) {\n      pipeline.add(fn)\n    } <span class=\"keyword\">else</span> {\n      <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"class\">Error</span>(<span class=\"string\">'Cannot load un-registered function: '</span> + fnName)\n    }\n  })\n\n  <span class=\"keyword\">return</span> pipeline\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"add\">\n              <header>\n                <h3>add</h3>\n                <h4>lunr.Pipeline.prototype.add()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">add</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>functions - Any number of functions to add to the pipeline.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Adds new functions to the end of the pipeline.</p>\n\n<p>Logs a warning if the function has not been registered.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Pipeline</span>.prototype.add = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">var</span> fns = <span class=\"class\">Array</span>.prototype.slice.call(arguments)\n\n  fns.forEach(<span class=\"keyword\">function</span> (fn) {\n    lunr.<span class=\"class\">Pipeline</span>.warnIfFunctionNotRegistered(fn)\n    <span class=\"keyword\">this</span>._stack.push(fn)\n  }, <span class=\"keyword\">this</span>)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"after\">\n              <header>\n                <h3>after</h3>\n                <h4>lunr.Pipeline.prototype.after()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">after</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>existingFn - A function that already exists in the pipeline.</li>\n                  \n                    <li>newFn - The new function to add to the pipeline.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Adds a single function after a function that already exists in the pipeline.</p>\n\n<p>Logs a warning if the function has not been registered.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Pipeline</span>.prototype.after = <span class=\"keyword\">function</span> (existingFn, newFn) {\n  lunr.<span class=\"class\">Pipeline</span>.warnIfFunctionNotRegistered(newFn)\n\n  <span class=\"keyword\">var</span> pos = <span class=\"keyword\">this</span>._stack.indexOf(existingFn)\n  <span class=\"keyword\">if</span> (pos == -<span class=\"number\">1</span>) {\n    <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"class\">Error</span>(<span class=\"string\">'Cannot find existingFn'</span>)\n  }\n\n  pos = pos + <span class=\"number\">1</span>\n  <span class=\"keyword\">this</span>._stack.splice(pos, <span class=\"number\">0</span>, newFn)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"before\">\n              <header>\n                <h3>before</h3>\n                <h4>lunr.Pipeline.prototype.before()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">before</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>existingFn - A function that already exists in the pipeline.</li>\n                  \n                    <li>newFn - The new function to add to the pipeline.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Adds a single function before a function that already exists in the pipeline.</p>\n\n<p>Logs a warning if the function has not been registered.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Pipeline</span>.prototype.before = <span class=\"keyword\">function</span> (existingFn, newFn) {\n  lunr.<span class=\"class\">Pipeline</span>.warnIfFunctionNotRegistered(newFn)\n\n  <span class=\"keyword\">var</span> pos = <span class=\"keyword\">this</span>._stack.indexOf(existingFn)\n  <span class=\"keyword\">if</span> (pos == -<span class=\"number\">1</span>) {\n    <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"class\">Error</span>(<span class=\"string\">'Cannot find existingFn'</span>)\n  }\n\n  <span class=\"keyword\">this</span>._stack.splice(pos, <span class=\"number\">0</span>, newFn)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"remove\">\n              <header>\n                <h3>remove</h3>\n                <h4>lunr.Pipeline.prototype.remove()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">remove</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>fn - The function to remove from the pipeline.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Removes a function from the pipeline.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Pipeline</span>.prototype.remove = <span class=\"keyword\">function</span> (fn) {\n  <span class=\"keyword\">var</span> pos = <span class=\"keyword\">this</span>._stack.indexOf(fn)\n  <span class=\"keyword\">if</span> (pos == -<span class=\"number\">1</span>) {\n    <span class=\"keyword\">return</span>\n  }\n\n  <span class=\"keyword\">this</span>._stack.splice(pos, <span class=\"number\">1</span>)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"run\">\n              <header>\n                <h3>run</h3>\n                <h4>lunr.Pipeline.prototype.run()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">run</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>tokens - The tokens to run through the pipeline.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Runs the current list of functions that make up the pipeline against the passed tokens.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Pipeline</span>.prototype.run = <span class=\"keyword\">function</span> (tokens) {\n  <span class=\"keyword\">var</span> out = [],\n      tokenLength = tokens.length,\n      stackLength = <span class=\"keyword\">this</span>._stack.length\n\n  <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; tokenLength; i++) {\n    <span class=\"keyword\">var</span> token = tokens[i]\n\n    <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> j = <span class=\"number\">0</span>; j &lt; stackLength; j++) {\n      token = <span class=\"keyword\">this</span>._stack[j](token, i, tokens)\n      <span class=\"keyword\">if</span> (token === <span class=\"keyword\">void</span> <span class=\"number\">0</span> || token === <span class=\"string\">''</span>) <span class=\"keyword\">break</span>\n    };\n\n    <span class=\"keyword\">if</span> (token !== <span class=\"keyword\">void</span> <span class=\"number\">0</span> &amp;&amp; token !== <span class=\"string\">''</span>) out.push(token)\n  };\n\n  <span class=\"keyword\">return</span> out\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"reset\">\n              <header>\n                <h3>reset</h3>\n                <h4>lunr.Pipeline.prototype.reset()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">reset</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                <ul>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Resets the pipeline by removing any existing processors.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Pipeline</span>.prototype.reset = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">this</span>._stack = []\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"toJSON\">\n              <header>\n                <h3>toJSON</h3>\n                <h4>lunr.Pipeline.prototype.toJSON()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">toJSON</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                <ul>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Returns a representation of the pipeline ready for serialisation.</p>\n\n<p>Logs a warning if the function has not been registered.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Pipeline</span>.prototype.toJSON = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>._stack.map(<span class=\"keyword\">function</span> (fn) {\n    lunr.<span class=\"class\">Pipeline</span>.warnIfFunctionNotRegistered(fn)\n\n    <span class=\"keyword\">return</span> fn.label\n  })\n}</code></pre>\n              </section>\n              \n            </section>\n          \n        </article>\n      \n        <article id=\"Vector\">\n          <header>\n            <h2>Vector</h2>\n          </header>\n\n          <section>\n            <p>lunr.Vectors implement vector related operations for a series of elements.</p>\n          </section>\n\n          \n            <section class=\"method\" id=\"Node\">\n              <header>\n                <h3>Node</h3>\n                <h4>lunr.Vector.Node()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">Node</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>The - index of the node in the vector.</li>\n                  \n                    <li>The - data at this node in the vector.</li>\n                  \n                    <li>The - node directly after this node in the vector.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>lunr.Vector.Node is a simple struct for each node in a lunr.Vector.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Vector</span>.<span class=\"class\">Node</span> = <span class=\"keyword\">function</span> (idx, val, next) {\n  <span class=\"keyword\">this</span>.idx = idx\n  <span class=\"keyword\">this</span>.val = val\n  <span class=\"keyword\">this</span>.next = next\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"magnitude\">\n              <header>\n                <h3>magnitude</h3>\n                <h4>lunr.Vector.prototype.magnitude()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">magnitude</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                <ul>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Calculates the magnitude of this vector.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Vector</span>.prototype.magnitude = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span>._magnitude) <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>._magnitude\n  <span class=\"keyword\">var</span> node = <span class=\"keyword\">this</span>.list,\n      sumOfSquares = <span class=\"number\">0</span>,\n      val\n\n  <span class=\"keyword\">while</span> (node) {\n    val = node.val\n    sumOfSquares += val * val\n    node = node.next\n  }\n\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>._magnitude = <span class=\"class\">Math</span>.sqrt(sumOfSquares)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"dot\">\n              <header>\n                <h3>dot</h3>\n                <h4>lunr.Vector.prototype.dot()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">dot</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>otherVector - The vector to compute the dot product with.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Calculates the dot product of this vector and another vector.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Vector</span>.prototype.dot = <span class=\"keyword\">function</span> (otherVector) {\n  <span class=\"keyword\">var</span> node = <span class=\"keyword\">this</span>.list,\n      otherNode = otherVector.list,\n      dotProduct = <span class=\"number\">0</span>\n\n  <span class=\"keyword\">while</span> (node &amp;&amp; otherNode) {\n    <span class=\"keyword\">if</span> (node.idx &lt; otherNode.idx) {\n      node = node.next\n    } <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (node.idx &gt; otherNode.idx) {\n      otherNode = otherNode.next\n    } <span class=\"keyword\">else</span> {\n      dotProduct += node.val * otherNode.val\n      node = node.next\n      otherNode = otherNode.next\n    }\n  }\n\n  <span class=\"keyword\">return</span> dotProduct\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"similarity\">\n              <header>\n                <h3>similarity</h3>\n                <h4>lunr.Vector.prototype.similarity()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">similarity</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>otherVector - The other vector to calculate the</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Calculates the cosine similarity between this vector and another vector.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Vector</span>.prototype.similarity = <span class=\"keyword\">function</span> (otherVector) {\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.dot(otherVector) / (<span class=\"keyword\">this</span>.magnitude() * otherVector.magnitude())\n}</code></pre>\n              </section>\n              \n            </section>\n          \n        </article>\n      \n        <article id=\"Node\">\n          <header>\n            <h2>Node</h2>\n          </header>\n\n          <section>\n            <p>lunr.Vector.Node is a simple struct for each node in a lunr.Vector.</p>\n          </section>\n\n          \n        </article>\n      \n        <article id=\"SortedSet\">\n          <header>\n            <h2>SortedSet</h2>\n          </header>\n\n          <section>\n            <p>lunr.SortedSets are used to maintain an array of uniq values in a sorted order.</p>\n          </section>\n\n          \n            <section class=\"method\" id=\"load\">\n              <header>\n                <h3>load</h3>\n                <h4>lunr.SortedSet.load()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">load</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>serialisedData - The serialised set to load.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Loads a previously serialised sorted set.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.load = <span class=\"keyword\">function</span> (serialisedData) {\n  <span class=\"keyword\">var</span> set = <span class=\"keyword\">new</span> <span class=\"keyword\">this</span>\n\n  set.elements = serialisedData\n  set.length = serialisedData.length\n\n  <span class=\"keyword\">return</span> set\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"add\">\n              <header>\n                <h3>add</h3>\n                <h4>lunr.SortedSet.prototype.add()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">add</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>The - objects to add to this set.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Inserts new items into the set in the correct position to maintain the order.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.prototype.add = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">var</span> i, element\n\n  <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; arguments.length; i++) {\n    element = arguments[i]\n    <span class=\"keyword\">if</span> (~<span class=\"keyword\">this</span>.indexOf(element)) <span class=\"keyword\">continue</span>\n    <span class=\"keyword\">this</span>.elements.splice(<span class=\"keyword\">this</span>.locationFor(element), <span class=\"number\">0</span>, element)\n  }\n\n  <span class=\"keyword\">this</span>.length = <span class=\"keyword\">this</span>.elements.length\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"toArray\">\n              <header>\n                <h3>toArray</h3>\n                <h4>lunr.SortedSet.prototype.toArray()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">toArray</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                <ul>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Converts this sorted set into an array.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.prototype.toArray = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.elements.slice()\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"map\">\n              <header>\n                <h3>map</h3>\n                <h4>lunr.SortedSet.prototype.map()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">map</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>fn - The function that is called on each element of the</li>\n                  \n                    <li>ctx - An optional object that can be used as the context</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Creates a new array with the results of calling a provided function on every element in this sorted set.</p>\n\n<p>Delegates to Array.prototype.map and has the same signature.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.prototype.map = <span class=\"keyword\">function</span> (fn, ctx) {\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.elements.map(fn, ctx)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"forEach\">\n              <header>\n                <h3>forEach</h3>\n                <h4>lunr.SortedSet.prototype.forEach()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">forEach</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>fn - The function that is called on each element of the</li>\n                  \n                    <li>ctx - An optional object that can be used as the context</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Executes a provided function once per sorted set element.</p>\n\n<p>Delegates to Array.prototype.forEach and has the same signature.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.prototype.forEach = <span class=\"keyword\">function</span> (fn, ctx) {\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.elements.forEach(fn, ctx)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"indexOf\">\n              <header>\n                <h3>indexOf</h3>\n                <h4>lunr.SortedSet.prototype.indexOf()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">indexOf</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>elem - The object to locate in the sorted set.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Returns the index at which a given element can be found in the sorted set, or -1 if it is not present.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.prototype.indexOf = <span class=\"keyword\">function</span> (elem) {\n  <span class=\"keyword\">var</span> start = <span class=\"number\">0</span>,\n      end = <span class=\"keyword\">this</span>.elements.length,\n      sectionLength = end - start,\n      pivot = start + <span class=\"class\">Math</span>.floor(sectionLength / <span class=\"number\">2</span>),\n      pivotElem = <span class=\"keyword\">this</span>.elements[pivot]\n\n  <span class=\"keyword\">while</span> (sectionLength &gt; <span class=\"number\">1</span>) {\n    <span class=\"keyword\">if</span> (pivotElem === elem) <span class=\"keyword\">return</span> pivot\n\n    <span class=\"keyword\">if</span> (pivotElem &lt; elem) start = pivot\n    <span class=\"keyword\">if</span> (pivotElem &gt; elem) end = pivot\n\n    sectionLength = end - start\n    pivot = start + <span class=\"class\">Math</span>.floor(sectionLength / <span class=\"number\">2</span>)\n    pivotElem = <span class=\"keyword\">this</span>.elements[pivot]\n  }\n\n  <span class=\"keyword\">if</span> (pivotElem === elem) <span class=\"keyword\">return</span> pivot\n\n  <span class=\"keyword\">return</span> -<span class=\"number\">1</span>\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"locationFor\">\n              <header>\n                <h3>locationFor</h3>\n                <h4>lunr.SortedSet.prototype.locationFor()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">locationFor</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>elem - The elem to find the position for in the set</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Returns the position within the sorted set that an element should be inserted at to maintain the current order of the set.</p>\n\n<p>This function assumes that the element to search for does not already exist in the sorted set.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.prototype.locationFor = <span class=\"keyword\">function</span> (elem) {\n  <span class=\"keyword\">var</span> start = <span class=\"number\">0</span>,\n      end = <span class=\"keyword\">this</span>.elements.length,\n      sectionLength = end - start,\n      pivot = start + <span class=\"class\">Math</span>.floor(sectionLength / <span class=\"number\">2</span>),\n      pivotElem = <span class=\"keyword\">this</span>.elements[pivot]\n\n  <span class=\"keyword\">while</span> (sectionLength &gt; <span class=\"number\">1</span>) {\n    <span class=\"keyword\">if</span> (pivotElem &lt; elem) start = pivot\n    <span class=\"keyword\">if</span> (pivotElem &gt; elem) end = pivot\n\n    sectionLength = end - start\n    pivot = start + <span class=\"class\">Math</span>.floor(sectionLength / <span class=\"number\">2</span>)\n    pivotElem = <span class=\"keyword\">this</span>.elements[pivot]\n  }\n\n  <span class=\"keyword\">if</span> (pivotElem &gt; elem) <span class=\"keyword\">return</span> pivot\n  <span class=\"keyword\">if</span> (pivotElem &lt; elem) <span class=\"keyword\">return</span> pivot + <span class=\"number\">1</span>\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"intersect\">\n              <header>\n                <h3>intersect</h3>\n                <h4>lunr.SortedSet.prototype.intersect()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">intersect</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>otherSet - The set to intersect with this set.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Creates a new lunr.SortedSet that contains the elements in the intersection of this set and the passed set.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.prototype.intersect = <span class=\"keyword\">function</span> (otherSet) {\n  <span class=\"keyword\">var</span> intersectSet = <span class=\"keyword\">new</span> lunr.<span class=\"class\">SortedSet</span>,\n      i = <span class=\"number\">0</span>, j = <span class=\"number\">0</span>,\n      a_len = <span class=\"keyword\">this</span>.length, b_len = otherSet.length,\n      a = <span class=\"keyword\">this</span>.elements, b = otherSet.elements\n\n  <span class=\"keyword\">while</span> (<span class=\"keyword\">true</span>) {\n    <span class=\"keyword\">if</span> (i &gt; a_len - <span class=\"number\">1</span> || j &gt; b_len - <span class=\"number\">1</span>) <span class=\"keyword\">break</span>\n\n    <span class=\"keyword\">if</span> (a[i] === b[j]) {\n      intersectSet.add(a[i])\n      i++, j++\n      <span class=\"keyword\">continue</span>\n    }\n\n    <span class=\"keyword\">if</span> (a[i] &lt; b[j]) {\n      i++\n      <span class=\"keyword\">continue</span>\n    }\n\n    <span class=\"keyword\">if</span> (a[i] &gt; b[j]) {\n      j++\n      <span class=\"keyword\">continue</span>\n    }\n  };\n\n  <span class=\"keyword\">return</span> intersectSet\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"clone\">\n              <header>\n                <h3>clone</h3>\n                <h4>lunr.SortedSet.prototype.clone()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">clone</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                <ul>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Makes a copy of this set</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.prototype.clone = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">var</span> clone = <span class=\"keyword\">new</span> lunr.<span class=\"class\">SortedSet</span>\n\n  clone.elements = <span class=\"keyword\">this</span>.toArray()\n  clone.length = clone.elements.length\n\n  <span class=\"keyword\">return</span> clone\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"union\">\n              <header>\n                <h3>union</h3>\n                <h4>lunr.SortedSet.prototype.union()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">union</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>otherSet - The set to union with this set.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Creates a new lunr.SortedSet that contains the elements in the union of this set and the passed set.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.prototype.union = <span class=\"keyword\">function</span> (otherSet) {\n  <span class=\"keyword\">var</span> longSet, shortSet, unionSet\n\n  <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span>.length &gt;= otherSet.length) {\n    longSet = <span class=\"keyword\">this</span>, shortSet = otherSet\n  } <span class=\"keyword\">else</span> {\n    longSet = otherSet, shortSet = <span class=\"keyword\">this</span>\n  }\n\n  unionSet = longSet.clone()\n\n  <span class=\"keyword\">for</span>(<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>, shortSetElements = shortSet.toArray(); i &lt; shortSetElements.length; i++){\n    unionSet.add(shortSetElements[i])\n  }\n\n  <span class=\"keyword\">return</span> unionSet\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"toJSON\">\n              <header>\n                <h3>toJSON</h3>\n                <h4>lunr.SortedSet.prototype.toJSON()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">toJSON</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                <ul>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Returns a representation of the sorted set ready for serialisation.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">SortedSet</span>.prototype.toJSON = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.toArray()\n}</code></pre>\n              </section>\n              \n            </section>\n          \n        </article>\n      \n        <article id=\"Index\">\n          <header>\n            <h2>Index</h2>\n          </header>\n\n          <section>\n            <p>lunr.Index is object that manages a search index.  It contains the indexes and stores all the tokens and document lookups.  It also provides the main user facing API for the library.</p>\n          </section>\n\n          \n            <section class=\"method\" id=\"on\">\n              <header>\n                <h3>on</h3>\n                <h4>lunr.Index.prototype.on()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">on</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>[eventName] - The name(s) of events to bind the function to.</li>\n                  \n                    <li>fn - The serialised set to load.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Bind a handler to events being emitted by the index.</p>\n\n<p>The handler can be bound to many events at the same time.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.on = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">var</span> args = <span class=\"class\">Array</span>.prototype.slice.call(arguments)\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.eventEmitter.addListener.apply(<span class=\"keyword\">this</span>.eventEmitter, args)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"off\">\n              <header>\n                <h3>off</h3>\n                <h4>lunr.Index.prototype.off()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">off</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>eventName - The name of events to remove the function from.</li>\n                  \n                    <li>fn - The serialised set to load.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Removes a handler from an event being emitted by the index.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.off = <span class=\"keyword\">function</span> (name, fn) {\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.eventEmitter.removeListener(name, fn)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"load\">\n              <header>\n                <h3>load</h3>\n                <h4>lunr.Index.load()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">load</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>serialisedData - The serialised set to load.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Loads a previously serialised index.</p>\n\n<p>Issues a warning if the index being imported was serialised by a different version of lunr.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.load = <span class=\"keyword\">function</span> (serialisedData) {\n  <span class=\"keyword\">if</span> (serialisedData.version !== lunr.version) {\n    lunr.utils.warn(<span class=\"string\">'version mismatch: current '</span> + lunr.version + <span class=\"string\">' importing '</span> + serialisedData.version)\n  }\n\n  <span class=\"keyword\">var</span> idx = <span class=\"keyword\">new</span> <span class=\"keyword\">this</span>\n\n  idx._fields = serialisedData.fields\n  idx._ref = serialisedData.ref\n\n  idx.tokenizer = lunr.tokenizer.load(serialisedData.tokenizer)\n  idx.documentStore = lunr.<span class=\"class\">Store</span>.load(serialisedData.documentStore)\n  idx.tokenStore = lunr.<span class=\"class\">TokenStore</span>.load(serialisedData.tokenStore)\n  idx.corpusTokens = lunr.<span class=\"class\">SortedSet</span>.load(serialisedData.corpusTokens)\n  idx.pipeline = lunr.<span class=\"class\">Pipeline</span>.load(serialisedData.pipeline)\n\n  <span class=\"keyword\">return</span> idx\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"field\">\n              <header>\n                <h3>field</h3>\n                <h4>lunr.Index.prototype.field()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">field</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>fieldName - The name of the field within the document that</li>\n                  \n                    <li>boost - An optional boost that can be applied to terms in this</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Adds a field to the list of fields that will be searchable within documents in the index.</p>\n\n<p>An optional boost param can be passed to affect how much tokens in this field rank in search results, by default the boost value is 1.</p>\n\n<p>Fields should be added before any documents are added to the index, fields that are added after documents are added to the index will only apply to new documents added to the index.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.field = <span class=\"keyword\">function</span> (fieldName, opts) {\n  <span class=\"keyword\">var</span> opts = opts || {},\n      field = { name: fieldName, boost: opts.boost || <span class=\"number\">1</span> }\n\n  <span class=\"keyword\">this</span>._fields.push(field)\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"ref\">\n              <header>\n                <h3>ref</h3>\n                <h4>lunr.Index.prototype.ref()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">ref</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>refName - The property to use to uniquely identify the</li>\n                  \n                    <li>emitEvent - Whether to emit add events, defaults to true</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Sets the property used to uniquely identify documents added to the index, by default this property is 'id'.</p>\n\n<p>This should only be changed before adding documents to the index, changing the ref property without resetting the index can lead to unexpected results.</p>\n\n<p>The value of ref can be of any type but it <em>must</em> be stably comparable and orderable.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.ref = <span class=\"keyword\">function</span> (refName) {\n  <span class=\"keyword\">this</span>._ref = refName\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"tokenizer\">\n              <header>\n                <h3>tokenizer</h3>\n                <h4>lunr.Index.prototype.tokenizer()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">tokenizer</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>fn - The function to use as a tokenizer.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Sets the tokenizer used for this index.</p>\n\n<p>By default the index will use the default tokenizer, lunr.tokenizer. The tokenizer should only be changed before adding documents to the index. Changing the tokenizer without re-building the index can lead to unexpected results.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.tokenizer = <span class=\"keyword\">function</span> (fn) {\n  <span class=\"keyword\">var</span> isRegistered = fn.label &amp;&amp; (fn.label <span class=\"keyword\">in</span> lunr.tokenizer.registeredFunctions)\n\n  <span class=\"keyword\">if</span> (!isRegistered) {\n    lunr.utils.warn(<span class=\"string\">'Function is not a registered tokenizer. This may cause problems when serialising the index'</span>)\n  }\n\n  <span class=\"keyword\">this</span>.tokenizerFn = fn\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"add\">\n              <header>\n                <h3>add</h3>\n                <h4>lunr.Index.prototype.add()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">add</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>doc - The document to add to the index.</li>\n                  \n                    <li>emitEvent - Whether or not to emit events, default true.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Add a document to the index.</p>\n\n<p>This is the way new documents enter the index, this function will run the fields from the document through the index's pipeline and then add it to the index, it will then show up in search results.</p>\n\n<p>An 'add' event is emitted with the document that has been added and the index the document has been added to. This event can be silenced by passing false as the second argument to add.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.add = <span class=\"keyword\">function</span> (doc, emitEvent) {\n  <span class=\"keyword\">var</span> docTokens = {},\n      allDocumentTokens = <span class=\"keyword\">new</span> lunr.<span class=\"class\">SortedSet</span>,\n      docRef = doc[<span class=\"keyword\">this</span>._ref],\n      emitEvent = emitEvent === <span class=\"special\">undefined</span> ? <span class=\"keyword\">true</span> : emitEvent\n\n  <span class=\"keyword\">this</span>._fields.forEach(<span class=\"keyword\">function</span> (field) {\n    <span class=\"keyword\">var</span> fieldTokens = <span class=\"keyword\">this</span>.pipeline.run(<span class=\"keyword\">this</span>.tokenizerFn(doc[field.name]))\n\n    docTokens[field.name] = fieldTokens\n\n    <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; fieldTokens.length; i++) {\n      <span class=\"keyword\">var</span> token = fieldTokens[i]\n      allDocumentTokens.add(token)\n      <span class=\"keyword\">this</span>.corpusTokens.add(token)\n    }\n  }, <span class=\"keyword\">this</span>)\n\n  <span class=\"keyword\">this</span>.documentStore.set(docRef, allDocumentTokens)\n\n  <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; allDocumentTokens.length; i++) {\n    <span class=\"keyword\">var</span> token = allDocumentTokens.elements[i]\n    <span class=\"keyword\">var</span> tf = <span class=\"number\">0</span>;\n\n    <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> j = <span class=\"number\">0</span>; j &lt; <span class=\"keyword\">this</span>._fields.length; j++){\n      <span class=\"keyword\">var</span> field = <span class=\"keyword\">this</span>._fields[j]\n      <span class=\"keyword\">var</span> fieldTokens = docTokens[field.name]\n      <span class=\"keyword\">var</span> fieldLength = fieldTokens.length\n\n      <span class=\"keyword\">if</span> (!fieldLength) <span class=\"keyword\">continue</span>\n\n      <span class=\"keyword\">var</span> tokenCount = <span class=\"number\">0</span>\n      <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> k = <span class=\"number\">0</span>; k &lt; fieldLength; k++){\n        <span class=\"keyword\">if</span> (fieldTokens[k] === token){\n          tokenCount++\n        }\n      }\n\n      tf += (tokenCount / fieldLength * field.boost)\n    }\n\n    <span class=\"keyword\">this</span>.tokenStore.add(token, { ref: docRef, tf: tf })\n  };\n\n  <span class=\"keyword\">if</span> (emitEvent) <span class=\"keyword\">this</span>.eventEmitter.emit(<span class=\"string\">'add'</span>, doc, <span class=\"keyword\">this</span>)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"remove\">\n              <header>\n                <h3>remove</h3>\n                <h4>lunr.Index.prototype.remove()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">remove</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>doc - The document to remove from the index.</li>\n                  \n                    <li>emitEvent - Whether to emit remove events, defaults to true</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Removes a document from the index.</p>\n\n<p>To make sure documents no longer show up in search results they can be removed from the index using this method.</p>\n\n<p>The document passed only needs to have the same ref property value as the document that was added to the index, they could be completely different objects.</p>\n\n<p>A 'remove' event is emitted with the document that has been removed and the index the document has been removed from. This event can be silenced by passing false as the second argument to remove.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.remove = <span class=\"keyword\">function</span> (doc, emitEvent) {\n  <span class=\"keyword\">var</span> docRef = doc[<span class=\"keyword\">this</span>._ref],\n      emitEvent = emitEvent === <span class=\"special\">undefined</span> ? <span class=\"keyword\">true</span> : emitEvent\n\n  <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.documentStore.has(docRef)) <span class=\"keyword\">return</span>\n\n  <span class=\"keyword\">var</span> docTokens = <span class=\"keyword\">this</span>.documentStore.get(docRef)\n\n  <span class=\"keyword\">this</span>.documentStore.remove(docRef)\n\n  docTokens.forEach(<span class=\"keyword\">function</span> (token) {\n    <span class=\"keyword\">this</span>.tokenStore.remove(token, docRef)\n  }, <span class=\"keyword\">this</span>)\n\n  <span class=\"keyword\">if</span> (emitEvent) <span class=\"keyword\">this</span>.eventEmitter.emit(<span class=\"string\">'remove'</span>, doc, <span class=\"keyword\">this</span>)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"update\">\n              <header>\n                <h3>update</h3>\n                <h4>lunr.Index.prototype.update()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">update</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>doc - The document to update in the index.</li>\n                  \n                    <li>emitEvent - Whether to emit update events, defaults to true</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Updates a document in the index.</p>\n\n<p>When a document contained within the index gets updated, fields changed, added or removed, to make sure it correctly matched against search queries, it should be updated in the index.</p>\n\n<p>This method is just a wrapper around <code>remove</code> and <code>add</code></p>\n\n<p>An 'update' event is emitted with the document that has been updated and the index. This event can be silenced by passing false as the second argument to update. Only an update event will be fired, the 'add' and 'remove' events of the underlying calls are silenced.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.update = <span class=\"keyword\">function</span> (doc, emitEvent) {\n  <span class=\"keyword\">var</span> emitEvent = emitEvent === <span class=\"special\">undefined</span> ? <span class=\"keyword\">true</span> : emitEvent\n\n  <span class=\"keyword\">this</span>.remove(doc, <span class=\"keyword\">false</span>)\n  <span class=\"keyword\">this</span>.add(doc, <span class=\"keyword\">false</span>)\n\n  <span class=\"keyword\">if</span> (emitEvent) <span class=\"keyword\">this</span>.eventEmitter.emit(<span class=\"string\">'update'</span>, doc, <span class=\"keyword\">this</span>)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"idf\">\n              <header>\n                <h3>idf</h3>\n                <h4>lunr.Index.prototype.idf()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">idf</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>token - The token to calculate the idf of.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Calculates the inverse document frequency for a token within the index.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.idf = <span class=\"keyword\">function</span> (term) {\n  <span class=\"keyword\">var</span> cacheKey = <span class=\"string\">\"@\"</span> + term\n  <span class=\"keyword\">if</span> (<span class=\"class\">Object</span>.prototype.hasOwnProperty.call(<span class=\"keyword\">this</span>._idfCache, cacheKey)) <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>._idfCache[cacheKey]\n\n  <span class=\"keyword\">var</span> documentFrequency = <span class=\"keyword\">this</span>.tokenStore.count(term),\n      idf = <span class=\"number\">1</span>\n\n  <span class=\"keyword\">if</span> (documentFrequency &gt; <span class=\"number\">0</span>) {\n    idf = <span class=\"number\">1</span> + <span class=\"class\">Math</span>.log(<span class=\"keyword\">this</span>.documentStore.length / documentFrequency)\n  }\n\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>._idfCache[cacheKey] = idf\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"search\">\n              <header>\n                <h3>search</h3>\n                <h4>lunr.Index.prototype.search()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">search</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>query - The query to search the index with.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Searches the index using the passed query.</p>\n\n<p>Queries should be a string, multiple words are allowed and will lead to an AND based query, e.g. <code>idx.search(<span class=\"string\">'foo bar'</span>)</code> will run a search for documents containing both 'foo' and 'bar'.</p>\n\n<p>All query tokens are passed through the same pipeline that document tokens are passed through, so any language processing involved will be run on every query term.</p>\n\n<p>Each query term is expanded, so that the term 'he' might be expanded to 'hello' and 'help' if those terms were already included in the index.</p>\n\n<p>Matching documents are returned as an array of objects, each object contains the matching document ref, as set for this index, and the similarity score for this document against the query.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.search = <span class=\"keyword\">function</span> (query) {\n  <span class=\"keyword\">var</span> queryTokens = <span class=\"keyword\">this</span>.pipeline.run(<span class=\"keyword\">this</span>.tokenizerFn(query)),\n      queryVector = <span class=\"keyword\">new</span> lunr.<span class=\"class\">Vector</span>,\n      documentSets = [],\n      fieldBoosts = <span class=\"keyword\">this</span>._fields.reduce(<span class=\"keyword\">function</span> (memo, f) { <span class=\"keyword\">return</span> memo + f.boost }, <span class=\"number\">0</span>)\n\n  <span class=\"keyword\">var</span> hasSomeToken = queryTokens.some(<span class=\"keyword\">function</span> (token) {\n    <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.tokenStore.has(token)\n  }, <span class=\"keyword\">this</span>)\n\n  <span class=\"keyword\">if</span> (!hasSomeToken) <span class=\"keyword\">return</span> []\n\n  queryTokens\n    .forEach(<span class=\"keyword\">function</span> (token, i, tokens) {\n      <span class=\"keyword\">var</span> tf = <span class=\"number\">1</span> / tokens.length * <span class=\"keyword\">this</span>._fields.length * fieldBoosts,\n          self = <span class=\"keyword\">this</span>\n\n      <span class=\"keyword\">var</span> set = <span class=\"keyword\">this</span>.tokenStore.expand(token).reduce(<span class=\"keyword\">function</span> (memo, key) {\n        <span class=\"keyword\">var</span> pos = self.corpusTokens.indexOf(key),\n            idf = self.idf(key),\n            similarityBoost = <span class=\"number\">1</span>,\n            set = <span class=\"keyword\">new</span> lunr.<span class=\"class\">SortedSet</span>\n\n        <span class=\"comment\">// if the expanded key is not an exact match to the token then</span>\n        <span class=\"comment\">// penalise the score for this key by how different the key is</span>\n        <span class=\"comment\">// to the token.</span>\n        <span class=\"keyword\">if</span> (key !== token) {\n          <span class=\"keyword\">var</span> diff = <span class=\"class\">Math</span>.max(<span class=\"number\">3</span>, key.length - token.length)\n          similarityBoost = <span class=\"number\">1</span> / <span class=\"class\">Math</span>.log(diff)\n        }\n\n        <span class=\"comment\">// calculate the query tf-idf score for this token</span>\n        <span class=\"comment\">// applying an similarityBoost to ensure exact matches</span>\n        <span class=\"comment\">// these rank higher than expanded terms</span>\n        <span class=\"keyword\">if</span> (pos &gt; -<span class=\"number\">1</span>) queryVector.insert(pos, tf * idf * similarityBoost)\n\n        <span class=\"comment\">// add all the documents that have this key into a set</span>\n        <span class=\"comment\">// ensuring that the type of key is preserved</span>\n        <span class=\"keyword\">var</span> matchingDocuments = self.tokenStore.get(key),\n            refs = <span class=\"class\">Object</span>.keys(matchingDocuments),\n            refsLen = refs.length\n\n        <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; refsLen; i++) {\n          set.add(matchingDocuments[refs[i]].ref)\n        }\n\n        <span class=\"keyword\">return</span> memo.union(set)\n      }, <span class=\"keyword\">new</span> lunr.<span class=\"class\">SortedSet</span>)\n\n      documentSets.push(set)\n    }, <span class=\"keyword\">this</span>)\n\n  <span class=\"keyword\">var</span> documentSet = documentSets.reduce(<span class=\"keyword\">function</span> (memo, set) {\n    <span class=\"keyword\">return</span> memo.intersect(set)\n  })\n\n  <span class=\"keyword\">return</span> documentSet\n    .map(<span class=\"keyword\">function</span> (ref) {\n      <span class=\"keyword\">return</span> { ref: ref, score: queryVector.similarity(<span class=\"keyword\">this</span>.documentVector(ref)) }\n    }, <span class=\"keyword\">this</span>)\n    .sort(<span class=\"keyword\">function</span> (a, b) {\n      <span class=\"keyword\">return</span> b.score - a.score\n    })\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"documentVector\">\n              <header>\n                <h3>documentVector</h3>\n                <h4>lunr.Index.prototype.documentVector()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">documentVector</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>documentRef - The ref to find the document with.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Generates a vector containing all the tokens in the document matching the passed documentRef.</p>\n\n<p>The vector contains the tf-idf score for each token contained in the document with the passed documentRef.  The vector will contain an element for every token in the indexes corpus, if the document does not contain that token the element will be 0.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.documentVector = <span class=\"keyword\">function</span> (documentRef) {\n  <span class=\"keyword\">var</span> documentTokens = <span class=\"keyword\">this</span>.documentStore.get(documentRef),\n      documentTokensLength = documentTokens.length,\n      documentVector = <span class=\"keyword\">new</span> lunr.<span class=\"class\">Vector</span>\n\n  <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; documentTokensLength; i++) {\n    <span class=\"keyword\">var</span> token = documentTokens.elements[i],\n        tf = <span class=\"keyword\">this</span>.tokenStore.get(token)[documentRef].tf,\n        idf = <span class=\"keyword\">this</span>.idf(token)\n\n    documentVector.insert(<span class=\"keyword\">this</span>.corpusTokens.indexOf(token), tf * idf)\n  };\n\n  <span class=\"keyword\">return</span> documentVector\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"toJSON\">\n              <header>\n                <h3>toJSON</h3>\n                <h4>lunr.Index.prototype.toJSON()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">toJSON</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                <ul>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Returns a representation of the index ready for serialisation.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.toJSON = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">return</span> {\n    version: lunr.version,\n    fields: <span class=\"keyword\">this</span>._fields,\n    ref: <span class=\"keyword\">this</span>._ref,\n    tokenizer: <span class=\"keyword\">this</span>.tokenizerFn.label,\n    documentStore: <span class=\"keyword\">this</span>.documentStore.toJSON(),\n    tokenStore: <span class=\"keyword\">this</span>.tokenStore.toJSON(),\n    corpusTokens: <span class=\"keyword\">this</span>.corpusTokens.toJSON(),\n    pipeline: <span class=\"keyword\">this</span>.pipeline.toJSON()\n  }\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"use\">\n              <header>\n                <h3>use</h3>\n                <h4>lunr.Index.prototype.use()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">use</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>plugin - The plugin to apply.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Applies a plugin to the current index.</p>\n\n<p>A plugin is a function that is called with the index as its context. Plugins can be used to customise or extend the behaviour the index in some way. A plugin is just a function, that encapsulated the custom behaviour that should be applied to the index.</p>\n\n<p>The plugin function will be called with the index as its argument, additional arguments can also be passed when calling use. The function will be called with the index as its context.</p>\n\n<p>Example:</p>\n\n<pre><code><span class=\"keyword\">var</span> myPlugin = <span class=\"keyword\">function</span> (idx, arg1, arg2) {\n  <span class=\"comment\">// `this` is the index to be extended</span>\n  <span class=\"comment\">// apply any extensions etc here.</span>\n}\n\n<span class=\"keyword\">var</span> idx = lunr(<span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">this</span>.use(myPlugin, <span class=\"string\">'arg1'</span>, <span class=\"string\">'arg2'</span>)\n})\n</code></pre>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Index</span>.prototype.use = <span class=\"keyword\">function</span> (plugin) {\n  <span class=\"keyword\">var</span> args = <span class=\"class\">Array</span>.prototype.slice.call(arguments, <span class=\"number\">1</span>)\n  args.unshift(<span class=\"keyword\">this</span>)\n  plugin.apply(<span class=\"keyword\">this</span>, args)\n}</code></pre>\n              </section>\n              \n            </section>\n          \n        </article>\n      \n        <article id=\"Store\">\n          <header>\n            <h2>Store</h2>\n          </header>\n\n          <section>\n            <p>lunr.Store is a simple key-value store used for storing sets of tokens for documents stored in index.</p>\n          </section>\n\n          \n            <section class=\"method\" id=\"load\">\n              <header>\n                <h3>load</h3>\n                <h4>lunr.Store.load()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">load</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>serialisedData - The serialised store to load.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Loads a previously serialised store</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Store</span>.load = <span class=\"keyword\">function</span> (serialisedData) {\n  <span class=\"keyword\">var</span> store = <span class=\"keyword\">new</span> <span class=\"keyword\">this</span>\n\n  store.length = serialisedData.length\n  store.store = <span class=\"class\">Object</span>.keys(serialisedData.store).reduce(<span class=\"keyword\">function</span> (memo, key) {\n    memo[key] = lunr.<span class=\"class\">SortedSet</span>.load(serialisedData.store[key])\n    <span class=\"keyword\">return</span> memo\n  }, {})\n\n  <span class=\"keyword\">return</span> store\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"set\">\n              <header>\n                <h3>set</h3>\n                <h4>lunr.Store.prototype.set()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">set</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>id - The key used to store the tokens against.</li>\n                  \n                    <li>tokens - The tokens to store against the key.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Stores the given tokens in the store against the given id.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Store</span>.prototype.set = <span class=\"keyword\">function</span> (id, tokens) {\n  <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.has(id)) <span class=\"keyword\">this</span>.length++\n  <span class=\"keyword\">this</span>.store[id] = tokens\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"get\">\n              <header>\n                <h3>get</h3>\n                <h4>lunr.Store.prototype.get()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">get</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>id - The key to lookup and retrieve from the store.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Retrieves the tokens from the store for a given key.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Store</span>.prototype.get = <span class=\"keyword\">function</span> (id) {\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.store[id]\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"has\">\n              <header>\n                <h3>has</h3>\n                <h4>lunr.Store.prototype.has()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">has</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>id - The id to look up in the store.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Checks whether the store contains a key.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Store</span>.prototype.has = <span class=\"keyword\">function</span> (id) {\n  <span class=\"keyword\">return</span> id <span class=\"keyword\">in</span> <span class=\"keyword\">this</span>.store\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"remove\">\n              <header>\n                <h3>remove</h3>\n                <h4>lunr.Store.prototype.remove()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">remove</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>id - The id to remove from the store.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Removes the value for a key in the store.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Store</span>.prototype.remove = <span class=\"keyword\">function</span> (id) {\n  <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.has(id)) <span class=\"keyword\">return</span>\n\n  <span class=\"keyword\">delete</span> <span class=\"keyword\">this</span>.store[id]\n  <span class=\"keyword\">this</span>.length--\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"toJSON\">\n              <header>\n                <h3>toJSON</h3>\n                <h4>lunr.Store.prototype.toJSON()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">toJSON</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                <ul>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Returns a representation of the store ready for serialisation.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">Store</span>.prototype.toJSON = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">return</span> {\n    store: <span class=\"keyword\">this</span>.store,\n    length: <span class=\"keyword\">this</span>.length\n  }\n}</code></pre>\n              </section>\n              \n            </section>\n          \n        </article>\n      \n        <article id=\"stemmer\">\n          <header>\n            <h2>stemmer</h2>\n          </header>\n\n          <section>\n            <p>lunr.stemmer is an english language stemmer, this is a JavaScript implementation of the PorterStemmer taken from <a href=\"http://tartarus.org/~martin\">http://tartarus.org/~martin</a></p>\n          </section>\n\n          \n        </article>\n      \n        <article id=\"generateStopWordFilter\">\n          <header>\n            <h2>generateStopWordFilter</h2>\n          </header>\n\n          <section>\n            <p>lunr.generateStopWordFilter builds a stopWordFilter function from the provided list of stop words.</p>\n\n<p>The built in lunr.stopWordFilter is built using this generator and can be used to generate custom stopWordFilters for applications or non English languages.</p>\n          </section>\n\n          \n        </article>\n      \n        <article id=\"stopWordFilter\">\n          <header>\n            <h2>stopWordFilter</h2>\n          </header>\n\n          <section>\n            <p>lunr.stopWordFilter is an English language stop word list filter, any words contained in the list will not be passed through the filter.</p>\n\n<p>This is intended to be used in the Pipeline. If the token does not pass the filter then undefined will be returned.</p>\n          </section>\n\n          \n        </article>\n      \n        <article id=\"trimmer\">\n          <header>\n            <h2>trimmer</h2>\n          </header>\n\n          <section>\n            <p>lunr.trimmer is a pipeline function for trimming non word characters from the begining and end of tokens before they enter the index.</p>\n\n<p>This implementation may not work correctly for non latin characters and should either be removed or adapted for use with languages with non-latin characters.</p>\n          </section>\n\n          \n        </article>\n      \n        <article id=\"TokenStore\">\n          <header>\n            <h2>TokenStore</h2>\n          </header>\n\n          <section>\n            <p>lunr.TokenStore is used for efficient storing and lookup of the reverse index of token to document ref.</p>\n          </section>\n\n          \n            <section class=\"method\" id=\"load\">\n              <header>\n                <h3>load</h3>\n                <h4>lunr.TokenStore.load()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">load</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>serialisedData - The serialised token store to load.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Loads a previously serialised token store</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">TokenStore</span>.load = <span class=\"keyword\">function</span> (serialisedData) {\n  <span class=\"keyword\">var</span> store = <span class=\"keyword\">new</span> <span class=\"keyword\">this</span>\n\n  store.root = serialisedData.root\n  store.length = serialisedData.length\n\n  <span class=\"keyword\">return</span> store\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"add\">\n              <header>\n                <h3>add</h3>\n                <h4>lunr.TokenStore.prototype.add()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">add</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>token - The token to store the doc under</li>\n                  \n                    <li>doc - The doc to store against the token</li>\n                  \n                    <li>root - An optional node at which to start looking for the</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Adds a new token doc pair to the store.</p>\n\n<p>By default this function starts at the root of the current store, however it can start at any node of any token store if required.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">TokenStore</span>.prototype.add = <span class=\"keyword\">function</span> (token, doc, root) {\n  <span class=\"keyword\">var</span> root = root || <span class=\"keyword\">this</span>.root,\n      key = token.charAt(<span class=\"number\">0</span>),\n      rest = token.slice(<span class=\"number\">1</span>)\n\n  <span class=\"keyword\">if</span> (!(key <span class=\"keyword\">in</span> root)) root[key] = {docs: {}}\n\n  <span class=\"keyword\">if</span> (rest.length === <span class=\"number\">0</span>) {\n    root[key].docs[doc.ref] = doc\n    <span class=\"keyword\">this</span>.length += <span class=\"number\">1</span>\n    <span class=\"keyword\">return</span>\n  } <span class=\"keyword\">else</span> {\n    <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.add(rest, doc, root[key])\n  }\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"has\">\n              <header>\n                <h3>has</h3>\n                <h4>lunr.TokenStore.prototype.has()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">has</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>token - The token to check for</li>\n                  \n                    <li>root - An optional node at which to start</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Checks whether this key is contained within this lunr.TokenStore.</p>\n\n<p>By default this function starts at the root of the current store, however it can start at any node of any token store if required.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">TokenStore</span>.prototype.has = <span class=\"keyword\">function</span> (token) {\n  <span class=\"keyword\">if</span> (!token) <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>\n\n  <span class=\"keyword\">var</span> node = <span class=\"keyword\">this</span>.root\n\n  <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; token.length; i++) {\n    <span class=\"keyword\">if</span> (!node[token.charAt(i)]) <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>\n\n    node = node[token.charAt(i)]\n  }\n\n  <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"getNode\">\n              <header>\n                <h3>getNode</h3>\n                <h4>lunr.TokenStore.prototype.getNode()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">getNode</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>token - The token to get the node for.</li>\n                  \n                    <li>root - An optional node at which to start.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Retrieve a node from the token store for a given token.</p>\n\n<p>By default this function starts at the root of the current store, however it can start at any node of any token store if required.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">TokenStore</span>.prototype.getNode = <span class=\"keyword\">function</span> (token) {\n  <span class=\"keyword\">if</span> (!token) <span class=\"keyword\">return</span> {}\n\n  <span class=\"keyword\">var</span> node = <span class=\"keyword\">this</span>.root\n\n  <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; token.length; i++) {\n    <span class=\"keyword\">if</span> (!node[token.charAt(i)]) <span class=\"keyword\">return</span> {}\n\n    node = node[token.charAt(i)]\n  }\n\n  <span class=\"keyword\">return</span> node\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"get\">\n              <header>\n                <h3>get</h3>\n                <h4>lunr.TokenStore.prototype.get()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">get</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>token - The token to get the documents for.</li>\n                  \n                    <li>root - An optional node at which to start.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Retrieve the documents for a node for the given token.</p>\n\n<p>By default this function starts at the root of the current store, however it can start at any node of any token store if required.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">TokenStore</span>.prototype.get = <span class=\"keyword\">function</span> (token, root) {\n  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.getNode(token, root).docs || {}\n}\n\nlunr.<span class=\"class\">TokenStore</span>.prototype.count = <span class=\"keyword\">function</span> (token, root) {\n  <span class=\"keyword\">return</span> <span class=\"class\">Object</span>.keys(<span class=\"keyword\">this</span>.get(token, root)).length\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"remove\">\n              <header>\n                <h3>remove</h3>\n                <h4>lunr.TokenStore.prototype.remove()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">remove</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>token - The token to get the documents for.</li>\n                  \n                    <li>ref - The ref of the document to remove from this token.</li>\n                  \n                    <li>root - An optional node at which to start.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Remove the document identified by ref from the token in the store.</p>\n\n<p>By default this function starts at the root of the current store, however it can start at any node of any token store if required.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">TokenStore</span>.prototype.remove = <span class=\"keyword\">function</span> (token, ref) {\n  <span class=\"keyword\">if</span> (!token) <span class=\"keyword\">return</span>\n  <span class=\"keyword\">var</span> node = <span class=\"keyword\">this</span>.root\n\n  <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; token.length; i++) {\n    <span class=\"keyword\">if</span> (!(token.charAt(i) <span class=\"keyword\">in</span> node)) <span class=\"keyword\">return</span>\n    node = node[token.charAt(i)]\n  }\n\n  <span class=\"keyword\">delete</span> node.docs[ref]\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"expand\">\n              <header>\n                <h3>expand</h3>\n                <h4>lunr.TokenStore.prototype.expand()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">expand</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                  <h4>Params</h4>\n                \n                <ul>\n                  \n                    <li>token - The token to expand.</li>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Find all the possible suffixes of the passed token using tokens currently in the store.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">TokenStore</span>.prototype.expand = <span class=\"keyword\">function</span> (token, memo) {\n  <span class=\"keyword\">var</span> root = <span class=\"keyword\">this</span>.getNode(token),\n      docs = root.docs || {},\n      memo = memo || []\n\n  <span class=\"keyword\">if</span> (<span class=\"class\">Object</span>.keys(docs).length) memo.push(token)\n\n  <span class=\"class\">Object</span>.keys(root)\n    .forEach(<span class=\"keyword\">function</span> (key) {\n      <span class=\"keyword\">if</span> (key === <span class=\"string\">'docs'</span>) <span class=\"keyword\">return</span>\n\n      memo.concat(<span class=\"keyword\">this</span>.expand(token + key, memo))\n    }, <span class=\"keyword\">this</span>)\n\n  <span class=\"keyword\">return</span> memo\n}</code></pre>\n              </section>\n              \n            </section>\n          \n            <section class=\"method\" id=\"toJSON\">\n              <header>\n                <h3>toJSON</h3>\n                <h4>lunr.TokenStore.prototype.toJSON()</h4>\n                <p class=\"type\">method</p>\n                \n                  <p class=\"related\">See: <a href=\"#\">toJSON</a></p>\n                \n              </header>\n\n              <section class=\"params\">\n                \n                <ul>\n                  \n                </ul>\n              </section>\n\n              \n\n              <section>\n                <p>Returns a representation of the token store ready for serialisation.</p>\n              </section>\n\n              <section class=\"source\">\n                <h4>Source</h4>\n                <pre><code>lunr.<span class=\"class\">TokenStore</span>.prototype.toJSON = <span class=\"keyword\">function</span> () {\n  <span class=\"keyword\">return</span> {\n    root: <span class=\"keyword\">this</span>.root,\n    length: <span class=\"keyword\">this</span>.length\n  }\n}</code></pre>\n              </section>\n              \n            </section>\n          \n        </article>\n      \n    </div>"
		}
	]
}
